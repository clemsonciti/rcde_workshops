{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2afce6df-0519-460b-b64f-f3f1e506d561",
   "metadata": {},
   "source": [
    "# Building the network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e050e5cd-265f-436e-babd-14a6597132ec",
   "metadata": {},
   "source": [
    "The `nn.Module` subpackage in PyTorch contains many neural network building blocks called \"modules\". We can compose these in arbitrary ways to build network architectures tailored to a given problem. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78ac35a7-044e-434f-904a-edf5311a1def",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# do everything on gpu unless we explicitly say otherwise\n",
    "torch.set_default_device('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933ed3f8-f62a-4f9a-a365-992bcd14d921",
   "metadata": {},
   "source": [
    "## The basics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225c65d5-89fb-413b-a661-767cf3a378f1",
   "metadata": {},
   "source": [
    "We saw examples like this in earlier notebooks: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d361b96-c513-42a2-acde-15663955ba95",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=10, out_features=10, bias=True)\n",
       "  (1): Tanh()\n",
       "  (2): Linear(in_features=10, out_features=10, bias=True)\n",
       "  (3): Tanh()\n",
       "  (4): Linear(in_features=10, out_features=3, bias=True)\n",
       "  (5): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(10,10),\n",
    "    nn.Tanh(),\n",
    "    nn.Linear(10,10),\n",
    "    nn.Tanh(),\n",
    "    nn.Linear(10,3),\n",
    "    nn.Sigmoid()\n",
    ")\n",
    "\n",
    "# printing the model shows the layers\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53cc531e-0228-4eac-b6a8-8494520c4041",
   "metadata": {},
   "source": [
    "`nn.Sequential`, `nn.Linear`, `nn.Tanh`, and `nn.Sigmoid` are all examples of modules. There are many more. You can see a full list here: https://pytorch.org/docs/stable/nn.html\n",
    "\n",
    "**Callable.** All modules are _callable_, meaning they can be evaluated like a function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "477f0ae1-06bd-412f-ae0a-506a32e2dbb9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0598,  0.0131, -0.0854, -0.6607, -0.1993],\n",
       "        [-0.0425,  0.5190,  0.6656, -1.0550, -0.3481],\n",
       "        [ 1.0251, -0.7363, -0.9741, -0.8997,  0.0310],\n",
       "        [-0.2934, -0.0984, -0.3092, -0.1875, -0.1605],\n",
       "        [-0.5643,  0.8014,  0.1436, -0.5571, -0.5451],\n",
       "        [-0.5590,  0.1040, -0.3402,  0.0422, -0.2416],\n",
       "        [-0.2919, -0.4171, -0.1272, -0.3652, -0.0406]], device='cuda:0',\n",
       "       grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer = nn.Linear(4,5)\n",
    "x = torch.randn(7, 4)\n",
    "layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c51be746-c0bb-4d96-82c0-5959ce71837e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0698, -0.0402, -0.2436, -0.7002],\n",
       "        [-0.8310, -0.4923,  0.5896, -0.4685],\n",
       "        [ 0.5444,  0.7774, -0.9923, -0.9824],\n",
       "        [ 0.6785, -0.3635,  0.1641, -0.4440],\n",
       "        [ 0.0650,  0.8741,  0.3331,  0.2424],\n",
       "        [ 0.6767, -0.4797,  0.3434,  0.0332],\n",
       "        [ 0.9344,  0.2534,  0.7204, -0.7594]], device='cuda:0')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer = nn.Tanh()\n",
    "layer(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85de0d18-2cdf-4be0-869a-9a9a0ee6040d",
   "metadata": {},
   "source": [
    "**Changing device.** Modules can be moved between devices. Unlike tensors, this operation is _in place_. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7af6b460-536c-4467-b69a-7cd73e7df459",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: cuda:0\n",
      "After: cpu\n"
     ]
    }
   ],
   "source": [
    "layer = nn.Linear(4,5)\n",
    "print(\"Before:\", layer.weight.device)\n",
    "layer.to('cpu')\n",
    "print(\"After:\", layer.weight.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab88aeaa-8775-4a95-9d36-ac7e69a96b07",
   "metadata": {},
   "source": [
    "All nested modules also move: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de49e75b-a7ba-4c6f-bc6d-88ce412c6161",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: cuda:0\n",
      "After: cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=10, out_features=10, bias=True)\n",
       "  (1): Tanh()\n",
       "  (2): Linear(in_features=10, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(10,10),\n",
    "    nn.Tanh(),\n",
    "    nn.Linear(10,3)\n",
    ")\n",
    "\n",
    "print(\"Before:\", model[0].weight.device)\n",
    "model.to('cpu')\n",
    "print(\"After:\", model[0].weight.device)\n",
    "\n",
    "# back on gpu for later\n",
    "model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "937f534f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Recollection check! What's the purpose of the `tanh` layer in the above model? Why is it important to include this or something like it here?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ded912c8bc2d4036bf3086627b336ddb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', layout=Layout(width='500px'), placeholder='Type your answer here')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f044a6649f7a481595e4205e913001ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='success', description='Submit', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f33c9790e10d4e96af702671e59b6a01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from utils import create_answer_box\n",
    "create_answer_box(\"Recollection check! What's the purpose of the `tanh` layer in the above model? Why is it important to include this or something like it here?\", \"06-01\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4696955b-60f3-4aea-b775-52de499eadaf",
   "metadata": {},
   "source": [
    "**Saving/loading**. Model weights can be saved to and loaded from disc. There are a few ways to do this. The recommended way is to just save the weights using the \"state dict\" object:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3c8ac65-cef8-4d4b-8581-6c8746918672",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.weight torch.Size([10, 10])\n",
      "0.bias torch.Size([10])\n",
      "2.weight torch.Size([3, 10])\n",
      "2.bias torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "for k, v in model.state_dict().items():\n",
    "    print(k, v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6390d5cc-8015-4c94-8669-4c39a7ae4962",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model_weights.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "123135aa-dd66-49a1-9eca-5796b61b44e6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PK\u0003\u0004\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0016\u0000\f\u0000model_weights/data.pklF\u0000ZZZZZZZZï¿½\u0002ccollections\n",
      "OrderedDict\n",
      "q\u0000)Rq\u0001(\u0000\u0000\u00000.weightq\u0002ctorch._utils\n"
     ]
    }
   ],
   "source": [
    "# Pytorch uses a version of pickle to save the weights\n",
    "!head -n 3 model_weights.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1280c676-407b-44b0-83c8-87656237a9de",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# some time later...\n",
    "model2 = nn.Sequential(\n",
    "    nn.Linear(10,10),\n",
    "    nn.Tanh(),\n",
    "    nn.Linear(10,3)\n",
    ")\n",
    "\n",
    "model2.load_state_dict(torch.load('model_weights.pt', weights_only=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fffa20f-db29-4500-9c88-281bb57060e4",
   "metadata": {},
   "source": [
    "Using the state dict required that we instantiate the model class first. We can also save the model structure together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c622fb42-99f0-4985-8811-b3943f63b4ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.save(model, 'model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "77e8fafe-e2da-4f36-be7d-7a54d60546f3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local_scratch/slurm.3876934/ipykernel_2140800/475113603.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model2 = torch.load('model.pt')\n"
     ]
    }
   ],
   "source": [
    "model2 = torch.load('model.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "577158f4-fa83-44a2-80d8-c67eb911f63a",
   "metadata": {},
   "source": [
    "Using `model.state_dict()` to save weights offers greater flexibility and compatibility, as it separates the model's parameters from its architecture, making it easy to update the model class or share weights. This approach results in smaller files and better portability across environments or versions of PyTorch, whereas saving the entire model (`torch.save(model, ...)`) is simpler but less adaptable to changes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51be37da-62d4-4d80-9621-923550ebacfd",
   "metadata": {},
   "source": [
    "**`eval`/`train` modes.** Some layers need to behave differently at training time and evaluation time. These can all be toggled with the `train()` and `eval()` methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2261f527-7b93-4209-a1d2-81862dabd4b3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.9855, -1.9097,  0.7585,  0.4166, -2.3734],\n",
      "        [ 0.5442, -0.9407,  0.7984, -0.1559, -1.0020],\n",
      "        [-0.5164,  0.0046,  0.1693,  1.7144,  1.6055]], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000, -3.8194,  0.0000,  0.8332, -4.7467],\n",
       "        [ 1.0885, -1.8815,  0.0000, -0.3118, -2.0039],\n",
       "        [-1.0328,  0.0093,  0.0000,  3.4289,  3.2110]], device='cuda:0')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer = nn.Dropout(0.5)\n",
    "\n",
    "# the default mode is \"training\"\n",
    "x = torch.randn(3, 5)\n",
    "print(x)\n",
    "layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4d9d9fdc-e5a1-4c5c-9c7f-c5100a4b713e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.9855, -1.9097,  0.7585,  0.4166, -2.3734],\n",
       "        [ 0.5442, -0.9407,  0.7984, -0.1559, -1.0020],\n",
       "        [-0.5164,  0.0046,  0.1693,  1.7144,  1.6055]], device='cuda:0')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# switch to eval:\n",
    "layer.eval()\n",
    "layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fafbcf6f-f58e-440f-b750-00422d81ccea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000, -3.8194,  1.5171,  0.0000, -0.0000],\n",
       "        [ 1.0885, -1.8815,  0.0000, -0.3118, -2.0039],\n",
       "        [-1.0328,  0.0093,  0.0000,  3.4289,  3.2110]], device='cuda:0')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# switch back to train\n",
    "layer.train()\n",
    "layer(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c1b63d-d265-4b56-b4f6-6bd9f57f9a61",
   "metadata": {},
   "source": [
    "## Writing custom modules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df47e22-665b-4a03-a68c-e3a3e78777c9",
   "metadata": {},
   "source": [
    "You can make your own modules. To do so, subclass `nn.Module` and define the `__init__` and `forward` method. These modules can be used just like any other module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dd280661-ac02-43b4-aa48-e88d198f643b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNetwork(\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (encoder): Sequential(\n",
       "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (5): ReLU()\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=256, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        The __init__ method defines all of the modules/parameters that will \n",
    "        appear in the model.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(256,1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Define how to get from the input to the output. \n",
    "        You can use arbitrary python code here so long as the \n",
    "        tensor operations are differentiable. \n",
    "        \"\"\"\n",
    "        x = self.flatten(x)\n",
    "        h = self.encoder(x)\n",
    "        y = self.classifier(h)\n",
    "        return y\n",
    "    \n",
    "model = NeuralNetwork()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cae247c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The `forward` method is very flexible, but there are limits. Can you think of an example of code that would NOT work in the `forward` method? Why would it not work?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e959326b836a4ee098c8339195089037",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', layout=Layout(width='500px'), placeholder='Type your answer here')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bc34f8b0a1b436590953500873857e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='success', description='Submit', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "847c6eadc3804782be8f8b00ca933402",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "create_answer_box(\"The `forward` method is very flexible, but there are limits. Can you think of an example of code that would NOT work in the `forward` method? Why would it not work?\", \"06-02\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "29f14f3b-2f82-422e-af82-26acfcec7447",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0322],\n",
       "        [ 0.0130],\n",
       "        [ 0.0116],\n",
       "        [-0.0103],\n",
       "        [-0.0058]], device='cuda:0', grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# simulate a batch of grayscale images:\n",
    "x = torch.randn(5, 1, 28, 28)\n",
    "\n",
    "model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155cb812-a6d0-4dd4-9523-864a78ee524b",
   "metadata": {},
   "source": [
    "You can customize your network however you see fit. For example, say we had a problem where the network took two images as input and made some decision about them. We could do something like this: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c8e58226-2338-4fb4-b303-efe9967e5982",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PairNetwork(\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (encoder): Sequential(\n",
       "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (5): ReLU()\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=512, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class PairNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        The __init__ method defines all of the modules/parameters that will \n",
    "        appear in the model.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(2*256,1)  # double the representation size\n",
    "        )\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        \"\"\"\n",
    "        Define how to get from the input to the output. \n",
    "        You can use arbitrary python code here so long as the \n",
    "        tensor operations are differentiable. \n",
    "        \"\"\"\n",
    "        x1 = self.flatten(x1)\n",
    "        h1 = self.encoder(x1)\n",
    "        \n",
    "        x2 = self.flatten(x2)\n",
    "        h2 = self.encoder(x2)\n",
    "        \n",
    "        # fuse the representations\n",
    "        h = torch.concat([h1, h2], axis=-1)\n",
    "        \n",
    "        y = self.classifier(h)\n",
    "        return y\n",
    "    \n",
    "pair_model = PairNetwork()\n",
    "pair_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4bcc4c8c-9d65-4362-a584-346ceca80017",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0026],\n",
       "        [ 0.0202],\n",
       "        [-0.0074],\n",
       "        [-0.0416],\n",
       "        [ 0.0159]], device='cuda:0', grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# simulate a batch of grayscale images:\n",
    "x1 = torch.randn(5, 1, 28, 28)\n",
    "x2 = torch.randn(5, 1, 28, 28)\n",
    "\n",
    "pair_model(x1, x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a83ffd96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "This network takes two images and concatenates their representations. Can you think of real-world applications where you'd want to compare or combine multiple inputs like this?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6190e74b39414a2abf7c6fa69fc1ab38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', layout=Layout(width='500px'), placeholder='Type your answer here')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f04803c4a8a54ae7a2edf903843b5b35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='success', description='Submit', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "891c752a9c2441c59de711c13df63697",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "create_answer_box(\"This network takes two images and concatenates their representations. Can you think of real-world applications where you'd want to compare or combine multiple inputs like this?\", \"06-03\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b1f7a9-1bf8-485e-9064-b8ad9c821b70",
   "metadata": {},
   "source": [
    "**Tracking parameters** Pytorch automatically tracks all of the parameters that appear in your custom model. This allows Pytorch to optimize the network during training. It allows can allow you to get diagnostic information such as the number of parameters in your model: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "882bfee0-0813-463d-8e8e-80e2fc3cac00",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 796161\n"
     ]
    }
   ],
   "source": [
    "num_pars = sum([p.numel() for p in model.parameters()])\n",
    "print(\"Number of parameters:\", num_pars)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PytorchWorkshop",
   "language": "python",
   "name": "pytorchworkshop"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
