{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9XHd5ExbUIUg"
   },
   "source": [
    "# PyTorch Quickstart\n",
    "In this code tutorial we will learn how to quickly train a model to understand some of PyTorch's basic building blocks to train a deep learning model. After completion of this tutorial, you should be able to import data, transform it, and efficiently feed the data in batches to a convolution neural network (CNN) model for image classification.\n",
    "\n",
    "This quickstart was adapted from [dair-ai's notebook](https://github.com/dair-ai/pytorch_notebooks/blob/master/pytorch_quick_start.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Su0COdCqT2Wk",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "rXCYmmjyVRq5",
    "outputId": "a9ea67e6-cd29-4c4e-bb8f-127eac9ab764",
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hhuQyU7AYE6K"
   },
   "source": [
    "## Import The Data\n",
    "The first step before training the model is to import the data. We will use the [MNIST dataset](http://yann.lecun.com/exdb/mnist/) which is like the Hello World dataset of machine learning. \n",
    "\n",
    "Besides importing the data, we will also do a few more things:\n",
    "- We will tranform the data into tensors using the `transforms` module\n",
    "- We will use `DataLoader` to build convenient data loaders or what are referred to as iterators, which makes it easy to efficiently feed data in batches to deep learning models. \n",
    "- As hinted above, we will also create batches of the data by setting the `batch` parameter inside the data loader. Notice we use batches of `32` in this tutorial but you can change it to `64` if you like. I encourage you to experiment with different batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "colab_type": "code",
    "id": "tSjjLXrOVWBy",
    "outputId": "47502e82-f178-452b-995f-8a469670a471",
    "tags": []
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "## transformations\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor()])\n",
    "\n",
    "## download and load training dataset\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "## download and load testing dataset\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=BATCH_SIZE,\n",
    "                                         shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0nZwZukWXUDn"
   },
   "source": [
    "## Exploring the Data\n",
    "As a practioner and researcher, I am always spending a bit of time and effort exploring and understanding the dataset. It's fun and this is a good practise to ensure that everything is in order. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NW_loWKga7CH"
   },
   "source": [
    "Let's check what the train and test dataset contains. I will use `matplotlib` to print out some of the images from our dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 220
    },
    "colab_type": "code",
    "id": "zWd9Pt1Ca6K9",
    "outputId": "1c02a3b5-f5bb-4c51-a999-52d0472f43af",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "## functions to show an image\n",
    "def imshow(img):\n",
    "    #img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "## get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "## show images\n",
    "imshow(torchvision.utils.make_grid(images))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d9mXAVmRvhrq"
   },
   "source": [
    "Let's check the dimensions of a batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "cNFKWz1GZ4R5",
    "outputId": "cc1fd627-b8b0-42d4-d1a7-cd1eeaefc7fb",
    "tags": []
   },
   "outputs": [],
   "source": [
    "for images, labels in trainloader:\n",
    "    print(\"Image batch dimensions:\", images.shape)\n",
    "    print(\"Image label dimensions:\", labels.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tmaCTw5tXowR"
   },
   "source": [
    "## The Model\n",
    "Now using the classical deep learning framework pipeline, let's build the 1 convolutional layer model. \n",
    "\n",
    "Here are a few notes for those who are beginning with PyTorch:\n",
    "- The model below consists of an `__init__()` portion which is where you include the layers and components of the neural network. In our model, we have a convolutional layer denoted by `nn.Conv2d(...)`. We are dealing with an image dataset that is in a grayscale so we only need one channel going in, hence `in_channels=1`. We hope to get a nice representation of this layer, so we use `out_channels=32`. Kernel size is 3, and for the rest of parameters we use the default values which you can find [here](https://pytorch.org/docs/stable/nn.html?highlight=conv2d#conv2d). \n",
    "- We use 2 back to back dense layers or what we refer to as linear transformations to the incoming data. Notice for `d1` I have a dimension which looks like it came out of nowhere. 128 represents the size we want as output and the (`26*26*32`) represents the dimension of the incoming data. If you would like to find out how to calculate those numbers refer to the [PyTorch documentation](https://pytorch.org/docs/stable/nn.html?highlight=linear#conv2d). In short, the convolutional layer transforms the input data into a specific dimension that has to be considered in the linear layer. The same applies for the second linear transformation (`d2`) where the dimension of the output of the previous linear layer was added as `in_features=128`, and `10` is just the size of the output which also corresponds to the number of classes.\n",
    "- After each one of those layers, we also apply an activation function such as `ReLU`. For prediction purposes, we then apply a `softmax` layer to the last transformation and return the output of that.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_IYnV4ZBa3cJ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "\n",
    "        # Define the first convolutional layer\n",
    "        # Input: 28x28x1 (grayscale image)\n",
    "        # Output: 32x26x26 (after applying 3x3 kernel, with 32 filters)\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3)\n",
    "\n",
    "        # Define the first fully connected layer (dense layer)\n",
    "        # Input size is the flattened output from the convolutional layer (32 * 26 * 26)\n",
    "        # Output size is 128 (reduced dimensionality for further processing)\n",
    "        self.d1 = nn.Linear(32 * 26 * 26, 128)\n",
    "\n",
    "        # Define the second fully connected layer (output layer)\n",
    "        # Input size is 128\n",
    "        # Output size is 10 (representing 10 classes, for example, digits 0-9)\n",
    "        self.d2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Apply the convolutional layer to input x\n",
    "        # Input shape: (batch_size, 1, 28, 28)\n",
    "        # Output shape after conv1: (batch_size, 32, 26, 26)\n",
    "        x = self.conv1(x)\n",
    "        # Apply ReLU activation function for non-linearity\n",
    "        x = F.relu(x)\n",
    "\n",
    "        # Flatten the output from the convolutional layer\n",
    "        # Flatten starting from dimension 1, to preserve the batch size\n",
    "        # Input shape: (batch_size, 32, 26, 26)\n",
    "        # Output shape: (batch_size, 32 * 26 * 26)\n",
    "        x = x.flatten(start_dim=1)\n",
    "\n",
    "        # Apply the first fully connected layer\n",
    "        # Input shape: (batch_size, 32 * 26 * 26)\n",
    "        # Output shape: (batch_size, 128)\n",
    "        x = self.d1(x)\n",
    "        # Apply ReLU activation function for non-linearity\n",
    "        x = F.relu(x)\n",
    "\n",
    "        # Apply the second fully connected layer (logits layer)\n",
    "        # Input shape: (batch_size, 128)\n",
    "        # Output shape: (batch_size, 10)\n",
    "        logits = self.d2(x)\n",
    "\n",
    "        # Apply softmax activation function to get class probabilities\n",
    "        # The output shape will be (batch_size, 10), with each value representing the probability of each class\n",
    "        out = F.softmax(logits, dim=1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "1poxFYqftKov",
    "outputId": "0a845d9b-54c8-43b9-c3d6-1abc1b7a4f28",
    "tags": []
   },
   "outputs": [],
   "source": [
    "## test the model with 1 batch\n",
    "model = MyModel()\n",
    "for images, labels in trainloader:\n",
    "    print(\"batch size:\", images.shape)\n",
    "    out = model(images)\n",
    "    print(out.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9h_3eZQRHV_P"
   },
   "source": [
    "## Training the Model\n",
    "Now we are ready to train the model but before that we are going to setup a loss function, an optimizer and a function to compute accuracy of the model. \n",
    "\n",
    "As is common for classifiers, we'll train using cross-entropy loss. This is a measure of the difference between two probability distributions: the true labels ($y$) and the predicted probabilities ($\\hat{y}$). The formula for cross-entropy loss is:\n",
    "\n",
    "$$\n",
    "L(y, \\hat{y}) = -\\sum_{i=1}^{C} y_i \\log(\\hat{y}_i)\n",
    "$$\n",
    "\n",
    "where $C$ is the number of classes, $y_i$ is the true label (0 or 1), and $\\hat{y}_i$ is the predicted probability for class $i$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3_0Vjq2RHlph",
    "tags": []
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "num_epochs = 5\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = MyModel()\n",
    "model = model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "44IdrNNeIi_I",
    "tags": []
   },
   "outputs": [],
   "source": [
    "## compute accuracy\n",
    "def get_accuracy(logit, target, batch_size):\n",
    "    ''' Obtain accuracy for training round '''\n",
    "    corrects = (torch.max(logit, 1)[1].view(target.size()).data == target.data).sum()\n",
    "    accuracy = 100.0 * corrects/batch_size\n",
    "    return accuracy.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nK3EcuIOISSR"
   },
   "source": [
    "Now it's time for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "E59hwZlAIVcL",
    "outputId": "ab16b14b-8a6e-4568-8500-2f2f5b447a93",
    "tags": []
   },
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    train_running_loss = 0.0\n",
    "    train_acc = 0.0\n",
    "\n",
    "    model = model.train()\n",
    "\n",
    "    ## training step\n",
    "    for i, (images, labels) in enumerate(trainloader):\n",
    "        \n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        ## forward + backprop + loss\n",
    "        logits = model(images)\n",
    "        loss = criterion(logits, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        ## update model params\n",
    "        optimizer.step()\n",
    "\n",
    "        train_running_loss += loss.detach().item()\n",
    "        train_acc += get_accuracy(logits, labels, BATCH_SIZE)\n",
    "    \n",
    "    model.eval()\n",
    "    print('Epoch: %d | Loss: %.4f | Train Accuracy: %.2f' \\\n",
    "          %(epoch, train_running_loss / i, train_acc/i))        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QuZxfQc1UIU-"
   },
   "source": [
    "We can also compute accuracy on the testing dataset to see how well the model performs on the image classificaiton task. As you can see below, our basic CNN model is performing very well on the MNIST classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "YU5WR0BTUHv1",
    "outputId": "e0f48883-e06a-4108-a933-0f33b2e56b4f",
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_acc = 0.0\n",
    "for i, (images, labels) in enumerate(testloader, 0):\n",
    "    images = images.to(device)\n",
    "    labels = labels.to(device)\n",
    "    outputs = model(images)\n",
    "    test_acc += get_accuracy(outputs, labels, BATCH_SIZE)\n",
    "        \n",
    "print('Test Accuracy: %.2f'%( test_acc/i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uLQlqGPsVjOB"
   },
   "source": [
    "## Final Words\n",
    "That's it for this tutorial! Congratulations! You are now able to implement a basic CNN model in PyTorch for image classification. If you would like, you can further extend the CNN model by adding more convolution layers and max pooling, but as you saw, you don't really need it here as results look good. If you are interested in implementing a similar image classification model using RNNs see the references below. "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "name": "pytorch_quick_start.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Pytorch Workshop",
   "language": "python",
   "name": "pytorchworkshop"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
