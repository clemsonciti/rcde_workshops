
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Regression and Classification with Fully Connected Neural Networks &#8212; Research Computing and Data Workshop</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Datasets and data loading" href="03-datasets.html" />
    <link rel="prev" title="PyTorch Basics" href="01-pytorch_basics.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Research Computing and Data Workshop</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../index.html">
                    Research Computing and Data Workshops
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Introductory Sequence
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../intro_linux/00-index.html">
   Introduction to Linux
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../intro_linux/00a-outline.html">
     Workshop Outline
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../intro_linux/01-introduction.html">
     What is Linux?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../intro_linux/01a-shell.html">
     Shell Specifics
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../intro_linux/02-accessing-palmetto.html">
     Accessing the Palmetto Cluster
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../intro_linux/03-file-system.html">
     Navigating Files and Directories
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../intro_linux/04-working_with_files_and_directories.html">
     Working With Files and Directories
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../intro_linux/04a-file-permissions.html">
     File Permissions and Atrributes
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../intro_linux/05-pipes.html">
     Pipes and Redirection
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../intro_linux/06-find.html">
     Finding Things
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../intro_linux/07-utilities.html">
     Utilities and Useful Information
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../intro_linux/08-conclusion.html">
     Workshop Conclusion
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../intro_palmetto/00-index.html">
   Introduction to Palmetto
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../intro_palmetto/01-introduction.html">
     Introduction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../intro_palmetto/02-accessing-palmetto.html">
     Accessing the Palmetto Cluster
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../intro_palmetto/03-palmetto_structure.html">
     The structure of the Palmetto Cluster
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../intro_palmetto/04-storage.html">
     Storage on Palmetto
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../intro_palmetto/05-interactive.html">
     Running an interactive job on Palmetto
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../intro_palmetto/06-file-transfer.html">
     Transferring files to and from Palmetto
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../intro_palmetto/07-open-od.html">
     Web-based access to the Palmetto Cluster
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../intro_palmetto/08-batch.html">
     Running a batch job
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  R
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../r_programming/00-index.html">
   Introduction to R
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../r_programming/01-Introduction.html">
     Introduction to R
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../r_programming/02-Basic-R.html">
     Basics of R
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../r_programming/03-Data-Structures.html">
     Data Structures
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../r_programming/04-Matrix.html">
     Vectors, Matrices, Lists and Data Frames
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../r_programming/05-Control-Structure.html">
     Control Structure
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../r_programming/06-Functions.html">
     Functions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../r_programming/07-Parallel-Computing.html">
     Parallel Computing in R
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../r_programming/08-Basic-Plotting.html">
     Basic plotting with R
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../r_programming/09-Plotting-with-ggplot.html">
     Ploting with ggplot
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../r_programming/10-R-in-Palmetto.html">
     R in Palmetto
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../r_machine_learning/00-index.html">
   Machine Learning using R
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../r_machine_learning/01-Introduction.html">
     Introduction to Machine Learning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../r_machine_learning/02-Caret-Preprocessing.html">
     Introduction to Caret
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../r_machine_learning/03-Caret-Data-Partition.html">
     Data Partition with caret
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../r_machine_learning/04-Caret-Evaluation-Metrics.html">
     Evaluation Metrics with caret
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../r_machine_learning/05-Training_Regression.html">
     Training Machine Learning model using Regression Method
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../r_machine_learning/06-Decision_boundaries.html">
     Classification with decision boundaries
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../r_machine_learning/07-KNN.html">
     Nearest Neighbours Classification
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../r_machine_learning/08-Training_Tree.html">
     Training Machine Learning model using Tree-based model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../r_machine_learning/09-Training_Ensemble.html">
     Training Machine Learning model using Ensemble approach
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../r_machine_learning/10-Unsupervised-Learning.html">
     Unsupervised Learning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../r_machine_learning/11-Neural-Network.html">
     Neural Network
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Python
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../python_programming/00-index.html">
   Introduction to Python Programming
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
  <label for="toctree-checkbox-5">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../python_programming/01-IntroToPython-I.html">
     Introduction to Python I
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../python_programming/02-IntroToPython-II.html">
     Introduction to Python II
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../python_programming/03-IntroToPython-III.html">
     Introduction to Python III
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../python_sklearn/00-index.html">
   Machine Learning using Python
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
  <label for="toctree-checkbox-6">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../python_sklearn/01-introduction.html">
     Introduction to Machine Learning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../python_sklearn/02-sklearn-preprocessing.html">
     Introduction to Scikit Learn
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../python_sklearn/03-sklearn-Data-Partition.html">
     Data partition: training and testing
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../python_sklearn/04-sklearn-Evaluation-Metrics.html">
     Evaluation Metrics with Scikit-Learn
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../python_sklearn/05-Training-Regression.html">
     Supervised Learning training with Regression
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../python_sklearn/06-Training-Tree.html">
     Tree-based Learning Model
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../python_sklearn/07-Training-Ensemble.html">
     Ensemble-based Learning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../python_sklearn/08-Model_Based.html">
     Model-based Prediction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../python_sklearn/09-Regularization.html">
     Regularization and Variable Selection
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../python_sklearn/10-Dimension-Reduction.html">
     Dimension Reduction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../python_sklearn/11-Neural-Network.html">
     Neural Network
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../python_sklearn/12-Support-Vector-Machine.html">
     Support Vector Machine
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../python_sklearn/13-KNN.html">
     K-Nearest Neighbour
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../python_sklearn/14-Unsupervised-Learning.html">
     Unsupervised Learning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../python_sklearn/15-Mini-Project.html">
     Mini-Project
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../python_deep_learning/00-index.html">
   Deep Learning in Python
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
  <label for="toctree-checkbox-7">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../python_deep_learning/01-Introduction.html">
     Introduction to Deep Learning
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../python_deep_learning/02-Deep-Learning-Framework.html">
     Deep Learning Library Framework
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../python_deep_learning/03-Neural-Network.html">
     Recap on ANN
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../python_deep_learning/04-Intro-to-Keras.html">
     Introduction to Keras
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../python_deep_learning/05-Keras-Regression.html">
     Training Deep Learning Regression model with Keras
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../python_deep_learning/06-Keras-Classification.html">
     Training Deep Learning Classification model with Keras
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../python_deep_learning/07-Convolution-Neural-Network.html">
     Convolution Neural Network for image classification
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../python_deep_learning/08-Recurrent-neural-networks.html">
     Recurrent Neural Network for Timeseries forecasting
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Deep Learning
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="00-index.html">
   Deep Learning in Pytorch
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
  <label for="toctree-checkbox-8">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="01-pytorch_basics.html">
     PyTorch Basics
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     Regression and Classification with Fully Connected Neural Networks
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="03-datasets.html">
     Datasets and data loading
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="04-modules.html">
     Builting the network
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Advanced Palmetto Usage
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../containers/00-index.html">
   Containerization on Palmetto (under development)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/>
  <label for="toctree-checkbox-9">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../containers/01-introduction.html">
     Introduction to CloudLab
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../containers/02-dockers.html">
     Docker Containers on CloudLab
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../containers/03-apptainers.html">
     Singularity/Apptainers on Palmetto
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../advanced_scheduling/00-index.html">
   Advanced Scheduling (under development)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/>
  <label for="toctree-checkbox-10">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../advanced_scheduling/01-introduction.html">
     1. What is Spark?
    </a>
   </li>
  </ul>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<div class="menu-dropdown menu-dropdown-launch-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Launch interactive content">
      <i class="fas fa-rocket"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://mybinder.org/v2/gh/clemsonciti/rcde_workshops/master?urlpath=tree/docs/pytorch/02-regression_and_classification.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Binder"
>
  

<span class="headerbtn__icon-container">
  
    <img src="../_static/images/logo_binder.svg">
  </span>
<span class="headerbtn__text-container">Binder</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../_sources/pytorch/02-regression_and_classification.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.ipynb</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#tasks-to-solve-in-this-notebook">
   Tasks to solve in this notebook
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#regression">
     Regression
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#classification">
     Classification
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#the-simplest-deep-learning-model-linear-regression">
   The Simplest “Deep Learning” Model: Linear Regression
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#initializing-our-model">
     Initializing our model
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#anatomy-of-a-training-loop">
     Anatomy of a training loop
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#linear-classification">
   Linear classification
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#a-slight-modification-to-the-model">
     A slight modification to the model
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#training-loop">
     Training loop
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#summing-up-linear-models">
     Summing up linear models
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#getting-non-linear-with-fully-connected-neural-networks">
   Getting non-linear with fully-connected neural networks
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#a-few-helper-functions">
     A few helper functions
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id1">
     Regression
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id2">
     Classification
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#summing-up-fully-connected-neural-networks">
     Summing up fully connected neural networks
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#high-dimensional-data">
   High Dimensional Data
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#fake-high-dimensional-data">
     Fake high-dimensional data
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#splitting-into-train-test">
     Splitting into train/test
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#fitting-a-model">
     Fitting a model
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#summing-up-high-dimensional-data">
     Summing up high dimensional data
    </a>
   </li>
  </ul>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Regression and Classification with Fully Connected Neural Networks</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#tasks-to-solve-in-this-notebook">
   Tasks to solve in this notebook
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#regression">
     Regression
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#classification">
     Classification
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#the-simplest-deep-learning-model-linear-regression">
   The Simplest “Deep Learning” Model: Linear Regression
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#initializing-our-model">
     Initializing our model
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#anatomy-of-a-training-loop">
     Anatomy of a training loop
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#linear-classification">
   Linear classification
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#a-slight-modification-to-the-model">
     A slight modification to the model
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#training-loop">
     Training loop
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#summing-up-linear-models">
     Summing up linear models
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#getting-non-linear-with-fully-connected-neural-networks">
   Getting non-linear with fully-connected neural networks
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#a-few-helper-functions">
     A few helper functions
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id1">
     Regression
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id2">
     Classification
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#summing-up-fully-connected-neural-networks">
     Summing up fully connected neural networks
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#high-dimensional-data">
   High Dimensional Data
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#fake-high-dimensional-data">
     Fake high-dimensional data
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#splitting-into-train-test">
     Splitting into train/test
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#fitting-a-model">
     Fitting a model
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#summing-up-high-dimensional-data">
     Summing up high dimensional data
    </a>
   </li>
  </ul>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section class="tex2jax_ignore mathjax_ignore" id="regression-and-classification-with-fully-connected-neural-networks">
<h1>Regression and Classification with Fully Connected Neural Networks<a class="headerlink" href="#regression-and-classification-with-fully-connected-neural-networks" title="Permalink to this headline">#</a></h1>
<p>Deep learning is a large, developing field with many sub-communities, a constant stream of new developments, and unlimited application areas. Despite this complexity, most deep learning techniques share a relatively small set of algorithmic building blocks. The purpose of this notebook is to gain familiarity with some of these core concepts. Much of the intuition you develop here is applicable to the neural networks making headline news from the likes of OpenAI. To focus this notebook, we will consider the two main types of supervised machine learning:</p>
<ol class="simple">
<li><p>Regression: estimation of continuous quantities</p></li>
<li><p>Classification: estimation of categories or discrete quantities</p></li>
</ol>
<p>We will create “deep learning” models for regression and classification. We will see the power of neural networks as well as the pitfalls.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># libraries we will need</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">torch.distributions</span> <span class="kn">import</span> <span class="n">bernoulli</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="c1"># set random seeds for reproducibility</span>
<span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<section id="tasks-to-solve-in-this-notebook">
<h2>Tasks to solve in this notebook<a class="headerlink" href="#tasks-to-solve-in-this-notebook" title="Permalink to this headline">#</a></h2>
<section id="regression">
<h3>Regression<a class="headerlink" href="#regression" title="Permalink to this headline">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># make some fake regression data</span>
<span class="n">n_samples_reg</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">x_reg</span> <span class="o">=</span> <span class="mf">1.5</span><span class="o">*</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">n_samples_reg</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">y_reg</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">x_reg</span> <span class="o">+</span> <span class="mf">3.0</span><span class="o">*</span><span class="n">torch</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="mi">3</span><span class="o">*</span><span class="n">x_reg</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">+</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">n_samples_reg</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">y_reg</span> <span class="o">=</span> <span class="n">y_reg</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_reg</span><span class="p">,</span> <span class="n">y_reg</span><span class="p">,</span> <span class="s1">&#39;o&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;y&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/02-regression_and_classification_6_0.png" src="../_images/02-regression_and_classification_6_0.png" />
</div>
</div>
</section>
<section id="classification">
<h3>Classification<a class="headerlink" href="#classification" title="Permalink to this headline">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># fake classification data</span>
<span class="n">n_samples_clf</span> <span class="o">=</span> <span class="mi">200</span>
<span class="n">x_clf</span> <span class="o">=</span> <span class="mf">2.5</span><span class="o">*</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">n_samples_clf</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">d</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span> <span class="n">x_clf</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span>  <span class="n">x_clf</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span><span class="o">**</span><span class="mi">2</span> <span class="p">)</span>
<span class="n">y_clf</span> <span class="o">=</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">d</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">d</span><span class="o">&lt;</span><span class="n">torch</span><span class="o">.</span><span class="n">pi</span><span class="p">)</span>

<span class="c1"># swap some labels near the boundary</span>
<span class="n">width</span> <span class="o">=</span> <span class="mf">0.7</span>
<span class="n">pgivd</span> <span class="o">=</span> <span class="mf">0.3</span> <span class="o">*</span> <span class="n">width</span><span class="o">**</span><span class="mi">2</span> <span class="o">/</span> <span class="p">((</span><span class="n">d</span> <span class="o">-</span> <span class="n">torch</span><span class="o">.</span><span class="n">pi</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="n">width</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
<span class="n">swaps</span> <span class="o">=</span> <span class="n">bernoulli</span><span class="o">.</span><span class="n">Bernoulli</span><span class="p">(</span><span class="n">pgivd</span><span class="p">)</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span><span class="o">.</span><span class="n">type</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">bool</span><span class="p">)</span>
<span class="n">y_clf</span><span class="p">[</span><span class="n">swaps</span><span class="p">]</span> <span class="o">=</span> <span class="o">~</span><span class="n">y_clf</span><span class="p">[</span><span class="n">swaps</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_clf</span><span class="p">[</span><span class="n">y_clf</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">x_clf</span><span class="p">[</span><span class="n">y_clf</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span> <span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;positive&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_clf</span><span class="p">[</span><span class="o">~</span><span class="n">y_clf</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">x_clf</span><span class="p">[</span><span class="o">~</span><span class="n">y_clf</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span> <span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;negative&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">set_aspect</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/02-regression_and_classification_9_0.png" src="../_images/02-regression_and_classification_9_0.png" />
</div>
</div>
</section>
</section>
<section id="the-simplest-deep-learning-model-linear-regression">
<h2>The Simplest “Deep Learning” Model: Linear Regression<a class="headerlink" href="#the-simplest-deep-learning-model-linear-regression" title="Permalink to this headline">#</a></h2>
<section id="initializing-our-model">
<h3>Initializing our model<a class="headerlink" href="#initializing-our-model" title="Permalink to this headline">#</a></h3>
<p>Good old fashioned linear model: <span class="math notranslate nohighlight">\(y = wx + b\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Pytorch&#39;s `nn` module has lots of neural network building blocks</span>
<span class="c1"># nn.Linear is what we need for y=wx+b</span>
<span class="n">reg_model</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">out_features</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<hr class="docutils" />
<p><strong>Question</strong>: What do you think the arguments <code class="docutils literal notranslate"><span class="pre">in_features</span></code> and <code class="docutils literal notranslate"><span class="pre">out_features</span></code> mean? When might they not be 1?</p>
<hr class="docutils" />
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># pytorch randomly initializes the w and b</span>
<span class="n">reg_model</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="n">reg_model</span><span class="o">.</span><span class="n">bias</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(Parameter containing:
 tensor([[-0.8761]], requires_grad=True),
 Parameter containing:
 tensor([-0.5502], requires_grad=True))
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># let&#39;s look at some predictions</span>
<span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="n">y_reg_init</span> <span class="o">=</span> <span class="n">reg_model</span><span class="p">(</span><span class="n">x_reg</span><span class="p">)</span>
    
<span class="n">y_reg_init</span><span class="p">[:</span><span class="mi">5</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor([[-3.0825],
        [-2.5047],
        [-1.7339],
        [ 2.2167],
        [-1.4418]])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># plot the predictions before training the model</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_reg</span><span class="p">,</span> <span class="n">y_reg</span><span class="p">,</span> <span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Actual targets&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_reg</span><span class="p">,</span> <span class="n">y_reg_init</span><span class="p">,</span> <span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Predicted targets&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;This model sucks.</span><span class="se">\n</span><span class="s2">We better fit it.&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/02-regression_and_classification_17_0.png" src="../_images/02-regression_and_classification_17_0.png" />
</div>
</div>
</section>
<section id="anatomy-of-a-training-loop">
<h3>Anatomy of a training loop<a class="headerlink" href="#anatomy-of-a-training-loop" title="Permalink to this headline">#</a></h3>
<p>Basic idea:</p>
<ul class="simple">
<li><p>Start with random parameter values</p></li>
<li><p>Define a loss/cost/objective measure to optimize</p></li>
<li><p>Use training data to evaluate the loss</p></li>
<li><p>Update the model to reduce the loss (use gradient descent)</p></li>
<li><p>Repeat until converged</p></li>
</ul>
<p>Basic weight update formula:
<span class="math notranslate nohighlight">\(
w_{i+1} = w_i - \mathrm{lr}\times \left.\frac{\partial L}{\partial w}\right|_{w=w_i}
\)</span></p>
<hr class="docutils" />
<p><strong>Question</strong>: Why the minus sign in front of the second term?</p>
<hr class="docutils" />
<img src="https://github.com/clemsonciti/rcde_workshops/raw/master/pytorch/fig_grad_descent.png" alt="grad descent" width="500"/>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># re-initialize our model each time we run this cell</span>
<span class="c1"># otherwise the model picks up from where it left off</span>
<span class="n">reg_model</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">out_features</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>

<span class="c1"># the torch `optim` module helps us fit models</span>
<span class="kn">import</span> <span class="nn">torch.optim</span> <span class="k">as</span> <span class="nn">optim</span>

<span class="c1"># create our optimizer object and tell it about the parameters in our model</span>
<span class="c1"># the optimizer will be responsible for updating these parameters during training</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">reg_model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>

<span class="c1"># how many times to update the model based on the available data</span>
<span class="n">num_epochs</span> <span class="o">=</span> <span class="mi">100</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>
    <span class="c1"># make sure gradients are set to zero on all parameters</span>
    <span class="c1"># by default, gradients accumulate</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
    
    <span class="c1"># &quot;forward pass&quot;</span>
    <span class="n">y_hat</span> <span class="o">=</span> <span class="n">reg_model</span><span class="p">(</span><span class="n">x_reg</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>
    
    <span class="c1"># measure the loss</span>
    <span class="c1"># this is the mean squared error</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">((</span><span class="n">y_hat</span> <span class="o">-</span> <span class="n">y_reg</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
    <span class="c1"># can use pytorch built-in: https://pytorch.org/docs/stable/generated/torch.nn.functional.mse_loss.html</span>
    
    <span class="c1"># &quot;backward pass&quot;</span>
    <span class="c1"># that is, compute gradient of loss wrt all parameters</span>
    <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
    
    <span class="c1"># parameter updates</span>
    <span class="c1"># use the basic weight update formula given above (with slight modifications)</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
    
    <span class="k">if</span> <span class="n">i</span> <span class="o">%</span> <span class="mi">20</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Epoch </span><span class="si">{</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">. MSE Loss = </span><span class="si">{</span><span class="n">loss</span><span class="si">:</span><span class="s2">0.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="n">y_reg_init</span> <span class="o">=</span> <span class="n">reg_model</span><span class="p">(</span><span class="n">x_reg</span><span class="p">)</span>
        
        <span class="n">ix</span> <span class="o">=</span> <span class="n">x_reg</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_reg</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()[</span><span class="n">ix</span><span class="p">],</span> <span class="n">y_reg_init</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()[</span><span class="n">ix</span><span class="p">],</span> <span class="s1">&#39;-&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="n">i</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>


<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_reg</span><span class="p">,</span> <span class="n">y_reg</span><span class="p">,</span> <span class="s1">&#39;ok&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Actual data&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="s1">&#39;Epoch&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1. MSE Loss = 24.350
Epoch 21. MSE Loss = 9.776
Epoch 41. MSE Loss = 7.300
Epoch 61. MSE Loss = 6.871
Epoch 81. MSE Loss = 6.793
</pre></div>
</div>
<img alt="../_images/02-regression_and_classification_20_1.png" src="../_images/02-regression_and_classification_20_1.png" />
</div>
</div>
<hr class="docutils" />
<p><strong>Question</strong>: What shortcomings does this model have?</p>
<hr class="docutils" />
<hr class="docutils" />
<p>🔥<strong>IMPORTANT CONCEPT</strong>🔥 Model bias is a type of error that occurs when your model doesn’t have enough flexibility to represent the real-world data!</p>
</section>
</section>
<hr class="docutils" />
<section id="linear-classification">
<h2>Linear classification<a class="headerlink" href="#linear-classification" title="Permalink to this headline">#</a></h2>
<section id="a-slight-modification-to-the-model">
<h3>A slight modification to the model<a class="headerlink" href="#a-slight-modification-to-the-model" title="Permalink to this headline">#</a></h3>
<p>We need to modify our model because the outputs are true/false</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">y_clf</span><span class="o">.</span><span class="n">unique</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor([False,  True])
</pre></div>
</div>
</div>
</div>
<p>While training the model, we cannot simply threshold the model outputs (e.g. call outputs greater than 0 ‘True’). Instead, we can have our model output a continuous number between 0 and 1. Use sigmoid to transform the output of a linear model to the range (0,1):
$<span class="math notranslate nohighlight">\(
p(y=1 | \vec{x}) = \mathrm{sigmoid}(\vec w \cdot \vec x + b)
\)</span>$</p>
<hr class="docutils" />
<p><strong>Question</strong>: Why doesn’t thresholding work while training?</p>
<hr class="docutils" />
<hr class="docutils" />
<p>🔥<strong>IMPORTANT CONCEPT</strong>🔥 In order to use gradient descent, neural networks must be differentiable.</p>
<hr class="docutils" />
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># what is sigmoid?</span>
<span class="n">x_plt</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">10</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="n">y_plt</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">x_plt</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_plt</span><span class="p">,</span> <span class="n">y_plt</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;input&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;output&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">gcf</span><span class="p">()</span><span class="o">.</span><span class="n">set_size_inches</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="mf">2.5</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Sigmoid Function&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/02-regression_and_classification_30_0.png" src="../_images/02-regression_and_classification_30_0.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># proposed new model for classification</span>
<span class="c1"># use nn.Sequential to string operations together</span>
<span class="n">model_clf</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="c1"># notice: we now have two inputs</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">()</span>  <span class="c1"># sigmoid squishes real numbers into (0, 1)</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># what do the outputs look like?</span>
<span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">model_clf</span><span class="p">(</span><span class="n">x_clf</span><span class="p">)[:</span><span class="mi">10</span><span class="p">])</span>
<span class="c1"># notice how they all lie between 0 and 1</span>
    
<span class="c1"># we loosely interpret these numbers as</span>
<span class="c1"># &quot;the probability that y=1 given the provided value of x&quot;</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor([[0.6701],
        [0.8487],
        [0.7813],
        [0.4899],
        [0.8440],
        [0.2253],
        [0.3412],
        [0.4453],
        [0.4484],
        [0.5387]])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># turning probabilities into &quot;decisions&quot;</span>
<span class="c1"># apply a threshold</span>
<span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">model_clf</span><span class="p">(</span><span class="n">x_clf</span><span class="p">)[:</span><span class="mi">10</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mf">0.5</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor([[ True],
        [ True],
        [ True],
        [False],
        [ True],
        [False],
        [False],
        [False],
        [False],
        [ True]])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># let&#39;s see how this model does before any training</span>

<span class="c1"># Code to plot the decision regions</span>
<span class="n">x_clf</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span> <span class="n">x_clf</span><span class="o">.</span><span class="n">max</span><span class="p">()</span>
<span class="n">xx</span><span class="p">,</span> <span class="n">yy</span> <span class="o">=</span> <span class="n">mg</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">x_clf</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span> <span class="n">x_clf</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">(),</span> <span class="mi">100</span><span class="p">),</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">x_clf</span><span class="p">[:,</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span> <span class="n">x_clf</span><span class="p">[:,</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">(),</span> <span class="mi">100</span><span class="p">)</span>
<span class="p">)</span>
<span class="n">grid_pts</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">vstack</span><span class="p">([</span><span class="n">xx</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span> <span class="n">yy</span><span class="o">.</span><span class="n">ravel</span><span class="p">()])</span><span class="o">.</span><span class="n">T</span>

<span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="c1"># use a 0.5 decision threshold</span>
    <span class="n">grid_preds</span> <span class="o">=</span> <span class="n">model_clf</span><span class="p">(</span><span class="n">grid_pts</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span><span class="o">&gt;</span><span class="mf">0.5</span>

<span class="n">grid_preds</span> <span class="o">=</span> <span class="n">grid_preds</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">xx</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">gcf</span><span class="p">()</span><span class="o">.</span><span class="n">set_size_inches</span><span class="p">(</span><span class="mi">7</span><span class="p">,</span><span class="mi">7</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_clf</span><span class="p">[</span><span class="n">y_clf</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">x_clf</span><span class="p">[</span><span class="n">y_clf</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span> <span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;positive&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_clf</span><span class="p">[</span><span class="o">~</span><span class="n">y_clf</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">x_clf</span><span class="p">[</span><span class="o">~</span><span class="n">y_clf</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span> <span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;negative&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">set_aspect</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">contourf</span><span class="p">(</span><span class="n">xx</span><span class="p">,</span> <span class="n">yy</span><span class="p">,</span> <span class="n">grid_preds</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">RdBu</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.4</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Decision boundary is not good&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/software/spackages/linux-rocky8-x86_64/gcc-9.5.0/anaconda3-2022.05-zyrazrj6uvrtukupqzhaslr63w7hj6in/envs/pytorch_workshop/lib/python3.10/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/conda/conda-bld/pytorch_1678411187366/work/aten/src/ATen/native/TensorShape.cpp:3483.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
</pre></div>
</div>
<img alt="../_images/02-regression_and_classification_34_1.png" src="../_images/02-regression_and_classification_34_1.png" />
</div>
</div>
</section>
<section id="training-loop">
<h3>Training loop<a class="headerlink" href="#training-loop" title="Permalink to this headline">#</a></h3>
<p>The main difference between regression and classification is the loss function. For regression, we used mean squared error. For classification, we will use cross-entropy loss. This loss formula encourages the model to output low values for <span class="math notranslate nohighlight">\(p(y=1|x)\)</span> when the class is 0 and high values when the class is 1.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># re-initialize our model each time we run this cell</span>
<span class="c1"># otherwise the model picks up from where it left off</span>
<span class="n">model_clf</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">()</span>
<span class="p">)</span>

<span class="c1"># create our optimizer object and tell it about the parameters in our model</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">model_clf</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>

<span class="c1"># torch needs the class labels to be zeros and ones, not False/True</span>
<span class="n">y_clf_int</span> <span class="o">=</span> <span class="n">y_clf</span><span class="o">.</span><span class="n">type</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">int16</span><span class="p">)</span>

<span class="c1"># how many times to update the model based on the available data</span>
<span class="n">num_epochs</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
    
    <span class="n">y_hat</span> <span class="o">=</span> <span class="n">model_clf</span><span class="p">(</span><span class="n">x_clf</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>
    
    <span class="c1"># measure the goodness of fit</span>
    <span class="c1"># need to use a different loss function here</span>
    <span class="c1"># this is the &quot;cross entropy loss&quot;</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="o">-</span><span class="n">y_clf_int</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">y_hat</span><span class="p">)</span> <span class="o">-</span> <span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">y_clf_int</span><span class="p">)</span><span class="o">*</span><span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">y_hat</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">loss</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
    <span class="c1"># pytorch built-in: https://pytorch.org/docs/stable/generated/torch.nn.functional.binary_cross_entropy.html</span>
    
    <span class="c1"># update the model</span>
    <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span> <span class="c1"># gradient computation</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>  <span class="c1"># weight updates</span>
    
    <span class="k">if</span> <span class="n">i</span> <span class="o">%</span> <span class="mi">100</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Epoch </span><span class="si">{</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">. MSE Loss = </span><span class="si">{</span><span class="n">loss</span><span class="si">:</span><span class="s2">0.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1. MSE Loss = 0.959
Epoch 101. MSE Loss = 0.774
Epoch 201. MSE Loss = 0.727
Epoch 301. MSE Loss = 0.705
Epoch 401. MSE Loss = 0.691
Epoch 501. MSE Loss = 0.683
Epoch 601. MSE Loss = 0.678
Epoch 701. MSE Loss = 0.675
Epoch 801. MSE Loss = 0.673
Epoch 901. MSE Loss = 0.672
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="c1"># use a 0.5 decision threshold</span>
    <span class="n">grid_preds</span> <span class="o">=</span> <span class="n">model_clf</span><span class="p">(</span><span class="n">grid_pts</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span><span class="o">&gt;</span><span class="mf">0.5</span>

<span class="n">grid_preds</span> <span class="o">=</span> <span class="n">grid_preds</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">xx</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">gcf</span><span class="p">()</span><span class="o">.</span><span class="n">set_size_inches</span><span class="p">(</span><span class="mi">7</span><span class="p">,</span><span class="mi">7</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_clf</span><span class="p">[</span><span class="n">y_clf</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">x_clf</span><span class="p">[</span><span class="n">y_clf</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span> <span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;positive&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_clf</span><span class="p">[</span><span class="o">~</span><span class="n">y_clf</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">x_clf</span><span class="p">[</span><span class="o">~</span><span class="n">y_clf</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span> <span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;negative&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">set_aspect</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">contourf</span><span class="p">(</span><span class="n">xx</span><span class="p">,</span> <span class="n">yy</span><span class="p">,</span> <span class="n">grid_preds</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">RdBu</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.4</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Decision boundary is still not good&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/02-regression_and_classification_38_0.png" src="../_images/02-regression_and_classification_38_0.png" />
</div>
</div>
<hr class="docutils" />
<p><strong>Question</strong>: Why did this experiment fail? Any ideas what we could do to make it work?</p>
</section>
<hr class="docutils" />
<section id="summing-up-linear-models">
<h3>Summing up linear models<a class="headerlink" href="#summing-up-linear-models" title="Permalink to this headline">#</a></h3>
<p>Sometimes linear models can be a good approximation to our data. Sometimes not.</p>
<p>Linear models tend to be <em>biased</em> in the statistical sense of the word. That is, they enforce linearity in the form of linear regression lines or linear decision boundaries. The linear model will fail to the degree that the real-world data is non-linear.</p>
</section>
</section>
<section id="getting-non-linear-with-fully-connected-neural-networks">
<h2>Getting non-linear with fully-connected neural networks<a class="headerlink" href="#getting-non-linear-with-fully-connected-neural-networks" title="Permalink to this headline">#</a></h2>
<p>We can compose simple math operations together to represent very complex functions.</p>
<img src="https://github.com/clemsonciti/rcde_workshops/raw/master/pytorch/fig_ann.png" alt="grad descent" width="500"/><section id="a-few-helper-functions">
<h3>A few helper functions<a class="headerlink" href="#a-few-helper-functions" title="Permalink to this headline">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">train_and_test_regression_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">num_epochs</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">reporting_interval</span><span class="o">=</span><span class="mi">100</span><span class="p">):</span>

    <span class="c1"># create our optimizer object and tell it about the parameters in our model</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>

    <span class="c1"># how many times to update the model based on the available data</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

        <span class="n">y_hat</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x_reg</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>

        <span class="c1"># measure the goodness of fit</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">((</span><span class="n">y_hat</span> <span class="o">-</span> <span class="n">y_reg</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>

        <span class="c1"># update the model</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span> <span class="c1"># gradient computation</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>  <span class="c1"># weight updates</span>

        <span class="k">if</span> <span class="n">i</span> <span class="o">%</span> <span class="n">reporting_interval</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Epoch </span><span class="si">{</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">. MSE Loss = </span><span class="si">{</span><span class="n">loss</span><span class="si">:</span><span class="s2">0.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="n">y_reg_init</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x_reg</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_reg</span><span class="o">.</span><span class="n">cpu</span><span class="p">(),</span> <span class="n">y_reg</span><span class="o">.</span><span class="n">cpu</span><span class="p">(),</span> <span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Actual targets&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_reg</span><span class="o">.</span><span class="n">cpu</span><span class="p">(),</span> <span class="n">y_reg_init</span><span class="o">.</span><span class="n">cpu</span><span class="p">(),</span> <span class="s1">&#39;x&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Predicted targets&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">train_and_test_classification_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">num_epochs</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">reporting_interval</span><span class="o">=</span><span class="mi">100</span><span class="p">):</span>

    <span class="c1"># create our optimizer object and tell it about the parameters in our model</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>

    <span class="c1"># how many times to update the model based on the available data</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

        <span class="n">y_hat</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x_clf</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>

        <span class="c1"># measure the goodness of fit</span>
        <span class="c1"># need to use a different loss function here</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="o">-</span><span class="n">y_clf_int</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">y_hat</span><span class="p">)</span> <span class="o">-</span> <span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">y_clf_int</span><span class="p">)</span><span class="o">*</span><span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">y_hat</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">loss</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>

        <span class="c1"># update the model</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span> <span class="c1"># gradient computation</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>  <span class="c1"># weight updates</span>
    
        <span class="k">if</span> <span class="n">i</span> <span class="o">%</span> <span class="n">reporting_interval</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Epoch </span><span class="si">{</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">. MSE Loss = </span><span class="si">{</span><span class="n">loss</span><span class="si">:</span><span class="s2">0.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>   
            
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="n">grid_preds</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">grid_pts</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span><span class="o">&gt;</span><span class="mf">0.5</span>

    <span class="n">grid_preds</span> <span class="o">=</span> <span class="n">grid_preds</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">xx</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">gcf</span><span class="p">()</span><span class="o">.</span><span class="n">set_size_inches</span><span class="p">(</span><span class="mi">7</span><span class="p">,</span><span class="mi">7</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_clf</span><span class="p">[</span><span class="n">y_clf</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">x_clf</span><span class="p">[</span><span class="n">y_clf</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span> <span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;positive&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_clf</span><span class="p">[</span><span class="o">~</span><span class="n">y_clf</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">x_clf</span><span class="p">[</span><span class="o">~</span><span class="n">y_clf</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span> <span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;negative&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span><span class="o">.</span><span class="n">set_aspect</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">contourf</span><span class="p">(</span><span class="n">xx</span><span class="p">,</span> <span class="n">yy</span><span class="p">,</span> <span class="n">grid_preds</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">RdBu</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.4</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="id1">
<h3>Regression<a class="headerlink" href="#id1" title="Permalink to this headline">#</a></h3>
<p>What about nested linear models? Might this do something interesting?
$<span class="math notranslate nohighlight">\(
y = w_1(w_0 x + b_0) + b_1
\)</span>$</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># We can build more complex models by stringing together more operations inside nn.Sequential:</span>
<span class="n">model</span> <span class="o">=</span>  <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">out_features</span> <span class="o">=</span> <span class="mi">1</span><span class="p">),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
<span class="p">)</span>

<span class="n">train_and_test_regression_model</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;But wait, that&#39;s still just a line?!&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1. MSE Loss = 16.093
Epoch 101. MSE Loss = 6.771
Epoch 201. MSE Loss = 6.771
Epoch 301. MSE Loss = 6.771
Epoch 401. MSE Loss = 6.771
Epoch 501. MSE Loss = 6.771
Epoch 601. MSE Loss = 6.771
Epoch 701. MSE Loss = 6.771
Epoch 801. MSE Loss = 6.771
Epoch 901. MSE Loss = 6.771
</pre></div>
</div>
<img alt="../_images/02-regression_and_classification_49_1.png" src="../_images/02-regression_and_classification_49_1.png" />
</div>
</div>
<hr class="docutils" />
<p><strong>Question</strong>: Why is it still just a line? How can we fix it?</p>
<hr class="docutils" />
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># We need a non-linearity between the two linear operations</span>
<span class="n">model</span> <span class="o">=</span>  <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">out_features</span> <span class="o">=</span> <span class="mi">1</span><span class="p">),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Tanh</span><span class="p">(),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
<span class="p">)</span>
<span class="c1"># this model does not reduce to a linear operation</span>

<span class="n">train_and_test_regression_model</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Non-linearity! But not enough.&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1. MSE Loss = 15.631
Epoch 101. MSE Loss = 7.572
Epoch 201. MSE Loss = 7.014
Epoch 301. MSE Loss = 6.965
Epoch 401. MSE Loss = 6.940
Epoch 501. MSE Loss = 6.922
Epoch 601. MSE Loss = 6.907
Epoch 701. MSE Loss = 6.896
Epoch 801. MSE Loss = 6.887
Epoch 901. MSE Loss = 6.880
</pre></div>
</div>
<img alt="../_images/02-regression_and_classification_51_1.png" src="../_images/02-regression_and_classification_51_1.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Let&#39;s really crank up the number of hidden nodes</span>
<span class="n">model</span> <span class="o">=</span>  <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">out_features</span> <span class="o">=</span> <span class="mi">30</span><span class="p">),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Tanh</span><span class="p">(),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">30</span><span class="p">,</span><span class="mi">30</span><span class="p">),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Tanh</span><span class="p">(),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">30</span><span class="p">,</span><span class="mi">30</span><span class="p">),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Tanh</span><span class="p">(),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">30</span><span class="p">,</span><span class="mi">30</span><span class="p">),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Tanh</span><span class="p">(),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">30</span><span class="p">,</span><span class="mi">30</span><span class="p">),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Tanh</span><span class="p">(),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">30</span><span class="p">,</span><span class="mi">30</span><span class="p">),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Tanh</span><span class="p">(),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">30</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
<span class="p">)</span>

<span class="n">train_and_test_regression_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">num_epochs</span><span class="o">=</span><span class="mi">50000</span><span class="p">,</span> <span class="n">reporting_interval</span><span class="o">=</span><span class="mi">5000</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1. MSE Loss = 17.355
Epoch 5001. MSE Loss = 2.108
Epoch 10001. MSE Loss = 1.754
Epoch 15001. MSE Loss = 1.412
Epoch 20001. MSE Loss = 1.390
Epoch 25001. MSE Loss = 1.473
Epoch 30001. MSE Loss = 0.707
Epoch 35001. MSE Loss = 0.664
Epoch 40001. MSE Loss = 0.695
Epoch 45001. MSE Loss = 1.219
</pre></div>
</div>
<img alt="../_images/02-regression_and_classification_52_1.png" src="../_images/02-regression_and_classification_52_1.png" />
</div>
</div>
<hr class="docutils" />
<p><strong>Question</strong>: What is wrong with this picture?</p>
<hr class="docutils" />
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="n">x_grid</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">x_reg</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span> <span class="n">x_reg</span><span class="o">.</span><span class="n">max</span><span class="p">(),</span> <span class="mi">200</span><span class="p">)[:,</span><span class="kc">None</span><span class="p">]</span>
    <span class="n">y_reg_grid</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x_grid</span><span class="p">)</span>
    <span class="n">y_reg_init</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x_reg</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_reg</span><span class="o">.</span><span class="n">cpu</span><span class="p">(),</span> <span class="n">y_reg</span><span class="o">.</span><span class="n">cpu</span><span class="p">(),</span> <span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Actual targets&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_reg</span><span class="o">.</span><span class="n">cpu</span><span class="p">(),</span> <span class="n">y_reg_init</span><span class="o">.</span><span class="n">cpu</span><span class="p">(),</span> <span class="s1">&#39;x&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Predicted targets&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_grid</span><span class="o">.</span><span class="n">cpu</span><span class="p">(),</span> <span class="n">y_reg_grid</span><span class="o">.</span><span class="n">cpu</span><span class="p">(),</span> <span class="s1">&#39;k-&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Predicted&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;matplotlib.legend.Legend at 0x1454620c0370&gt;
</pre></div>
</div>
<img alt="../_images/02-regression_and_classification_54_1.png" src="../_images/02-regression_and_classification_54_1.png" />
</div>
</div>
<hr class="docutils" />
<p><strong>Question</strong>: Where is overfitting most severe? How might having more data alleviate the problem?</p>
<hr class="docutils" />
<hr class="docutils" />
<p>🔥<strong>IMPORTANT CONCEPT</strong>🔥 Overfitting is a type of error that occurs when your model memorizes the training samples and fails to generalize to unseen data. This usually ocurrs when the model has excess capacity.</p>
<hr class="docutils" />
<hr class="docutils" />
<p>😅<strong>EXCERCISE</strong>😅 Using the code cell below, design and test a model that gets it “just right”.</p>
<hr class="docutils" />
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#model = your model goes here</span>

<span class="c1"># train_and_test_regression_model(model, num_epochs=10000, reporting_interval=1000)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="id2">
<h3>Classification<a class="headerlink" href="#id2" title="Permalink to this headline">#</a></h3>
<p>Let’s apply the same non-linear treatment to the case of classification.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span>  <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span> <span class="n">out_features</span> <span class="o">=</span> <span class="mi">2</span><span class="p">),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Tanh</span><span class="p">(),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">()</span>
<span class="p">)</span>

<span class="n">train_and_test_classification_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="mi">10000</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Not non-linear enough&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1. MSE Loss = 0.748
Epoch 1001. MSE Loss = 0.674
Epoch 2001. MSE Loss = 0.665
Epoch 3001. MSE Loss = 0.640
Epoch 4001. MSE Loss = 0.589
Epoch 5001. MSE Loss = 0.548
Epoch 6001. MSE Loss = 0.522
Epoch 7001. MSE Loss = 0.507
Epoch 8001. MSE Loss = 0.497
Epoch 9001. MSE Loss = 0.492
</pre></div>
</div>
<img alt="../_images/02-regression_and_classification_61_1.png" src="../_images/02-regression_and_classification_61_1.png" />
</div>
</div>
<hr class="docutils" />
<p><strong>Question</strong>: What would overfitting look like in this type of graph?</p>
<hr class="docutils" />
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span>  <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span> <span class="n">out_features</span> <span class="o">=</span> <span class="mi">50</span><span class="p">),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Tanh</span><span class="p">(),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">50</span><span class="p">,</span><span class="mi">50</span><span class="p">),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Tanh</span><span class="p">(),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">50</span><span class="p">,</span><span class="mi">50</span><span class="p">),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Tanh</span><span class="p">(),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">50</span><span class="p">,</span><span class="mi">50</span><span class="p">),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Tanh</span><span class="p">(),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">50</span><span class="p">,</span><span class="mi">50</span><span class="p">),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Tanh</span><span class="p">(),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">50</span><span class="p">,</span><span class="mi">50</span><span class="p">),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Tanh</span><span class="p">(),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">50</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">()</span>
<span class="p">)</span>

<span class="n">train_and_test_classification_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="mi">30000</span><span class="p">,</span> <span class="mi">3000</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;What went wrong here?&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 1. MSE Loss = 0.697
Epoch 3001. MSE Loss = 0.276
Epoch 6001. MSE Loss = 0.251
Epoch 9001. MSE Loss = 0.236
Epoch 12001. MSE Loss = 0.221
Epoch 15001. MSE Loss = 0.211
Epoch 18001. MSE Loss = 0.189
Epoch 21001. MSE Loss = 0.171
Epoch 24001. MSE Loss = 0.151
Epoch 27001. MSE Loss = 0.136
</pre></div>
</div>
<img alt="../_images/02-regression_and_classification_63_1.png" src="../_images/02-regression_and_classification_63_1.png" />
</div>
</div>
<hr class="docutils" />
<p><strong>Question</strong>: What’s wrong with this picture?</p>
<hr class="docutils" />
<hr class="docutils" />
<p>😅<strong>EXCERCISE</strong>😅 Using the code cell below, design and test a model that gets it “just right”.</p>
<hr class="docutils" />
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#model = your model goes here</span>

<span class="c1"># train_and_test_classification_model(model, 20000, 2000)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="summing-up-fully-connected-neural-networks">
<h3>Summing up fully connected neural networks<a class="headerlink" href="#summing-up-fully-connected-neural-networks" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>Fully connected neural networks can represent highly non-linear functions</p></li>
<li><p>We can learn good functions through gradient descent</p></li>
<li><p>Overfitting is a big problem</p></li>
</ul>
<p>These concepts apply to nearly any neural network trained with gradient descent from the smallest fully connected net to GPT-4.</p>
</section>
</section>
<section id="high-dimensional-data">
<h2>High Dimensional Data<a class="headerlink" href="#high-dimensional-data" title="Permalink to this headline">#</a></h2>
<p>For high-dimensional data, it is not possible to get a dense sampling of the data space. Consider the following analogy. Imagine we are measuring the temperatures of spaces with growing numbers of dimensions. We have sensors that measure reliably within a “volume” 1mm in extent. Outside of that volume, the temperature may change, so we need lots of sensors to map the temperature through the space.</p>
<ul class="simple">
<li><p>1D space: The total space is 1 m. You are given 100 sensors; each 1mm extent. The most you could fill up is 1/10th of the space</p></li>
<li><p>2D space: The total space is 1 m^2. You are given 100 sensors; each 1mm^2. The most you could fill up is 100mm^2 / (1000 mm)^2 = 1/10000th of the space. To cover 1/10th of the space, you would need 100,000 sensors!</p></li>
<li><p>3D space: The total space is 1 m^3. You are given 100 sensors; each 1mm^3. The most you could fill up is 100 mm^3 / (1000 mm)^3 = 1/10^7th of the space. To cover 1/10th of the space, you would need 100,000,000 sensors!</p></li>
</ul>
<p>You see where this is going. This is called THE CURSE OF DIMENSIONALITY.</p>
<p>In deep learning, we often work in data spaces with hundreds or thousands of dimensions, so… are we out of luck?</p>
<hr class="docutils" />
<p>🔥<strong>IMPORTANT CONCEPT</strong>🔥 The CURSE OF DIMENSIONALITY refers to the fact that in high dimensional space, it is impossible to get dense coverage of the data space.</p>
<hr class="docutils" />
<hr class="docutils" />
<p><strong>Question</strong>: Think back to the overfit regression model above. How might the curse of dimensionality make the overfitting problem worse? Why are deep neural networks especially problematic in this regard?</p>
<hr class="docutils" />
<hr class="docutils" />
<p><strong>Question</strong>: How might THE CURSE OF DIMENSIONALITY pose a problem for real-world tasks like computer vision for autonomous driving?</p>
<hr class="docutils" />
<section id="fake-high-dimensional-data">
<h3>Fake high-dimensional data<a class="headerlink" href="#fake-high-dimensional-data" title="Permalink to this headline">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># set random seeds for reproducibility</span>
<span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># this dataset is a lot bigger, so we&#39;re going to switch over to gpu</span>
<span class="c1"># pytorch makes this easy</span>
<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">&#39;cuda&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># make some non-linear, fake data</span>
<span class="n">n_samples</span> <span class="o">=</span> <span class="mi">100000</span>
<span class="n">n_test</span> <span class="o">=</span> <span class="mi">20000</span>
<span class="n">n_dims</span> <span class="o">=</span> <span class="mi">1000</span>

<span class="n">w1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">n_dims</span><span class="p">,</span> <span class="mi">128</span><span class="p">)</span>
<span class="n">w2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">128</span><span class="p">)</span>
<span class="n">b1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">128</span><span class="p">)</span>
<span class="n">b2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">noise</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">n_samples</span><span class="p">)</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">n_samples</span><span class="p">,</span> <span class="n">n_dims</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">X</span> <span class="o">@</span> <span class="n">w1</span> <span class="o">+</span> <span class="n">b1</span><span class="p">)</span> <span class="o">@</span> <span class="n">w2</span> <span class="o">+</span> <span class="n">b2</span> <span class="o">+</span> <span class="n">noise</span>

<span class="c1"># move to gpu:</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

<span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">y</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(torch.Size([100000, 1000]), torch.Size([100000]))
</pre></div>
</div>
</div>
</div>
</section>
<section id="splitting-into-train-test">
<h3>Splitting into train/test<a class="headerlink" href="#splitting-into-train-test" title="Permalink to this headline">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># train/test split</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:</span><span class="o">-</span><span class="n">n_test</span><span class="p">],</span> <span class="n">X</span><span class="p">[</span><span class="o">-</span><span class="n">n_test</span><span class="p">:]</span>
<span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">y</span><span class="p">[:</span><span class="o">-</span><span class="n">n_test</span><span class="p">],</span> <span class="n">y</span><span class="p">[</span><span class="o">-</span><span class="n">n_test</span><span class="p">:]</span>

<span class="p">(</span><span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">y_train</span><span class="o">.</span><span class="n">shape</span><span class="p">),</span> <span class="p">(</span><span class="n">X_test</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">y_test</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>((torch.Size([80000, 1000]), torch.Size([80000])),
 (torch.Size([20000, 1000]), torch.Size([20000])))
</pre></div>
</div>
</div>
</div>
</section>
<section id="fitting-a-model">
<h3>Fitting a model<a class="headerlink" href="#fitting-a-model" title="Permalink to this headline">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># helper function for training/evaluation</span>
<span class="k">def</span> <span class="nf">train_and_test_highdim</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">num_epochs</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">reporting_interval</span><span class="o">=</span><span class="mi">100</span><span class="p">):</span>

    <span class="c1"># create our optimizer object and tell it about the parameters in our model</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.001</span><span class="p">)</span>

    <span class="c1"># how many times to update the model based on the available data</span>
    <span class="n">epoch_ls</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">train_losses</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">test_losses</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

        <span class="n">y_hat</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">((</span><span class="n">y_hat</span> <span class="o">-</span> <span class="n">y_train</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>

        <span class="c1"># update the model</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span> <span class="c1"># gradient computation</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>  <span class="c1"># weight updates</span>

        <span class="k">if</span> <span class="n">i</span> <span class="o">%</span> <span class="n">reporting_interval</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            
            <span class="c1"># Evaluate on test data</span>
            <span class="c1"># turn off gradient tracking for this step:</span>
            <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
                <span class="n">y_hat</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>
                <span class="n">test_loss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">((</span><span class="n">y_hat</span> <span class="o">-</span> <span class="n">y_test</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
                
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Epoch </span><span class="si">{</span><span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">zfill</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="s1">&#39;</span><span class="se">\r</span><span class="s1">&#39;</span><span class="p">)</span>
            
            <span class="n">epoch_ls</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
            <span class="n">train_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
            <span class="n">test_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">test_loss</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
            
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epoch_ls</span><span class="p">,</span> <span class="n">train_losses</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;train&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">epoch_ls</span><span class="p">,</span> <span class="n">test_losses</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;test&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Epoch&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;MSE Loss&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># This architecture is intentionally designed to overfit</span>
<span class="n">model</span> <span class="o">=</span>  <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span> <span class="o">=</span> <span class="n">n_dims</span><span class="p">,</span> <span class="n">out_features</span> <span class="o">=</span> <span class="mi">128</span><span class="p">),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Tanh</span><span class="p">(),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span><span class="mi">128</span><span class="p">),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Tanh</span><span class="p">(),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span><span class="mi">64</span><span class="p">),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Tanh</span><span class="p">(),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span><span class="mi">50</span><span class="p">),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Tanh</span><span class="p">(),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">50</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
<span class="p">)</span>

<span class="c1"># move model to gpu:</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

<span class="n">train_and_test_highdim</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="mi">2000</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch 02000
</pre></div>
</div>
<img alt="../_images/02-regression_and_classification_81_1.png" src="../_images/02-regression_and_classification_81_1.png" />
</div>
</div>
<hr class="docutils" />
<p><strong>Question</strong>: Why does the plot look like that?</p>
<hr class="docutils" />
<hr class="docutils" />
<p><strong>Question</strong>: Does this plot suggest a way that we could mitigate overfitting?</p>
<hr class="docutils" />
<hr class="docutils" />
<p>😅<strong>EXCERCISE</strong>😅 Using the code cell below, designed and test a biased model. How do the training curves differ?</p>
<hr class="docutils" />
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#model = your biased model goes here</span>

<span class="c1">#model = model.to(device)</span>

<span class="c1"># train_and_test_highdim(model, 2000, 1)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="summing-up-high-dimensional-data">
<h3>Summing up high dimensional data<a class="headerlink" href="#summing-up-high-dimensional-data" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>Overfitting problems become much worse for high-dimensional data due to the curse of dimensionality</p></li>
<li><p>To test for overfitting, it is critical to evaluate your model on different data than you used to train your model</p></li>
<li><p>Much of the technical progress in deep learning over the last decade can be viewed as better ways to prevent overfitting.</p></li>
</ul>
<p>The significance of the challenge of overfitting for deep learning cannot be overstated!</p>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./pytorch"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="01-pytorch_basics.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">PyTorch Basics</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="03-datasets.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Datasets and data loading</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Linh Ngo<br/>
  
    <div class="extra_footer">
      <a rel="license" href="http://creativecommons.org/licenses/by-nc/4.0/"></a> <span xmlns:dct="http://purl.org/dc/terms/" property="dct:title">Research Computing and Data Workshops</span> is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-nc/4.0/">Creative Commons Attribution-NonCommercial 4.0 International License</a>.
    </div>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>