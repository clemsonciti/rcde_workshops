{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-node Parallelism and Dask\n",
    "\n",
    "### Concepts of Multi-node Jobs and Distributed Computing\n",
    "- **Multi-node parallelism**: When a single job uses multiple nodes, it allows distributed computing across nodes to solve larger problems. This requires breaking down tasks and distributing them efficiently across nodes.\n",
    "- **Advantages of distributed computing**: Utilizing multiple nodes allows scaling workloads beyond the limits of a single machine. Examples:\n",
    "  - Parallelizing large dataframes and arrays\n",
    "  - Machine learning on large datasets (Training models on data that wonâ€™t fit into memory), leveraging libraries like Dask-ML\n",
    "  - Distributed hyperparameter tuning\n",
    "  - ETL and data pipelines\n",
    "  - Interactive data analysis\n",
    "- **Challenges**:\n",
    "  - **Efficient distribution of tasks**: Breaking tasks into smaller units that can be executed independently is crucial for maximizing parallel efficiency.\n",
    "  - **Minimizing communication overhead**: Communication between nodes can slow down processing. Efficient algorithms aim to reduce the amount of inter-node communication.\n",
    "  - **Handling data dependencies**: Dependencies between tasks can limit parallelism. Identifying independent tasks and minimizing dependencies are key to effective multi-node parallelism."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction to Dask\n",
    "- **Dask collections**: Dask collections are high-level abstractions that provide distributed versions of familiar data structures.\n",
    "  - **Delayed**: Lazy evaluation that allows you to construct a task graph and execute it only when required. This is useful for breaking down complex computations into smaller, manageable tasks.\n",
    "  - **Dask Array**: Parallelized version of NumPy arrays that can be distributed across multiple nodes.\n",
    "  - **Dask DataFrame**: Parallelized version of Pandas DataFrames that can be distributed across multiple nodes.\n",
    "  - **Dask Bag**: Parallelized version of Python iterators that can be distributed across multiple nodes.\n",
    "  - **Dask ML**: Distributed machine learning library that can scale scikit-learn workflows to large datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask\n",
    "\n",
    "# Delayed: Delay computation until it is needed\n",
    "\n",
    "def add(x, y):\n",
    "    return x + y\n",
    "delayed_add = dask.delayed(add)(5, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(delayed_add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = delayed_add.compute()  # Trigger computation\n",
    "print(result)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualizing task graphs:** Dask provides visualization tools to understand the task dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize a task graph\n",
    "delayed_add.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dask Array: Parallel NumPy arrays\n",
    "\n",
    "import dask.array as da\n",
    "import numpy as np\n",
    "\n",
    "x = np.random.rand(10000)\n",
    "y = np.random.rand(10000)\n",
    "dx = da.from_array(x, chunks=len(x)//4)\n",
    "dy = da.from_array(y, chunks=len(y)//4)\n",
    "result = (dx + dy).sum()\n",
    "print(result.compute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dask DataFrame: Parallel Pandas DataFrames\n",
    "\n",
    "import dask.dataframe as dd\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'x': np.random.randint(0, 10, size=10000), 'y': np.random.rand(10000)})\n",
    "ddf = dd.from_pandas(df, npartitions=4)\n",
    "result = ddf.groupby('x').y.mean()\n",
    "print(result.compute())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dask Bag: Parallel Python lists\n",
    "\n",
    "import dask.bag as db\n",
    "\n",
    "b = db.from_sequence(range(10000), npartitions=4)\n",
    "result = b.map(lambda x: x**2).filter(lambda x: x % 2 == 0).sum()\n",
    "print(result.compute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a more complex task graph for visualization\n",
    "import random\n",
    "\n",
    "def random_walk(n):\n",
    "    x = 0\n",
    "    for _ in range(n):\n",
    "        x += random.choice([-1, 1])\n",
    "    return x\n",
    "\n",
    "b = db.from_sequence(range(1000), npartitions=4)\n",
    "\n",
    "result = b.map(random_walk).mean()\n",
    "result.visualize()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result.compute())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running Dask Jobs on Palmetto2\n",
    "- **Using Dask with SLURM**: Dask jobs can be executed on Palmetto by leveraging SLURM to allocate nodes and manage resources. Dask can then orchestrate the distributed computation across the allocated nodes. Here's a simple example of a SLURM script to run a Dask job:\n",
    "```bash\n",
    "#!/bin/bash\n",
    "#SBATCH --job-name=dask_job\n",
    "#SBATCH --nodes=2\n",
    "#SBATCH --ntasks-per-node=2\n",
    "#SBATCH --time=01:00:00\n",
    "#SBATCH --output=dask_output.log\n",
    "\n",
    "module load anaconda3  # Load Anaconda\n",
    "\n",
    "# Ensure the conda environment is accessible across nodes\n",
    "export PATH=$HOME/.conda/envs/hpc_ml/bin:$PATH\n",
    "\n",
    "# Get the hostnames of the allocated nodes\n",
    "hostnames=$(scontrol show hostnames $SLURM_JOB_NODELIST)\n",
    "\n",
    "# Start the Dask scheduler on the first node\n",
    "first_node=$(echo $hostnames | awk '{print $1}')\n",
    "ssh $first_node \"\n",
    "    module load anaconda3 &&\n",
    "    source activate hpc_ml &&\n",
    "    dask-scheduler --scheduler-file=scheduler.json &\n",
    "\" &\n",
    "\n",
    "# Start Dask workers on all nodes\n",
    "for node in $hostnames; do\n",
    "    ssh $node \"\n",
    "        module load anaconda3 &&\n",
    "        source activate hpc_ml &&\n",
    "        dask-worker --scheduler-file=scheduler.json --nthreads=1 --nprocs=2 --memory-limit=0 &\n",
    "    \" &\n",
    "done\n",
    "\n",
    "# Wait for all processes to complete\n",
    "wait\n",
    "```\n",
    "\n",
    "Save the above as, e.g., `dask_job.slurm`, and submit it using `sbatch dask_job.slurm`. Then you can use `ssh` to connect to the first node and run your Dask code. Make sure your code points to the scheduler file (`scheduler.json`) to connect to the Dask cluster. For example, your code could be a .py file that looks like the following:\n",
    "\n",
    "```python\n",
    "from dask.distributed import Client\n",
    "import dask.array as da\n",
    "\n",
    "# Connect to the Dask scheduler\n",
    "client = Client(scheduler_file='scheduler.json')\n",
    "\n",
    "# Example: Creating a random Dask array and performing a computation\n",
    "x = da.random.random((10000, 10000), chunks=(1000, 1000))\n",
    "result = x.mean().compute()\n",
    "\n",
    "print(\"Mean of the array:\", result)\n",
    "```\n",
    "\n",
    "If you save this as `dask_example.py`, you can run it by using `ssh` to connect to the first node running your Dask job and then running `python dask_example.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HPC_ML",
   "language": "python",
   "name": "hpc_ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
