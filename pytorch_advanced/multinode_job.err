/home/dane2/.conda/envs/pytorch_bench/lib/python3.11/site-packages/lightning/pytorch/utilities/parsing.py:199: Attribute 'pytorch_model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['pytorch_model'])`.
Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4
Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4
Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4
----------------------------------------------------------------------------------------------------
distributed_backend=nccl
All distributed processes registered. Starting with 4 processes
----------------------------------------------------------------------------------------------------

wandb: Currently logged in as: dhudsmith (wficai-fast). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.17.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.7
wandb: Run data is saved locally in ./wandb/run-20240510_162954-e7xekhw6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run Multi-node, multi-gpu
wandb: ⭐️ View project at https://wandb.ai/wficai-fast/lightning_logs
wandb: 🚀 View run at https://wandb.ai/wficai-fast/lightning_logs/runs/e7xekhw6
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]
LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1]
LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1]
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]

  | Name      | Type               | Params
-------------------------------------------------
0 | model     | ResNet             | 11.2 M
1 | train_acc | MulticlassAccuracy | 0     
2 | test_acc  | MulticlassAccuracy | 0     
-------------------------------------------------
11.2 M    Trainable params
0         Non-trainable params
11.2 M    Total params
44.777    Total estimated model params size (MB)
/home/dane2/.conda/envs/pytorch_bench/lib/python3.11/site-packages/torch/nn/modules/conv.py:456: UserWarning: Attempt to open cnn_infer failed: handle=0 error: libcudnn_cnn_infer.so.8: cannot open shared object file: No such file or directory (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:81.)
  return F.conv2d(input, weight, bias, self.stride,
/home/dane2/.conda/envs/pytorch_bench/lib/python3.11/site-packages/torch/nn/modules/conv.py:456: UserWarning: Attempt to open cnn_infer failed: handle=0 error: libcudnn_cnn_infer.so.8: cannot open shared object file: No such file or directory (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:81.)
  return F.conv2d(input, weight, bias, self.stride,
/home/dane2/.conda/envs/pytorch_bench/lib/python3.11/site-packages/torch/nn/modules/conv.py:456: UserWarning: Attempt to open cnn_infer failed: handle=0 error: libcudnn_cnn_infer.so.8: cannot open shared object file: No such file or directory (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:81.)
  return F.conv2d(input, weight, bias, self.stride,
/home/dane2/.conda/envs/pytorch_bench/lib/python3.11/site-packages/torch/nn/modules/conv.py:456: UserWarning: Attempt to open cnn_infer failed: handle=0 error: libcudnn_cnn_infer.so.8: cannot open shared object file: No such file or directory (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:81.)
  return F.conv2d(input, weight, bias, self.stride,
/home/dane2/.conda/envs/pytorch_bench/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/logger_connector/result.py:441: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.
`Trainer.fit` stopped: `max_epochs=5` reached.
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.007 MB of 0.007 MB uploaded (0.000 MB deduped)wandb: \ 0.007 MB of 0.007 MB uploaded (0.000 MB deduped)wandb: | 0.007 MB of 0.007 MB uploaded (0.000 MB deduped)wandb: / 0.007 MB of 0.007 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:               epoch ▁▁▁▁▁▃▃▃▃▃▅▅▅▅▅▅▆▆▆▆▆██████
wandb:           train_acc ▁▄▅▅▆▅▆▇▇▆▆▆▇▆▆█▇▆▆███
wandb:          train_loss █▄▃▃▃▄▃▂▂▂▃▃▂▃▃▁▂▂▃▁▂▂
wandb: trainer/global_step ▁▂▂▂▁▁▁▂▃▃▄▁▁▁▁▄▄▄▅▅▁▁▁▅▅▆▆▁▁▁▁▇▇▇██▁▁▁█
wandb:       val_acc_epoch ▁▅▇██
wandb:        val_acc_step ▃▁▃▃▄▄▃▅▆▆▆▆▅▇▇▇▅▇██▇▆▇██
wandb:      val_loss_epoch █▄▂▁▁
wandb:       val_loss_step ▆█▆▆▆▄▆▃▃▃▃▃▂▂▂▃▃▁▁▁▂▃▁▁▁
wandb: 
wandb: Run summary:
wandb:               epoch 4
wandb:           train_acc 0.92188
wandb:          train_loss 0.25785
wandb: trainer/global_step 1104
wandb:       val_acc_epoch 0.87702
wandb:        val_acc_step 0.87714
wandb:      val_loss_epoch 0.36423
wandb:       val_loss_step 0.34481
wandb: 
wandb: 🚀 View run Multi-node, multi-gpu at: https://wandb.ai/wficai-fast/lightning_logs/runs/e7xekhw6
wandb: ️⚡ View job at https://wandb.ai/wficai-fast/lightning_logs/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjgwOTE3MjM5/version_details/v6
wandb: Synced 6 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240510_162954-e7xekhw6/logs
Exception in thread NetStatThr:
Traceback (most recent call last):
  File "/home/dane2/.conda/envs/pytorch_bench/lib/python3.11/threading.py", line 1045, in _bootstrap_inner
    self.run()
  File "/home/dane2/.conda/envs/pytorch_bench/lib/python3.11/threading.py", line 982, in run
    self._target(*self._args, **self._kwargs)
  File "/home/dane2/.local/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 256, in check_network_status
    self._loop_check_status(
  File "/home/dane2/.local/lib/python3.11/site-packages/wandb/sdk/wandb_run.py", line 212, in _loop_check_status
    local_handle = request()
                   ^^^^^^^^^
  File "/home/dane2/.local/lib/python3.11/site-packages/wandb/sdk/interface/interface.py", line 862, in deliver_network_status
    return self._deliver_network_status(status)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/dane2/.local/lib/python3.11/site-packages/wandb/sdk/interface/interface_shared.py", line 610, in _deliver_network_status
    return self._deliver_record(record)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/dane2/.local/lib/python3.11/site-packages/wandb/sdk/interface/interface_shared.py", line 569, in _deliver_record
    handle = mailbox._deliver_record(record, interface=self)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/dane2/.local/lib/python3.11/site-packages/wandb/sdk/lib/mailbox.py", line 455, in _deliver_record
    interface._publish(record)
  File "/home/dane2/.local/lib/python3.11/site-packages/wandb/sdk/interface/interface_sock.py", line 51, in _publish
    self._sock_client.send_record_publish(record)
  File "/home/dane2/.local/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 221, in send_record_publish
    self.send_server_request(server_req)
  File "/home/dane2/.local/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 155, in send_server_request
    self._send_message(msg)
  File "/home/dane2/.local/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 152, in _send_message
    self._sendall_with_error_handle(header + data)
  File "/home/dane2/.local/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py", line 130, in _sendall_with_error_handle
    sent = self._sock.send(data)
           ^^^^^^^^^^^^^^^^^^^^^
BrokenPipeError: [Errno 32] Broken pipe
multi_node_helper.sh: line 26: unexpected EOF while looking for matching `"'
multi_node_helper.sh: line 27: syntax error: unexpected end of file
srun: error: node2088: task 1: Exited with exit code 2
