{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0d580e8-c362-4a0f-b1fd-08b441eb7339",
   "metadata": {},
   "source": [
    "# Scripting Your Code\n",
    "\n",
    "Once you have drafted the code to prepare your data, split it and train/evaluate your model, you should package your code into a script that you can run via SLURM.\n",
    "\n",
    "This will allow you to submit your job to the cluster and have it run asynchronously, without needing to keep your notebook open. It will also allow you to run your code on a larger dataset, or with more iterations, than you could do interactively.\n",
    "\n",
    "What is different about running your code as a script vs. in a notebook? You need to ensure each of the following:\n",
    "- Your code runs from top to bottom without needing any manual intervention\n",
    "- Your code load the full dataset, not just a sample\n",
    "- Your code checks for unexpected conditions and handles them gracefully\n",
    "- Your code logs information about what it is doing, so you can debug it later if needed\n",
    "- For long jobs, your code checkpoints its progress so that it can resume where it left off if it is interrupted\n",
    "- Make sure any desired outputs (plots, model files, etc.) are saved to disk (rather than merely displayed in the notebook)\n",
    "- Figure out what resources you need to request\n",
    "\n",
    "Let's look at a couple of ways of converting code you developed in Jupyter into a SLURM-submittable script, and then dive into some of the above considerations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8217283-f243-4629-995d-7544ddbaa983",
   "metadata": {},
   "source": [
    "## 1. Running your notebook directly as a script\n",
    "\n",
    "Probably the easiest route to converting your notebook is just to run it directly as a job on the cluster. This is possible with the command:\n",
    "\n",
    "```bash\n",
    "jupyter nbconvert --to notebook --execute --inplace [notebook_filename].ipynb\n",
    "```\n",
    "\n",
    "where you would replace `notebook_filename` with whatever your notebook filename is. In a full SLURM script, this command might appear as follows:\n",
    "\n",
    "```bash\n",
    "#!/bin/bash\n",
    "\n",
    "#SBATCH --job-name my-job-name\n",
    "#SBATCH --nodes 1\n",
    "#SBATCH --cpus-per-task 4\n",
    "#SBATCH --gpus-per-node v100:1\n",
    "#SBATCH --mem 8gb\n",
    "#SBATCH --time 08:00:00\n",
    "\n",
    "module load anaconda\n",
    "\n",
    "cd /path/to/your/notebook\n",
    "\n",
    "jupyter nbconvert --to notebook --execute --inplace [notebook_filename].ipynb\n",
    "```\n",
    "\n",
    "Notice that in this case I've determined that my code can make use of 4 cores each on 2 nodes, as well as a V100 GPU on each node. I've also requested 8GB of memory and 8 hours of runtime. You should adjust these values based on your needs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b69719a-7b77-4381-a4a2-2ced71b79e75",
   "metadata": {},
   "source": [
    "## 2. Converting your notebook to a script\n",
    "\n",
    "The preferred coding practice would be to convert your notebook into a script yourself. If you have worked with Jupyter notebooks but not with .py scripts, you can think of the latter as being one big cell in a notebook. In fact, you can even make sure your code runs in a single Jupyter cell (including checkpoints, logging, etc.), and then simply copy that cell into a .py file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7544d19c-b824-4c0a-8e1f-117cea91867c",
   "metadata": {},
   "source": [
    "## 3. Checkpointing\n",
    "\n",
    "If your code is going to take a long time to run, you should consider checkpointing it. This means saving the state of your code at regular intervals, so that if it is interrupted, you can resume from the last checkpoint rather than starting over from the beginning. \n",
    "\n",
    "What exactly this looks like will depend on what you are doing. If you are searching over possible hyperparameters to find the best ones, then you should keep track of which hyperparameters you have tried and what the results were. See the below toy example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862f4107-6501-4da5-a7db-71c236b69061",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import csv\n",
    "import os\n",
    "\n",
    "X, y = np.random.rand(1000, 5), np.random.randint(0, 2, 1000)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Define hyperparameters to test\n",
    "params = [(10, 5), (10, None), (50, 5), (50, None)]\n",
    "\n",
    "# Define the results file, where we'll save the information about which hyperparameters we've already tested\n",
    "results_file = 'results.csv'\n",
    "\n",
    "# Load existing results we've already computed\n",
    "if os.path.exists(results_file):\n",
    "    with open(results_file, 'r') as f:\n",
    "        done = set(tuple(row[:2]) for row in csv.reader(f))\n",
    "else:\n",
    "    done = set()\n",
    "\n",
    "# Train models and save results for each set of hyperparameters not already tested\n",
    "with open(results_file, 'a', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    if not done:\n",
    "        writer.writerow(['n_estimators', 'max_depth', 'accuracy'])\n",
    "    for n_estimators, max_depth in params:\n",
    "        if (str(n_estimators), str(max_depth)) not in done:\n",
    "            model = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth)\n",
    "            accuracy = accuracy_score(y_test, model.fit(X_train, y_train).predict(X_test))\n",
    "            writer.writerow([n_estimators, max_depth, accuracy])\n",
    "            print(f\"n_estimators={n_estimators}, max_depth={max_depth}, accuracy={accuracy:.4f}\")\n",
    "\n",
    "print(f\"Results saved to {results_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ffa308-c0e2-478f-bb23-378f3239bfb9",
   "metadata": {},
   "source": [
    "If we have a long training run, we might want to save the model at regular intervals. This is especially important if we are training a model that takes a long time to train, or if we are training on a large dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66799348-648c-401d-bc9a-7ee73dcf9dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Define a simple neural network model\n",
    "class NNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(10, 200),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(200, 10),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(10, 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "model = NNModel()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Make some random data\n",
    "x = torch.randn(10000, 10)  # Input data\n",
    "y = torch.randn(10000, 1)  # Target data\n",
    "\n",
    "best_loss = float('inf')\n",
    "best_model = None\n",
    "\n",
    "for epoch in range(20):\n",
    "    print(f\"Epoch {epoch+1}\")\n",
    "\n",
    "    # Forward pass\n",
    "    output = model(x)\n",
    "    loss = nn.functional.mse_loss(output, y)\n",
    "    \n",
    "    print(f\"Loss: {loss.item()}\")\n",
    "\n",
    "    # Backward pass\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Track best model\n",
    "    if loss.item() < best_loss:\n",
    "        best_loss = loss.item()\n",
    "        best_model = model.state_dict()\n",
    "        print(f\"New best model found with loss: {best_loss}\")\n",
    "        torch.save({\n",
    "            'model': best_model,\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'epoch': epoch,\n",
    "            'loss': best_loss\n",
    "        }, 'best_model.pt')\n",
    "    \n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        torch.save({\n",
    "            'model': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'epoch': epoch,\n",
    "            'loss': loss.item()\n",
    "        }, f'checkpoint_{epoch+1}.pt')\n",
    "\n",
    "print(\"Training complete. Best model saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98402a35-3b0e-4152-ae0c-ab6170c1351a",
   "metadata": {},
   "source": [
    "## 4. Resource allocation\n",
    "\n",
    "In order to effectively run your code on the cluster, you need to request the appropriate resources. This includes the number of nodes, the number of cores per node, the amount of memory, the amount of time, and the type of GPU.\n",
    "\n",
    "**When multiple cores help:**\n",
    "- When you are running multiple independent jobs\n",
    "- When you are running a single job that can be parallelized (check the documentation!)\n",
    "- When you are running a single job that can be parallelized, but the parallelization is not built into the code (e.g. you are running multiple instances of the code with different hyperparameters)\n",
    "\n",
    "**When multiple cores don't help:**\n",
    "- When you are running a single job that cannot be parallelized\n",
    "- When you haven't written your code to take advantage of multiple cores\n",
    "\n",
    "**When a GPU helps:**\n",
    "- When you are running a deep learning model\n",
    "- When you are running a model that can be accelerated by a GPU (check the documentation!)\n",
    "\n",
    "**When a GPU doesn't help:**\n",
    "- When you are running a model that is not accelerated by a GPU\n",
    "- When you haven't written your code to take advantage of a GPU\n",
    "\n",
    "**How much memory to request:**\n",
    "- This depends on the size of your dataset and the size of your model, as well as whether you are using a GPU. E.g., if you are using a large language model, you might need a big GPU but not much memory. If you are using a large dataset, you might need a lot of memory but not a big GPU.\n",
    "\n",
    "Be sure to use the `jobperf` command to check how much memory your job is using. E.g., `watch -n 2 jobperf [jobid]` will show you how much memory your job is using every 2 seconds."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HPC_ML",
   "language": "python",
   "name": "hpc_ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
