{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "mod5-title",
   "metadata": {},
   "source": [
    "# Module 5: Graph RAG\n",
    "\n",
    "*Part of the RCD Workshops series: Retrieval-Augmented Generation (RAG) for Advanced Research Applications*\n",
    "\n",
    "---\n",
    "\n",
    "So far, retrieval found text snippets. What if your knowledge isn't just documents—but a **knowledge graph**?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08631a5-1990-40df-a22c-e2d1658848a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import create_answer_box\n",
    "create_answer_box('Describe your level of familiarity with knowledge graphs.', question_id='mod4_knowledge_graph_background')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mod5-basics",
   "metadata": {},
   "source": [
    "## What is Graph RAG?\n",
    "A **knowledge graph (KG)** organizes data as entities (nodes) and relationships (edges): facts like (Subject —relation→ Object).\n",
    "Graphs let you represent links across topics and discover answers even when no single document states them directly.\n",
    "\n",
    "![knowledge_graph](knowledge_graph.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mod5-why-graph",
   "metadata": {},
   "source": [
    "### 5.1 Why Knowledge Graphs?\n",
    "- **Multi-hop answers**: Answer questions that require tracing connections (e.g., \"Which startups were founded by former Google employees?\").\n",
    "- **Structured queries (SPARQL, Cypher)**: Let LLMs generate graph queries from user input.\n",
    "- **Context beyond text**: Some info is implicit and scattered across documents, but explicit in the graph."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mod5-approaches",
   "metadata": {},
   "source": [
    "### 5.2 Approaches\n",
    "1. **Vector-based retrieval over nodes/edges:** Treat node/edge texts as documents; embed and run semantic search (baseline RAG, but on graph content).\n",
    "2. **Prompt-to-Graph Query:** Use the LLM to translate the user’s question to a graph query (e.g. SPARQL/Cypher), then fetch subgraph to answer.\n",
    "3. **Hybrid:** Use vectors to find graph entities, then expand by graph traversal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mod5-demo-desc",
   "metadata": {},
   "source": [
    "### 5.3 Hands-on Demo: Building/Querying a Knowledge Graph\n",
    "Let’s use NetworkX to create and query a tiny toy KG."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0234bb90",
   "metadata": {},
   "source": [
    "### Dataset: Demo Corpus\n",
    "\n",
    "We will use a tiny mixed-domain corpus (AI, Climate, Biomedical, Materials) stored in `data/demo_corpus.jsonl`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297b1186",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "DATA_PATH = 'data/demo_corpus.jsonl'\n",
    "df = pd.read_json(DATA_PATH, lines=True)\n",
    "docs = df.to_dict('records')\n",
    "print(f'Loaded {len(docs)} docs from {DATA_PATH}')\n",
    "display(df[['id','title','year','authors','topics']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mod5-demo-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "# Build a heterogeneous graph from the demo corpus: Authors, Papers, Topics\n",
    "G = nx.DiGraph()\n",
    "\n",
    "# Limit to a small subset for readable visualization\n",
    "MAX_PAPERS = 20\n",
    "records = df.head(MAX_PAPERS).to_dict('records')\n",
    "\n",
    "for rec in records:\n",
    "    pid = rec.get('id')\n",
    "    title = rec.get('title', '')\n",
    "    year = rec.get('year')\n",
    "    topics = rec.get('topics', []) or []\n",
    "    authors = rec.get('authors', []) or []\n",
    "    # Paper node\n",
    "    G.add_node(pid, type='Paper', title=title, year=year)\n",
    "    # Author -> Paper edges\n",
    "    for author in authors:\n",
    "        G.add_node(author, type='Author')\n",
    "        G.add_edge(author, pid, relation='authored')\n",
    "    # Paper -> Topic edges\n",
    "    for topic in topics:\n",
    "        G.add_node(topic, type='Topic')\n",
    "        G.add_edge(pid, topic, relation='has_topic')\n",
    "\n",
    "print(f'Graph built: {G.number_of_nodes()} nodes, {G.number_of_edges()} edges')\n",
    "print('Node types:', {t for t in set(nx.get_node_attributes(G, 'type').values())})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mod5-graph-viz-title",
   "metadata": {},
   "source": [
    "### 5.3.1 Visualizing the Graph\n",
    "A quick view of the nodes (Researchers vs Papers) and edge relations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mod5-graph-viz",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "import numpy as np\n",
    "# Layered radial layout: Topics outer ring; Papers and Authors near related topics\n",
    "node_types = nx.get_node_attributes(G, 'type')\n",
    "topics = [n for n, t in node_types.items() if t == 'Topic']\n",
    "papers = [n for n, t in node_types.items() if t == 'Paper']\n",
    "authors = [n for n, t in node_types.items() if t == 'Author']\n",
    "\n",
    "R_TOPIC, R_PAPER, R_AUTHOR = 1.0, 0.68, 0.25\n",
    "rng = np.random.default_rng(42)\n",
    "\n",
    "pos = {}\n",
    "\n",
    "# Place topics evenly on a circle\n",
    "angles = np.linspace(0, 2*np.pi, max(len(topics), 1), endpoint=False)\n",
    "topic_angle = {}\n",
    "for i, topic in enumerate(topics):\n",
    "    theta = angles[i % len(angles)] if len(angles) else 0.0\n",
    "    topic_angle[topic] = theta\n",
    "    pos[topic] = (R_TOPIC*np.cos(theta), R_TOPIC*np.sin(theta))\n",
    "\n",
    "# Helper: circular mean of angles\n",
    "def circ_mean(angles):\n",
    "    arr = np.asarray(angles)\n",
    "    if arr.size == 0:\n",
    "        return 0.0\n",
    "    s = np.sin(arr).mean()\n",
    "    c = np.cos(arr).mean()\n",
    "    return float(np.arctan2(s, c))\n",
    "\n",
    "# Place papers near the mean angle of their topic neighbors\n",
    "paper_angle = {}\n",
    "for p in papers:\n",
    "    nbr_topics = [v for v in G.successors(p) if node_types.get(v) == 'Topic']\n",
    "    thetas = [topic_angle[v] for v in nbr_topics if v in topic_angle]\n",
    "    theta = circ_mean(np.array(thetas)) if thetas else rng.uniform(0, 2*np.pi)\n",
    "    # jitter to reduce overlap\n",
    "    theta += rng.normal(scale=0.16)\n",
    "    r = R_PAPER + rng.normal(scale=0.08)\n",
    "    paper_angle[p] = theta\n",
    "    pos[p] = (r*np.cos(theta), r*np.sin(theta))\n",
    "\n",
    "# Place authors near the mean angle of their paper neighbors\n",
    "for a in authors:\n",
    "    nbr_papers = [v for v in G.successors(a) if node_types.get(v) == 'Paper']\n",
    "    thetas = [paper_angle[v] for v in nbr_papers if v in paper_angle]\n",
    "    theta = circ_mean(np.array(thetas)) if thetas else rng.uniform(0, 2*np.pi)\n",
    "    theta += rng.normal(scale=0.16)\n",
    "    r = R_AUTHOR + rng.normal(scale=0.16)\n",
    "    pos[a] = (r*np.cos(theta), r*np.sin(theta))\n",
    "\n",
    "# Colors, sizes, and shapes per type\n",
    "type_color = {'Author': '#4C78A8', 'Paper': '#F58518', 'Topic': '#54A24B'}\n",
    "type_shape = {'Author': 'o', 'Paper': 's', 'Topic': '^'}\n",
    "sizes = {\n",
    "    'Author': 500,\n",
    "    'Paper': 500,\n",
    "    'Topic': 500,\n",
    "}\n",
    "\n",
    "plt.figure(figsize=(9.5, 6.5))\n",
    "\n",
    "# Draw edges first\n",
    "nx.draw_networkx_edges(\n",
    "    G, pos, arrows=True, arrowstyle='<|-|>', arrowsize=12,\n",
    "    width=1.2, edge_color='#999999', alpha=0.7\n",
    ")\n",
    "\n",
    "# Draw nodes by type with distinct shapes\n",
    "for nodelist, t in [(authors, 'Author'), (papers, 'Paper'), (topics, 'Topic')]:\n",
    "    if not nodelist:\n",
    "        continue\n",
    "    nx.draw_networkx_nodes(\n",
    "        G, pos, nodelist=nodelist,\n",
    "        node_color=type_color[t], node_shape=type_shape[t],\n",
    "        node_size=sizes[t], alpha=0.95, linewidths=1, edgecolors='white'\n",
    "    )\n",
    "\n",
    "# Labels: short paper titles; others as-is, sized per type\n",
    "def short(s, n=28):\n",
    "    s = str(s)\n",
    "    return s if len(s) <= n else s[: n - 1] + '…'\n",
    "\n",
    "# Build label dicts per type to control styling\n",
    "paper_labels = {n: short(G.nodes[n].get('title', n)) for n in papers}\n",
    "author_labels = {n: n for n in authors}\n",
    "topic_labels = {n: n for n in topics}\n",
    "\n",
    "nx.draw_networkx_labels(G, pos, labels=paper_labels, font_size=9)\n",
    "nx.draw_networkx_labels(G, pos, labels=author_labels, font_size=8)\n",
    "nx.draw_networkx_labels(G, pos, labels=topic_labels, font_size=9)\n",
    "\n",
    "# Optional edge labels for small graphs\n",
    "if G.number_of_edges() <= 30:\n",
    "    edge_labels = nx.get_edge_attributes(G, 'relation')\n",
    "    nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels, font_size=8, label_pos=0.45)\n",
    "\n",
    "# Legend with shapes\n",
    "legend_elements = [\n",
    "    Line2D([0], [0], marker=type_shape['Author'], color='w', label='Author',\n",
    "           markerfacecolor=type_color['Author'], markeredgecolor='white', markersize=10, markeredgewidth=1),\n",
    "    Line2D([0], [0], marker=type_shape['Paper'], color='w', label='Paper',\n",
    "           markerfacecolor=type_color['Paper'], markeredgecolor='white', markersize=11, markeredgewidth=1),\n",
    "    Line2D([0], [0], marker=type_shape['Topic'], color='w', label='Topic',\n",
    "           markerfacecolor=type_color['Topic'], markeredgecolor='white', markersize=10, markeredgewidth=1),\n",
    "]\n",
    "plt.legend(handles=legend_elements, frameon=False, loc='upper left')\n",
    "\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mod5-query-desc",
   "metadata": {},
   "source": [
    "- **Example query:** \"Which authors wrote papers about a given topic?\"\n",
    "Let's traverse the graph to answer (Author → Paper → Topic)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mod5-query-logic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick a target topic that's present in the subset\n",
    "all_topics = sorted({t for rec in records for t in (rec.get('topics') or [])})\n",
    "TARGET_TOPIC = 'Climate'\n",
    "print('Available topics:', all_topics)\n",
    "print('Target topic:', TARGET_TOPIC)\n",
    "\n",
    "authors_for_topic = set()\n",
    "if TARGET_TOPIC is not None:\n",
    "    # Walk Author -> Paper -> Topic\n",
    "    for author, paper, ed in G.edges(data=True):\n",
    "        if ed.get('relation') == 'authored':\n",
    "            # Check if this paper links to the target topic\n",
    "            for _, topic, td in G.out_edges(paper, data=True):\n",
    "                if td.get('relation') == 'has_topic' and topic == TARGET_TOPIC:\n",
    "                    authors_for_topic.add(author)\n",
    "\n",
    "print(f'Authors with papers on \"{TARGET_TOPIC}\":', sorted(authors_for_topic))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mod5-graph-rag-twohop-explain",
   "metadata": {},
   "source": [
    "### 5.3.2 Query → Paper + 2-Hop Graph Expansion\n",
    "Below we illustrate Graph RAG in a tiny way:\n",
    "1) Find the most relevant paper to a user query via semantic search over abstracts.\n",
    "2) Expand on the graph to include any papers exactly two hops away (e.g., Paper → Author → Paper).\n",
    "\n",
    "This shows how graphs surface related context beyond the single top document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mod5-graph-rag-twohop",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "\n",
    "# Build a simple embedding index over the SAME subset used in the graph (\"records\")\n",
    "paper_ids, titles, abstracts = [], [], []\n",
    "for r in records:\n",
    "    t = (r.get('abstract') or '').strip()\n",
    "    if not t:\n",
    "        continue\n",
    "    paper_ids.append(r.get('id'))\n",
    "    titles.append(r.get('title'))\n",
    "    abstracts.append(t)\n",
    "\n",
    "if not abstracts:\n",
    "    raise ValueError('No abstracts available to index in this subset.')\n",
    "\n",
    "encoder = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "embs = encoder.encode(abstracts)\n",
    "# L2-normalize for cosine similarity via dot product\n",
    "def l2norm(v):\n",
    "    n = np.linalg.norm(v)\n",
    "    return v / n if n else v\n",
    "embs = np.array([l2norm(v) for v in embs], dtype='float32')\n",
    "\n",
    "# Try your own query\n",
    "query = 'What is the purpose of graph-based retrieval of scientific papers?'\n",
    "qv = encoder.encode([query])[0]\n",
    "qv = l2norm(qv)\n",
    "\n",
    "# Top-1 by cosine similarity\n",
    "scores = embs @ qv\n",
    "top_idx = int(np.argmax(scores))\n",
    "top_id = paper_ids[top_idx]\n",
    "top_title = titles[top_idx]\n",
    "top_abs = abstracts[top_idx]\n",
    "\n",
    "print('Top-1 paper by semantic similarity:')\n",
    "print(f'- {top_title} (id={top_id})\\n')\n",
    "print(top_abs[:1000])\n",
    "\n",
    "# Graph expansion: papers two hops from the top paper\n",
    "UG = G.to_undirected()\n",
    "dists = nx.single_source_shortest_path_length(UG, top_id, cutoff=2)\n",
    "node_types = nx.get_node_attributes(G, 'type')\n",
    "two_hop_papers = [n for n, d in dists.items() if d == 2 and node_types.get(n) == 'Paper']\n",
    "\n",
    "print('\\nTwo-hop related papers via graph:')\n",
    "if not two_hop_papers:\n",
    "    print('(none found in this subset)')\n",
    "else:\n",
    "    rec_by_id = {r.get('id'): r for r in records}\n",
    "    for pid in two_hop_papers:\n",
    "        rec = rec_by_id.get(pid, {})\n",
    "        title = rec.get('title', pid)\n",
    "        print(f'\\n- {title} (id={pid})')\n",
    "        abs_txt = (rec.get('abstract') or '').strip()\n",
    "        print(abs_txt[:800] if abs_txt else '(no abstract available)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mod5-answer-box",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import create_answer_box\n",
    "create_answer_box('Please describe any changes that you think would make this workshop more useful in the future!', question_id='mod4_graph_rag_application')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04bc12e8-b3c8-4dbd-9afd-1ea379260d31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
