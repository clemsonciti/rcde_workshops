{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Goals\n",
    "\n",
    "- Define Retrieval-Augmented Generation (RAG) and why it matters for research.\n- Contrast RAG with fine-tuning and plain prompting; identify trade-offs.\n- Recognize common research use cases and pitfalls (stale sources, grounding).\n- Name the core components of a RAG system (retrieval, ranking, prompting, generation).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef07b9d",
   "metadata": {},
   "source": [
    "# Module 1: Introduction to Retrieval-Augmented Generation (RAG)\n",
    "\n",
    "*Part of the RCD Workshops series: RAG for Research Applications*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5a06d1",
   "metadata": {},
   "source": [
    "\n",
    "## 1.1 What is RAG and Why Do We Need It?\n",
    "\n",
    "Retrieval-Augmented Generation (RAG) combines a pretrained large language model (LLM) with an external data retrieval system so that answers are **grounded in up-to-date, relevant external knowledge**. Instead of relying solely on what the LLM knows, RAG-enabled systems can \"consult\" databases or document corpora to generate better, more trustworthy responses.\n",
    "\n",
    "### Motivations for RAG in Research\n",
    "- **Reduce hallucinations**: LLMs sometimes make up answers. RAG anchors model outputs using real documents.\n",
    "- **Extend knowledge**: LLMs have a training cutoff; RAG lets you search new/specialized info on demand.\n",
    "- **Enable citations & trust**: In research and academic settings, RAG allows citation of sources and provenance.\n",
    "- **Lower costs**: Augmenting a frozen LLM with retrieval is much cheaper than fine-tuning or retraining.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ecd2d8",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "> ![Diagram Placeholder: Schematic of a RAG pipeline. Show a query box, retrieval module fetching relevant docs from a database, passing to LLM with retrieved context, and final grounded answer.](rag_pipeline_graphviz.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002609d7",
   "metadata": {},
   "source": [
    "\n",
    "## 1.2 Examples & Use Cases\n",
    "- **Open-domain QA**: e.g., \"What were the results of the latest climate impact study?\" Without RAG, LLM can't recall something recent; with RAG, it summarizes/quotes the real paper.\n",
    "- **Academic/enterprise chatbots**: e.g., University chatbot using RAG to cite research articles, theses, policies.\n",
    "- **LLM as a \"clerk\"**: LLM interprets, but retrieval provides the vital supporting facts/documents.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbbbe6ea",
   "metadata": {},
   "source": [
    "\n",
    "## 1.3 RAG vs. Other Approaches\n",
    "- **Versus Fine-tuning:** Fine-tuning builds new knowledge into the model weights (very costly/slow). RAG keeps the model fixed and only augments its inputs with up-to-date evidence.\n",
    "- **Versus traditional search:** Search finds docs, but RAG finds *and reads/summarizes* them for you, so you get the answer directly.\n",
    "\n",
    "---\n",
    "\n",
    "### Reflection Point\n",
    "**Consider your own research context:** How might RAG address a specific challenge you face when working with literature or data in your field? What would be the primary benefit for your work?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d80829bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**How might RAG be relevant to your research?**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b1e3adaf2a04781a76e7ec9be62caf5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', layout=Layout(width='500px'), placeholder='Type your answer here')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa2ab840d0a54eb08b660eb48d0f39de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='success', description='Submit', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8209cb0c4dd4a8d9cecfd8025b5bc73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from utils import create_answer_box\n",
    "\n",
    "create_answer_box(\n",
    "    '**How might RAG be relevant to your research?**',\n",
    "    question_id='mod1_advantage_rag'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e152c0",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Wrap-Up\n",
    "\n",
    "You now understand what RAG is, why it's important for scientific/academic research, and how it compares with other ways of expanding a language model's knowledge.\n",
    "\n",
    "**Next:** In the following module, you'll get hands-on with document retrieval and see how modern vector-based retrieval (using embeddings) powers RAG systems.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AutoGluon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}