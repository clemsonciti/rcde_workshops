{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8n40xD862nhd"
   },
   "source": [
    "# Computer Vision and Convolutional Neural Networks (CNNs)\n",
    "\n",
    "Computer Vision was the first area where the power of deep learning was demonstrated. In this notebook we will work through the implementation of an architecture for a classification of hand-written digits and letters using the EMNIST dataset. The figure below shows the classes present in the data.\n",
    "\n",
    "https://docs.google.com/presentation/d/17Uygrr1g6qBMpXOwcfZf584PkW2LTZoXgX1mqsK6syE/edit?usp=sharing\n",
    "\n",
    "We will use the EMNIST dataset which contains . You will experiment with different CNN architecture choices to understand their importance for accurate image recognition. \n",
    "\n",
    "In addition to the digits 0-9, EMNIST has 37 upper and lower-case latin characters (see Figure) for a total of 47 classes. The added classes make EMNIST a more difficult classification task than the original MNIST.\n",
    "\n",
    "![Balanced EMNIST Dataset](https://www.researchgate.net/publication/329391937/figure/fig3/AS:700515201605633@1544027247072/Visualization-of-EMNIST-balanced-dataset-10-Fig2.ppm)\n",
    "\n",
    "To complete the assignment, work through the notebook, following the prompts and answer the questions. Submit your answers using [this google form](https://forms.gle/2n6uH5B8RmH6Ndx1A). You will need to save a copy of the notebook to your own Google Drive using the File menu above. \n",
    "\n",
    "You will need to use a GPU-enabled runtime to complete this assignment. Please go ahead and make sure you have a GPU runtime by selecting `Runtime > Change runtime type` from the menu above. If not already selected, choose `GPU` from the `Hardware accelerator` dropdown menu. \n",
    "\n",
    "### References: \n",
    "* [EMNIST homepage](https://www.westernsydney.edu.au/icns/reproducible_research/publication_support_materials/emnist)\n",
    "* [EMNIST paper on arxiv](https://arxiv.org/pdf/1702.05373.pdf)\n",
    "* [Original CNN Notebook](https://colab.research.google.com/drive/1VXIwT42W1b6yx2xdVsXfazk4_vvMNdY8?usp=sharing)\n",
    "* Slides on CNNs from Watt AI Course: \n",
    "    * [Part 1](https://docs.google.com/presentation/d/19W9-BYMxKnYhPlVkcD4yjao3wO08NI4Dcmbt67EYbGY/edit?usp=sharing)\n",
    "    * [Part 2](https://docs.google.com/presentation/d/1am6YVLQn-kN7R4qNPGsmt2C0swxXqlFnjSgWpqvNOqQ/edit?usp=sharing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7NGHwURr8or8"
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "form",
    "id": "tjB9tDRT2DLi"
   },
   "outputs": [],
   "source": [
    "# @title Import libraries\n",
    "\n",
    "# Library imports\n",
    "import numpy as np\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import math\n",
    "%matplotlib inline\n",
    "\n",
    "# set random seed for reproducibility\n",
    "_ = torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yeE9oK-h9Jjw",
    "outputId": "b92fa5d1-86a2-4be6-c5eb-b5b9d99e2175"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "#@title Model and Training Settings\n",
    "batch_size=64 #input batch size for training (default: 64)\n",
    "test_batch_size=1000 #input batch size for testing (default: 1000)\n",
    "lr=1.0 #learning rate (default: 1.0)\n",
    "gamma=0.7 #Learning rate step gamma (default: 0.7)\n",
    "no_cuda=False #disables CUDA training (default: True)\n",
    "seed=42 #random seed (default: 42)\n",
    "log_interval=150 #how many batches to wait before logging training status (default: 10)\n",
    "save_model=False #save the trained model (default: False)\n",
    "\n",
    "# additional derived settings\n",
    "use_cuda = not no_cuda and torch.cuda.is_available()\n",
    "torch.manual_seed(seed)\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
    "\n",
    "print(\"Device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84,
     "referenced_widgets": [
      "a594b0a61f9c471f927d1e84bb6b660e",
      "7907db13bf594b6188ee1321502e01f3",
      "430518b6f83343e0b5e22d32b348d605",
      "4b3178c079fb4eb3800e3b8311caf412",
      "21179021fdd249dca874a2cb3215d3e9",
      "3f00f27414ed4d80ace97ee0bcea32d6",
      "87f7464c25c44cde8088e97126f4190e",
      "b765f713ef5440ea85c5f12540ebba75",
      "674919a7e1d14f738a6d70ad66a89f4b",
      "60c4d3e66e2146cdb1ed443d133ae9ec",
      "c7cb437d14a24ecd9551c8f9516577c8"
     ]
    },
    "id": "klIYys9h8sUN",
    "outputId": "7a98a546-4d78-45d1-f711-09cf658b7955"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.itl.nist.gov/iaui/vip/cs_links/EMNIST/gzip.zip to ../data/EMNIST/raw/gzip.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 561753746/561753746 [00:17<00:00, 32250396.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/EMNIST/raw/gzip.zip to ../data/EMNIST/raw\n"
     ]
    }
   ],
   "source": [
    "# @title Loading the data\n",
    "# define pytorch dataloaders for training and testing\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.EMNIST('../data', split='balanced', train=True, download=True,\n",
    "                    transform=transforms.Compose([\n",
    "                        transforms.ToTensor(),\n",
    "                        transforms.Normalize((0.1307,), (0.3081,))\n",
    "                    ])),\n",
    "    batch_size=batch_size, shuffle=True, **kwargs)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.EMNIST('../data', split='balanced', train=False, transform=transforms.Compose([\n",
    "                        transforms.ToTensor(),\n",
    "                        transforms.Normalize((0.1307,), (0.3081,))\n",
    "                    ])),\n",
    "    batch_size=test_batch_size, shuffle=False, **kwargs)\n",
    "\n",
    "image_gen = iter(test_loader)\n",
    "test_img, test_trg = next(image_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aJ0iyHFj-LUG",
    "outputId": "24d1bbaf-8f0d-450a-ff2b-df553af2f2e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset: Dataset EMNIST\n",
      "    Number of datapoints: 112800\n",
      "    Root location: ../data\n",
      "    Split: Train\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               ToTensor()\n",
      "               Normalize(mean=(0.1307,), std=(0.3081,))\n",
      "           )\n",
      "Testing dataset: Dataset EMNIST\n",
      "    Number of datapoints: 18800\n",
      "    Root location: ../data\n",
      "    Split: Test\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               ToTensor()\n",
      "               Normalize(mean=(0.1307,), std=(0.3081,))\n",
      "           )\n"
     ]
    }
   ],
   "source": [
    "print(\"Training dataset:\", train_loader.dataset)\n",
    "print(\"Testing dataset:\", test_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "id": "fBOgyUZwUVIB",
    "outputId": "642cb012-b018-4cd2-e517-f9a16c17db1e"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 16 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#@title Look at the data:\n",
    "n_images = 16\n",
    "rand_imgs = next(iter(test_loader))\n",
    "ints = torch.randint(0,len(rand_imgs[0]), (n_images,))\n",
    "\n",
    "fig, ax_arr = plt.subplots(4, 4)\n",
    "ax_arr = ax_arr.flatten()\n",
    "\n",
    "for n, ix in enumerate(ints):\n",
    "  img = rand_imgs[0][ix]\n",
    "  ax_arr[n].imshow(img[0].detach().cpu().numpy().T, cmap='Greys')\n",
    "  ax_arr[n].axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AR0lyfnEuPsw"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "**Question 1**: In addition to the larger number of classes in EMNIST compared to MNIST, why might it be more difficult to accurately classify images from the EMNIST set?\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cellView": "form",
    "id": "7g4s_TT-3ZeF"
   },
   "outputs": [],
   "source": [
    "#@title Training and testing functions\n",
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    losses = []\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.cross_entropy(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('\\r\\tTrain epoch {}: [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()), end='')\n",
    "            \n",
    "def test(model, device, test_loader, epoch):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.cross_entropy(output, target, reduction='sum').item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\rTest epoch {}: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)'.format(\n",
    "        epoch,\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "    \n",
    "def train_and_test(model, save_name='model.pt', epochs=5):\n",
    "    # @title Train the linear model\n",
    "    optimizer = optim.Adadelta(model.parameters(), lr=lr)\n",
    "    scheduler = StepLR(optimizer, step_size=1, gamma=gamma)\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        train(model, device, train_loader, optimizer, epoch)\n",
    "        test(model, device, test_loader, epoch)\n",
    "        scheduler.step()\n",
    "\n",
    "    if save_model:\n",
    "        torch.save(model.state_dict(), save_name)\n",
    "\n",
    "def get_n_params(model):\n",
    "    pp=0\n",
    "    for p in list(model.parameters()):\n",
    "        nn=1\n",
    "        for s in list(p.size()):\n",
    "            nn = nn*s\n",
    "        pp += nn\n",
    "    return pp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EfeJK7_EF0Jf"
   },
   "source": [
    "# Classification architectures\n",
    "We will explore a range of classification architectures starting with a linear classifier and scaling up to a several-layer convolutional neural network. Each architecture can be described in two steps (see figure below):\n",
    "1. Feature extraction -- converting the raw pixel information into a _feature vector_\n",
    "2. Classification -- converting the feature vector into predictions about the character in the input image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vy7U5jeCFmRN"
   },
   "source": [
    "![CNN diagram](https://miro.medium.com/max/1400/1*XbuW8WuRrAY5pC4t-9DZAQ.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W9AIybygGyud"
   },
   "source": [
    "Most of the secret sauce of CNNs takes place in the feature extraction step. We will define a generic classification architecture that takes as input the sequence of operations used for feature extraction. We will use progressively more complex feature extraction pipelines. For the classification step, we will always use a single linear layer, but the number of inputs will depend on the size of the feature vector produced by the feature extractor. \n",
    "\n",
    "The class defined below implements this generic classifier class in pytorch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "XU9unsjPHGWe"
   },
   "outputs": [],
   "source": [
    "# Define the generic EMNIST classification architecture\n",
    "# The `feature_extractor` argument takes images as input and produces feature vectors.\n",
    "# These vectors can be of any length. \n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, feature_extractor):\n",
    "        super(Classifier, self).__init__()\n",
    "\n",
    "        # feature encoder\n",
    "        self.feature_extractor = feature_extractor\n",
    "        \n",
    "        # classifier\n",
    "        self.classifier = nn.LazyLinear(47)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.feature_extractor(x) # Flatten -> x_i\n",
    "        x = self.classifier(x) # Matrix multiply -> c_m^0 + sum(W_mi*x_i)\n",
    "        x = F.softmax(x, dim=1) # apply the softmax function\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EectRKIank05"
   },
   "source": [
    "# Linear Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N9-aG-j7Hm81"
   },
   "source": [
    "A linear classifier uses the original pixels as the features for classification. We simply need to unravel the 2D image into a vector. This is accomplished using `nn.Flatten()`. \n",
    "\n",
    "Note: you can safely ignore the message `UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
    "  warnings.warn('Lazy modules are a new feature under heavy development`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QaTveymj-iF4",
    "outputId": "ea4dc50a-d213-49e1-822b-975d52be6e43"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/software/spackages/linux-rocky8-x86_64/gcc-9.5.0/anaconda3-2022.05-zyrazrj6uvrtukupqzhaslr63w7hj6in/envs/pytorch_workshop/lib/python3.10/site-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    }
   ],
   "source": [
    "# set random seed for reproducibility\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# define the feature extractor\n",
    "# for linear model, we just flatten the original image into a vector\n",
    "feature_extractor = nn.Flatten()\n",
    "\n",
    "# Create the model\n",
    "model = Classifier(feature_extractor).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "id": "8vSFTMcbH-cI",
    "outputId": "6bfb0ed5-85b1-457a-ab5d-d29712188822"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Classifier(\n",
       "  (feature_extractor): Flatten(start_dim=1, end_dim=-1)\n",
       "  (classifier): Linear(in_features=784, out_features=47, bias=True)\n",
       ")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters in linear model: 36895\n"
     ]
    }
   ],
   "source": [
    "# @title Display model and number of parameters \n",
    "# Run one batch through the model to initialize the lazy linear layer\n",
    "# this is necessary to get accurate parameter counts\n",
    "with torch.no_grad():\n",
    "    model(test_img.to(device)) \n",
    "\n",
    "display(model)\n",
    "\n",
    "print(\"Number of parameters in linear model:\", get_n_params(model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EinhuAcXvLx2"
   },
   "source": [
    "---\n",
    "\n",
    "**Question 2**: You should find that the linear model has 36,895 parameters compared with 7,850 when using the linear model with MNIST. Both EMNIST and MNIST contain 28x28 pixel images, so why does the linear model for EMNIST have so many more parameters?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-D9tp1GYxAvJ"
   },
   "source": [
    "## Train and test the linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZONf9JTx7kAL",
    "outputId": "581e8034-772f-4e89-c557-90c2c5407609"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test epoch 1: Average loss: 3.3020, Accuracy: 11264/18800 (59.91%)\n",
      "Test epoch 2: Average loss: 3.2766, Accuracy: 11716/18800 (62.32%)\n",
      "Test epoch 3: Average loss: 3.2662, Accuracy: 11899/18800 (63.29%)\n",
      "Test epoch 4: Average loss: 3.2604, Accuracy: 11989/18800 (63.77%)\n",
      "Test epoch 5: Average loss: 3.2485, Accuracy: 12224/18800 (65.02%)\n"
     ]
    }
   ],
   "source": [
    "train_and_test(model)\n",
    "\n",
    "# by default, `train_and_test` trains for 5 epochs\n",
    "# you can adjust this using the epochs argument, like\n",
    "# train_and_test(model, epochs=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ci5OzdbdozRI"
   },
   "source": [
    "---\n",
    "\n",
    "**Question 3**: How accurate is the linear model after 5 epochs? How does this compare with the MNIST digit classification result used in the lecture? Why do you think it worked out that way? \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M-uG4JFzoM8p"
   },
   "source": [
    "# CNN Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sYRtyOHnM8TF"
   },
   "source": [
    "### One convolution layer\n",
    "We now make a more interesting feature extractor using convolution. The feature extractor has the following steps: \n",
    "1. _convolution_ (`nn.Conv2d`) over the input image.\n",
    "2. _batch normalization_ (`nn.BatchNorm2d`) rescales the feature maps. This helps the network converge more quickly. You can see the definition [here](https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm2d.html).\n",
    "3. _ReLU_ (`nn.ReLU`) zeroes out negative values in the feature maps. \n",
    "4. _max pooling_ (`nn.MaxPool2d`) takes the maximum pixel from each 2x2 block resulting in an image that has half the size in each dimension. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "_SG3nRRxHtbF"
   },
   "outputs": [],
   "source": [
    "# set random seed for reproducibility\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# define the feature extractor\n",
    "feature_extractor = nn.Sequential(\n",
    "    # convolution block:\n",
    "    nn.Conv2d(in_channels=1, out_channels=4, kernel_size=3, stride=1, bias=False),\n",
    "    nn.LazyBatchNorm2d(),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2),\n",
    "    # flatten just as with the linear classifier\n",
    "    nn.Flatten()\n",
    ")\n",
    "# Create the model\n",
    "model = Classifier(feature_extractor).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 208
    },
    "id": "Cz8bql81KXSQ",
    "outputId": "7cc6cc2b-4681-4184-94b2-ea182c03bc32"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Classifier(\n",
       "  (feature_extractor): Sequential(\n",
       "    (0): Conv2d(1, 4, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (4): Flatten(start_dim=1, end_dim=-1)\n",
       "  )\n",
       "  (classifier): Linear(in_features=676, out_features=47, bias=True)\n",
       ")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters in linear model: 31863\n"
     ]
    }
   ],
   "source": [
    "# @title Display model and number of parameters \n",
    "# Run one batch through the model to initialize the lazy linear layer\n",
    "# this is necessary to get accurate parameter counts\n",
    "with torch.no_grad():\n",
    "    model(test_img.to(device)) \n",
    "\n",
    "display(model)\n",
    "\n",
    "print(\"Number of parameters in linear model:\", get_n_params(model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kfdS6w6vog1V"
   },
   "source": [
    "(Less than 36,895 for linear model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hZYspFPRrI2t",
    "outputId": "eca388b3-8e4d-45de-fa1d-a3118d232fb9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test epoch 1: Average loss: 3.2283, Accuracy: 12484/18800 (66.40%)\n",
      "Test epoch 2: Average loss: 3.1817, Accuracy: 13378/18800 (71.16%)\n",
      "Test epoch 3: Average loss: 3.1581, Accuracy: 13784/18800 (73.32%)\n",
      "Test epoch 4: Average loss: 3.1469, Accuracy: 14009/18800 (74.52%)\n",
      "Test epoch 5: Average loss: 3.1428, Accuracy: 14097/18800 (74.98%)\n"
     ]
    }
   ],
   "source": [
    "train_and_test(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eaNhkI-nMg-4"
   },
   "source": [
    "---\n",
    "\n",
    "**Question 4**: Why does the CNN beat the linear model after 5 epochs despite having fewer parameters?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 681
    },
    "id": "xHvF95xthS0Y",
    "outputId": "908fbc8e-f4c0-497c-ff34-badfd22e0ab0"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "3\n",
    "\n",
    "imgs, labels = next(image_gen)\n",
    "test_img_plot = imgs[6,0]\n",
    "\n",
    "kern = model.feature_extractor[0]\n",
    "\n",
    "#@title Generate feature maps\n",
    "fmaps_1 = kern(test_img_plot[None, None].cuda()).detach().cpu().numpy()[0]\n",
    "for K, fmap in zip(kern.weight, fmaps_1):\n",
    "  # plot kernel\n",
    "  plt.subplot(1,2,1)\n",
    "  mat = K.clone().detach().cpu().numpy()[0]\n",
    "  plt.imshow(mat.T)\n",
    "  plt.axis('off')\n",
    "\n",
    "  # plot feature map\n",
    "  plt.subplot(1,2,2)\n",
    "  plt.imshow(fmap.T, cmap='Greys')\n",
    "  plt.axis('off')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I_3CZo0Uzr0s"
   },
   "source": [
    "In the cell above, the colored grids on the left are representations of the convolution kernel matrices. The values of these kernel matrices were \"learned\" during the training of the network. The image on the right is the feature map produced by convolving the kernel matrix with the original image. Bright areas correspond to high numerical values; dark areas correspond to low numerical values. \n",
    "\n",
    "---\n",
    "\n",
    "**Question 5**: \n",
    "1. Upload a screen capture of your feature maps (the left column of images) to the Google form\n",
    "2. Rerun the above cell several times to see the activation maps for several characters. Describe which features in the original image each of the 4 kernels appear to be highlighting. Why might these features be useful for correctly classifying hand-written characters?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oXtrbRCL9_Sd"
   },
   "source": [
    "# A \"wider\" model\n",
    "The \"width\" of a CNN refers to how many feature maps are used in the convolution layers. Wide layers have many convolution kernels leading to many feature maps. In the model above, we had 4 convolution kernels (see `out_channels=4` in the `nn.Conv2d` layer in the feature extractor). Interpreting these kernels as feature extractors, it's plausible that we could improve the performance of the model by increasing the number of kernels.\n",
    "\n",
    "The network below is the same as the previous one except that it uses twice as many kernels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "v3vuPy-u_vzI"
   },
   "outputs": [],
   "source": [
    "# set random seed for reproducibility\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# define the feature extractor\n",
    "feature_extractor = nn.Sequential(\n",
    "    # convolution block:\n",
    "    nn.Conv2d(in_channels=1, out_channels=8, kernel_size=3, stride=1, bias=False),\n",
    "    nn.LazyBatchNorm2d(),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2),\n",
    "    # flatten just as with the linear classifier\n",
    "    nn.Flatten()\n",
    ")\n",
    "\n",
    "# Create the model\n",
    "model = Classifier(feature_extractor).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 208
    },
    "id": "P8XHRva5AIkF",
    "outputId": "f9369081-fec2-4f33-e5f1-4ce9f12218b0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Classifier(\n",
       "  (feature_extractor): Sequential(\n",
       "    (0): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (4): Flatten(start_dim=1, end_dim=-1)\n",
       "  )\n",
       "  (classifier): Linear(in_features=1352, out_features=47, bias=True)\n",
       ")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters in linear model: 63679\n"
     ]
    }
   ],
   "source": [
    "# @title Display model and number of parameters \n",
    "# Run one batch through the model to initialize the lazy linear layer\n",
    "# this is necessary to get accurate parameter counts\n",
    "with torch.no_grad():\n",
    "    model(test_img.to(device)) \n",
    "\n",
    "display(model)\n",
    "\n",
    "print(\"Number of parameters in linear model:\", get_n_params(model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZjhbsKpIBn3c"
   },
   "source": [
    "Notice that doubling the number of channels nearly doubled the number of free parameters in the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A6Vp4OjJAMb6",
    "outputId": "2870ab48-a87d-42d2-8e9b-ad98cdbe28b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test epoch 1: Average loss: 3.2283, Accuracy: 12468/18800 (66.32%)\n",
      "Test epoch 2: Average loss: 3.1334, Accuracy: 14267/18800 (75.89%)\n",
      "Test epoch 3: Average loss: 3.1114, Accuracy: 14663/18800 (77.99%)\n",
      "Test epoch 4: Average loss: 3.1033, Accuracy: 14829/18800 (78.88%)\n",
      "Test epoch 5: Average loss: 3.0973, Accuracy: 14918/18800 (79.35%)\n"
     ]
    }
   ],
   "source": [
    "train_and_test(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k9Mv_jrGASFu"
   },
   "source": [
    "---\n",
    "\n",
    "**Question 6**: How does the performance with 8 kernels compare to the performance with 4 kernels? Why do you think this might be the case?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6IueniS6Gyrx"
   },
   "source": [
    "# A \"deeper\" model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "80REJwRrhvV4"
   },
   "source": [
    "The \"depth\" of a CNN refers to how many convolution layers are used in the network. The feature maps from one convolution step are used as the input for the next convolution. The previous network had a single convolution step. We will now try adding more convolution layers and see how it effects performance. To isolate the effect of having more layers, we will hold the width at 4 kernels like our first CNN.\n",
    "\n",
    "---\n",
    "\n",
    "**Question 7**: Why might it be helpful to add more convolutional layers to the CNN?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "7fxqecWJM_2U"
   },
   "outputs": [],
   "source": [
    "# set random seed for reproducibility\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# define the encoder\n",
    "# we repeat the convolution block several times\n",
    "feature_extractor = nn.Sequential(\n",
    "    # block 1\n",
    "    nn.Conv2d(in_channels=1, out_channels=4, kernel_size=3, stride=1, bias=False),\n",
    "    nn.LazyBatchNorm2d(),\n",
    "    nn.ReLU(),\n",
    "    # 2\n",
    "    nn.Conv2d(in_channels=4, out_channels=4, kernel_size=3, stride=1, bias=False),\n",
    "    nn.LazyBatchNorm2d(),\n",
    "    nn.ReLU(),\n",
    "    # 3\n",
    "    nn.Conv2d(in_channels=4, out_channels=4, kernel_size=3, stride=1, bias=False),\n",
    "    nn.LazyBatchNorm2d(),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2),\n",
    "    # flatten just as with the linear classifier\n",
    "    nn.Flatten()\n",
    ")\n",
    "\n",
    "# Create the model\n",
    "model = Classifier(feature_extractor).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "id": "bitGRh8qNX8p",
    "outputId": "bd7e9dfe-3863-49f0-ed02-d3ef59786997"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Classifier(\n",
       "  (feature_extractor): Sequential(\n",
       "    (0): Conv2d(1, 4, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "    (4): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU()\n",
       "    (6): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "    (7): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (8): ReLU()\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Flatten(start_dim=1, end_dim=-1)\n",
       "  )\n",
       "  (classifier): Linear(in_features=484, out_features=47, bias=True)\n",
       ")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters in linear model: 23143\n"
     ]
    }
   ],
   "source": [
    "# @title Display model and number of parameters \n",
    "# Run one batch through the model to initialize the lazy linear layer\n",
    "# this is necessary to get accurate parameter counts\n",
    "with torch.no_grad():\n",
    "    model(test_img.to(device)) \n",
    "\n",
    "display(model)\n",
    "\n",
    "print(\"Number of parameters in linear model:\", get_n_params(model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nWZzzoW1B5l-"
   },
   "source": [
    "The number of parameters is actually _less_ than our single layer model. We added lots of convolution kernels, so how can that be? Most of the parameters come from the final linear layer. Each convolution layer trims off a row of pixels around the image. This, in turn reduces the size of the final feature vector which reduces the number of parameters in the final linear layer. This reduction is greater than the number of new parameters in the added convolution layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E5pc2RTi9UfX",
    "outputId": "5b3f17e2-ff65-41e7-96de-f04d39df8f73"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test epoch 1: Average loss: 3.2106, Accuracy: 12774/18800 (67.95%)\n",
      "Test epoch 2: Average loss: 3.1319, Accuracy: 14263/18800 (75.87%)\n",
      "Test epoch 3: Average loss: 3.1148, Accuracy: 14557/18800 (77.43%)\n",
      "Test epoch 4: Average loss: 3.1063, Accuracy: 14742/18800 (78.41%)\n",
      "Test epoch 5: Average loss: 3.1039, Accuracy: 14764/18800 (78.53%)\n"
     ]
    }
   ],
   "source": [
    "train_and_test(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NSd76lvkOKXa"
   },
   "source": [
    "---\n",
    "\n",
    "**Question 8**: You should find that the deeper model outperformed the wider model despite having many fewer parameters. Why do you think increasing the depth of the model was more effective than increasing the width?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Eu9yXu8cC8Uv"
   },
   "source": [
    "# Your turn! \n",
    "Modify the feature extractor below and see how good of a score you can obtain on EMNIST. Some ideas: \n",
    "* Change the number of channels in the convolution layers. Note: the `in_channels` argument to `nn.Conv2d` must match the `out_channels` argument from a previous layer. The input image has 1 channel since the images are grayscale.\n",
    "* Change the `kernel_size`, which is the size of the kernel matrix used in convolution. \n",
    "* Change the number of convolution blocks in the network.\n",
    "* Try [different activation functions](https://pytorch.org/docs/stable/nn.html#non-linear-activations-weighted-sum-nonlinearity).\n",
    "* Add or remove max pooling layers between convolution blocks\n",
    "* Use a greater number of epochs in the `train_and_test` function\n",
    "\n",
    "There are many, many possible combinations that you could try, and you can't explore them all. Try to think of a few experiments to try and record what you learn. If you want to go down the rabbit hole of trying many things, feel free, but that's not expected for this assignment.\n",
    "\n",
    "Try to beat my score of 83.4% resulting from using the \"deeper model\" above trained for 13 epochs.\n",
    "\n",
    "---\n",
    "\n",
    "**Question 9:** \n",
    "1. Upload two screencaps: i) the printout for your best training run and ii) the code defining your feature extractor for this run.\n",
    "2. What was your highest percent accuracy score? \n",
    "3. Summarize what you learned in your experimentation. What worked well? What didn't work well? What surprised you?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "d944NmW_C-wh"
   },
   "outputs": [],
   "source": [
    "# set random seed for reproducibility\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# define the encoder\n",
    "# we repeat the convolution block several times\n",
    "feature_extractor = nn.Sequential(\n",
    "    # block 1\n",
    "    nn.Conv2d(in_channels=1, out_channels=4, kernel_size=3, stride=1),\n",
    "    nn.LazyBatchNorm2d(),\n",
    "    nn.ReLU(),\n",
    "    # block 2\n",
    "    # the value of `in_channels` has to match `out_channels` from the previous step\n",
    "    nn.Conv2d(in_channels=4, out_channels=4, kernel_size=3, stride=1),\n",
    "    nn.LazyBatchNorm2d(),\n",
    "    nn.ReLU(),\n",
    "    # block 3\n",
    "    nn.Conv2d(in_channels=4, out_channels=4, kernel_size=3, stride=1),\n",
    "    nn.LazyBatchNorm2d(),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2),\n",
    "    # flatten just as with the linear classifier\n",
    "    nn.Flatten()\n",
    ")\n",
    "\n",
    "# Create the model\n",
    "model = Classifier(feature_extractor).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2g5zHcroEqra",
    "outputId": "c420f942-c41c-4422-fa16-98dcf95f11f4",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test epoch 1: Average loss: 3.2606, Accuracy: 11945/18800 (63.54%)\n",
      "Test epoch 2: Average loss: 3.0921, Accuracy: 15013/18800 (79.86%)\n",
      "Test epoch 3: Average loss: 3.0805, Accuracy: 15202/18800 (80.86%)\n",
      "Test epoch 4: Average loss: 3.0712, Accuracy: 15376/18800 (81.79%)\n",
      "Test epoch 5: Average loss: 3.0685, Accuracy: 15430/18800 (82.07%)\n"
     ]
    }
   ],
   "source": [
    "train_and_test(model, epochs=5)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "21179021fdd249dca874a2cb3215d3e9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3f00f27414ed4d80ace97ee0bcea32d6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "430518b6f83343e0b5e22d32b348d605": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b765f713ef5440ea85c5f12540ebba75",
      "max": 561753746,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_674919a7e1d14f738a6d70ad66a89f4b",
      "value": 561753746
     }
    },
    "4b3178c079fb4eb3800e3b8311caf412": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_60c4d3e66e2146cdb1ed443d133ae9ec",
      "placeholder": "​",
      "style": "IPY_MODEL_c7cb437d14a24ecd9551c8f9516577c8",
      "value": " 561753746/561753746 [00:37&lt;00:00, 15679465.54it/s]"
     }
    },
    "60c4d3e66e2146cdb1ed443d133ae9ec": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "674919a7e1d14f738a6d70ad66a89f4b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "7907db13bf594b6188ee1321502e01f3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3f00f27414ed4d80ace97ee0bcea32d6",
      "placeholder": "​",
      "style": "IPY_MODEL_87f7464c25c44cde8088e97126f4190e",
      "value": "100%"
     }
    },
    "87f7464c25c44cde8088e97126f4190e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a594b0a61f9c471f927d1e84bb6b660e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7907db13bf594b6188ee1321502e01f3",
       "IPY_MODEL_430518b6f83343e0b5e22d32b348d605",
       "IPY_MODEL_4b3178c079fb4eb3800e3b8311caf412"
      ],
      "layout": "IPY_MODEL_21179021fdd249dca874a2cb3215d3e9"
     }
    },
    "b765f713ef5440ea85c5f12540ebba75": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c7cb437d14a24ecd9551c8f9516577c8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
