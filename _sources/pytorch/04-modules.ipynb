{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2afce6df-0519-460b-b64f-f3f1e506d561",
   "metadata": {},
   "source": [
    "# Building the network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e050e5cd-265f-436e-babd-14a6597132ec",
   "metadata": {},
   "source": [
    "The `nn.Module` subpackage in PyTorch contains many neural network building blocks called \"modules\". We can compose these in arbitrary ways to build network architectures tailored to a given problem. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78ac35a7-044e-434f-904a-edf5311a1def",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# do everything on gpu unless we explicitly say otherwise\n",
    "torch.set_default_device('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933ed3f8-f62a-4f9a-a365-992bcd14d921",
   "metadata": {},
   "source": [
    "## The basics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225c65d5-89fb-413b-a661-767cf3a378f1",
   "metadata": {},
   "source": [
    "We saw examples like this in earlier notebooks: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d361b96-c513-42a2-acde-15663955ba95",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=10, out_features=10, bias=True)\n",
       "  (1): Tanh()\n",
       "  (2): Linear(in_features=10, out_features=10, bias=True)\n",
       "  (3): Tanh()\n",
       "  (4): Linear(in_features=10, out_features=3, bias=True)\n",
       "  (5): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(10,10),\n",
    "    nn.Tanh(),\n",
    "    nn.Linear(10,10),\n",
    "    nn.Tanh(),\n",
    "    nn.Linear(10,3),\n",
    "    nn.Sigmoid()\n",
    ")\n",
    "\n",
    "# printing the model shows the layers\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53cc531e-0228-4eac-b6a8-8494520c4041",
   "metadata": {},
   "source": [
    "`nn.Sequential`, `nn.Linear`, `nn.Tanh`, and `nn.Sigmoid` are all examples of modules. There are many more. You can see a full list here: https://pytorch.org/docs/stable/nn.html\n",
    "\n",
    "**Callable.** All modules are _callable_, meaning they can be evaluated like a function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "477f0ae1-06bd-412f-ae0a-506a32e2dbb9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2067, -0.1036, -0.0760,  0.1359,  0.1805],\n",
       "        [-0.7918,  0.2130,  0.5677, -0.1730,  0.6101],\n",
       "        [ 0.3045, -0.1712, -0.2181,  0.1504, -0.0715],\n",
       "        [-0.0092, -0.1449, -0.2185,  0.2841,  0.0868],\n",
       "        [ 1.0998, -0.0064, -0.1398,  0.6454,  0.4840],\n",
       "        [ 0.0100, -0.4746, -0.8649,  0.5077, -0.4945],\n",
       "        [ 0.8390, -0.2072, -0.4667,  0.6762,  0.2141]], device='cuda:0',\n",
       "       grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer = nn.Linear(4,5)\n",
    "x = torch.randn(7, 4)\n",
    "layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c51be746-c0bb-4d96-82c0-5959ce71837e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0721, -0.4746,  0.3835, -0.3337],\n",
       "        [-0.8418, -0.8637, -0.7904, -0.7616],\n",
       "        [ 0.8242, -0.2777,  0.2174, -0.1672],\n",
       "        [ 0.4278, -0.6650, -0.3149,  0.0979],\n",
       "        [ 0.0996,  0.6908,  0.6997,  0.4332],\n",
       "        [ 0.9625, -0.8417, -0.5027,  0.7079],\n",
       "        [ 0.2415,  0.0522,  0.6528,  0.5939]], device='cuda:0')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer = nn.Tanh()\n",
    "layer(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85de0d18-2cdf-4be0-869a-9a9a0ee6040d",
   "metadata": {},
   "source": [
    "**Changing device.** Modules can be moved between devices. Unlike tensors, this operation is _in place_. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7af6b460-536c-4467-b69a-7cd73e7df459",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: cuda:0\n",
      "After: cpu\n"
     ]
    }
   ],
   "source": [
    "layer = nn.Linear(4,5)\n",
    "print(\"Before:\", layer.weight.device)\n",
    "layer.to('cpu')\n",
    "print(\"After:\", layer.weight.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab88aeaa-8775-4a95-9d36-ac7e69a96b07",
   "metadata": {},
   "source": [
    "All nested modules also move: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de49e75b-a7ba-4c6f-bc6d-88ce412c6161",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: cuda:0\n",
      "After: cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=10, out_features=10, bias=True)\n",
       "  (1): Tanh()\n",
       "  (2): Linear(in_features=10, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(10,10),\n",
    "    nn.Tanh(),\n",
    "    nn.Linear(10,3)\n",
    ")\n",
    "\n",
    "print(\"Before:\", model[0].weight.device)\n",
    "model.to('cpu')\n",
    "print(\"After:\", model[0].weight.device)\n",
    "\n",
    "# back on gpu for later\n",
    "model.to('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4696955b-60f3-4aea-b775-52de499eadaf",
   "metadata": {},
   "source": [
    "**Saving/loading**. Model weights can be saved to and loaded from disc. There are a few ways to do this. The recommended way is to just save the weights using the \"state dict\" object:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3c8ac65-cef8-4d4b-8581-6c8746918672",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.weight torch.Size([10, 10])\n",
      "0.bias torch.Size([10])\n",
      "2.weight torch.Size([3, 10])\n",
      "2.bias torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "for k, v in model.state_dict().items():\n",
    "    print(k, v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6390d5cc-8015-4c94-8669-4c39a7ae4962",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model_weights.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "123135aa-dd66-49a1-9eca-5796b61b44e6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PK\u0003\u0004\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0016\u0000\f",
      "\u0000model_weights/data.pklF\u0000ZZZZZZZZï¿½\u0002ccollections\n",
      "OrderedDict\n",
      "q\u0000)Rq\u0001(\u0000\u0000\u00000.weightq\u0002ctorch._utils\n"
     ]
    }
   ],
   "source": [
    "# Pytorch uses a version of pickle to save the weights\n",
    "!head -n 3 model_weights.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1280c676-407b-44b0-83c8-87656237a9de",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# some time later...\n",
    "model2 = nn.Sequential(\n",
    "    nn.Linear(10,10),\n",
    "    nn.Tanh(),\n",
    "    nn.Linear(10,3)\n",
    ")\n",
    "\n",
    "model2.load_state_dict(torch.load('model_weights.pt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fffa20f-db29-4500-9c88-281bb57060e4",
   "metadata": {},
   "source": [
    "Using the state dict required that we instantiate the model class first. We can also save the model structure together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c622fb42-99f0-4985-8811-b3943f63b4ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.save(model, 'model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "77e8fafe-e2da-4f36-be7d-7a54d60546f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model2 = torch.load('model.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51be37da-62d4-4d80-9621-923550ebacfd",
   "metadata": {},
   "source": [
    "**`eval`/`train` modes.** Some layers need to behave differently at training time and evaluation time. These can all be toggled with the `train()` and `eval()` methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2261f527-7b93-4209-a1d2-81862dabd4b3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1891,  0.3391,  0.8269,  1.6241,  0.7730],\n",
      "        [ 0.1412,  0.7913, -0.5472,  0.4971, -0.1926],\n",
      "        [-0.9877, -0.7166, -0.0323, -0.2046,  1.9819]], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3782,  0.0000,  0.0000,  3.2482,  0.0000],\n",
       "        [ 0.0000,  1.5826, -1.0944,  0.9942, -0.3851],\n",
       "        [-0.0000, -1.4331, -0.0000, -0.0000,  0.0000]], device='cuda:0')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer = nn.Dropout(0.5)\n",
    "\n",
    "# the default mode is \"training\"\n",
    "x = torch.randn(3, 5)\n",
    "print(x)\n",
    "layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4d9d9fdc-e5a1-4c5c-9c7f-c5100a4b713e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1891,  0.3391,  0.8269,  1.6241,  0.7730],\n",
       "        [ 0.1412,  0.7913, -0.5472,  0.4971, -0.1926],\n",
       "        [-0.9877, -0.7166, -0.0323, -0.2046,  1.9819]], device='cuda:0')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# switch to eval:\n",
    "layer.eval()\n",
    "layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fafbcf6f-f58e-440f-b750-00422d81ccea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3782,  0.6783,  1.6537,  3.2482,  1.5461],\n",
       "        [ 0.2823,  0.0000, -1.0944,  0.0000, -0.3851],\n",
       "        [-0.0000, -1.4331, -0.0646, -0.4092,  3.9638]], device='cuda:0')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# switch back to train\n",
    "layer.train()\n",
    "layer(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c1b63d-d265-4b56-b4f6-6bd9f57f9a61",
   "metadata": {},
   "source": [
    "## Writing custom modules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df47e22-665b-4a03-a68c-e3a3e78777c9",
   "metadata": {},
   "source": [
    "You can make your own modules. To do so, subclass `nn.Module` and define the `__init__` and `forward` method. These modules can be used just like any other module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dd280661-ac02-43b4-aa48-e88d198f643b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNetwork(\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (encoder): Sequential(\n",
       "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (5): ReLU()\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=256, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        The __init__ method defines all of the modules/parameters that will \n",
    "        appear in the model.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(256,1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Define how to get from the input to the output. \n",
    "        You can use arbitrary python code here so long as the \n",
    "        tensor operations are differentiable. \n",
    "        \"\"\"\n",
    "        x = self.flatten(x)\n",
    "        h = self.encoder(x)\n",
    "        y = self.classifier(h)\n",
    "        return y\n",
    "    \n",
    "model = NeuralNetwork()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "29f14f3b-2f82-422e-af82-26acfcec7447",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1180],\n",
       "        [0.0702],\n",
       "        [0.0694],\n",
       "        [0.1116],\n",
       "        [0.1236]], device='cuda:0', grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# simulate a batch of grayscale images:\n",
    "x = torch.randn(5, 1, 28, 28)\n",
    "\n",
    "model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155cb812-a6d0-4dd4-9523-864a78ee524b",
   "metadata": {},
   "source": [
    "You can customize your network however you see fit. For example, say we had a problem where the network took two images as input and made some decision about them. We could do something like this: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c8e58226-2338-4fb4-b303-efe9967e5982",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PairNetwork(\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (encoder): Sequential(\n",
       "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (5): ReLU()\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=512, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class PairNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        The __init__ method defines all of the modules/parameters that will \n",
    "        appear in the model.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(2*256,1)  # double the representation size\n",
    "        )\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        \"\"\"\n",
    "        Define how to get from the input to the output. \n",
    "        You can use arbitrary python code here so long as the \n",
    "        tensor operations are differentiable. \n",
    "        \"\"\"\n",
    "        x1 = self.flatten(x1)\n",
    "        h1 = self.encoder(x1)\n",
    "        \n",
    "        x2 = self.flatten(x2)\n",
    "        h2 = self.encoder(x2)\n",
    "        \n",
    "        # fuse the representations\n",
    "        h = torch.concat([h1, h2], axis=-1)\n",
    "        \n",
    "        y = self.classifier(h)\n",
    "        return y\n",
    "    \n",
    "pair_model = PairNetwork()\n",
    "pair_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4bcc4c8c-9d65-4362-a584-346ceca80017",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0418],\n",
       "        [ 0.0130],\n",
       "        [-0.0402],\n",
       "        [ 0.0025],\n",
       "        [ 0.0232]], device='cuda:0', grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# simulate a batch of grayscale images:\n",
    "x1 = torch.randn(5, 1, 28, 28)\n",
    "x2 = torch.randn(5, 1, 28, 28)\n",
    "\n",
    "pair_model(x1, x2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b1f7a9-1bf8-485e-9064-b8ad9c821b70",
   "metadata": {},
   "source": [
    "**Tracking parameters** Pytorch automatically tracks all of the parameters that appear in your custom model. This allows Pytorch to optimize the network during training. It allows can allow you to get diagnostic information such as the number of parameters in your model: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "882bfee0-0813-463d-8e8e-80e2fc3cac00",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 796161\n"
     ]
    }
   ],
   "source": [
    "num_pars = sum([p.numel() for p in model.parameters()])\n",
    "print(\"Number of parameters:\", num_pars)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
