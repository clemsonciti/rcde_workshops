{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to Natural Language Processing\n",
    "Welcome to NLP. NLP aims to enable computers to understand, interpret, and generate human language in a way that is both meaningful and useful.\n",
    "Applications of NLP range from sentiment analysis, machine translation, chatbots, speech recognition, text summarization, and information retrieval.\n",
    "In this notebook, we'll dive into the world of text analysis.\n",
    "We will explore ways to extract meaning from text, and build a model that can classify newsgroups post into their respective topics.\n",
    "We'll be using a simplistic technique called Bag of Words,\n",
    "which involves representing text as numerical vectors of words represented their frequency and index."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "To start off let's get some data. The dataset we are going to use is the 20 newsgroups dataset from `scikit-learn`.\n",
    "The dataset comprises around 18000 newsgroups posts on 20 topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "news_dataset = fetch_20newsgroups(data_home='./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label_number</th>\n",
       "      <th>label_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>From: lerxst@wam.umd.edu (where's my thing)\\nS...</td>\n",
       "      <td>7</td>\n",
       "      <td>./20news_home/20news-bydate-train/rec.autos/10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>From: guykuo@carson.u.washington.edu (Guy Kuo)...</td>\n",
       "      <td>4</td>\n",
       "      <td>./20news_home/20news-bydate-train/comp.sys.mac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>From: twillis@ec.ecn.purdue.edu (Thomas E Will...</td>\n",
       "      <td>4</td>\n",
       "      <td>./20news_home/20news-bydate-train/comp.sys.mac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>From: jgreen@amber (Joe Green)\\nSubject: Re: W...</td>\n",
       "      <td>1</td>\n",
       "      <td>./20news_home/20news-bydate-train/comp.graphic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From: jcm@head-cfa.harvard.edu (Jonathan McDow...</td>\n",
       "      <td>14</td>\n",
       "      <td>./20news_home/20news-bydate-train/sci.space/60880</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label_number  \\\n",
       "0  From: lerxst@wam.umd.edu (where's my thing)\\nS...             7   \n",
       "1  From: guykuo@carson.u.washington.edu (Guy Kuo)...             4   \n",
       "2  From: twillis@ec.ecn.purdue.edu (Thomas E Will...             4   \n",
       "3  From: jgreen@amber (Joe Green)\\nSubject: Re: W...             1   \n",
       "4  From: jcm@head-cfa.harvard.edu (Jonathan McDow...            14   \n",
       "\n",
       "                                          label_name  \n",
       "0  ./20news_home/20news-bydate-train/rec.autos/10...  \n",
       "1  ./20news_home/20news-bydate-train/comp.sys.mac...  \n",
       "2  ./20news_home/20news-bydate-train/comp.sys.mac...  \n",
       "3  ./20news_home/20news-bydate-train/comp.graphic...  \n",
       "4  ./20news_home/20news-bydate-train/sci.space/60880  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# make a pandas dataframe out of the dataset\n",
    "df = pd.DataFrame({\n",
    "    'text': news_dataset.data,\n",
    "    'label_number': news_dataset.target,\n",
    "    'label_name': news_dataset.filenames\n",
    "})\n",
    "\n",
    "# df = df[:1000]\n",
    "\n",
    "#  Let's see what's in it\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Data\n",
    "In order to get usable data, we must transform the data to be suitable for analysis.\n",
    "We'll be using some regular expression to clean out unwanted strings and\n",
    "the `CountVectorizer` from scikit-learn to transform the collection of text\n",
    " into a matrix of token counts where each row represents a document and\n",
    "  each column represents a unique word in the document collection.\n",
    "  Let's see it in action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\"From: lerxst@wam.umd.edu (where's my thing)\\n\"\n",
      " 'Subject: WHAT car is this!?\\n'\n",
      " 'Nntp-Posting-Host: rac3.wam.umd.edu\\n'\n",
      " 'Organization: University of Maryland, College Park\\n'\n",
      " 'Lines: 15\\n'\n",
      " '\\n'\n",
      " ' I was wondering if anyone out there could enlighten me on this car I saw\\n'\n",
      " 'the other day. It was a 2-door sports car, looked to be from the late 60s/\\n'\n",
      " 'early 70s. It was called a Bricklin. The doors were really small. In '\n",
      " 'addition,\\n'\n",
      " 'the front bumper was separate from the rest of the body. This is \\n'\n",
      " 'all I know. If anyone can tellme a model name, engine specs, years\\n'\n",
      " 'of production, where this car is made, history, or whatever info you\\n'\n",
      " 'have on this funky looking car, please e-mail.\\n'\n",
      " '\\n'\n",
      " 'Thanks,\\n'\n",
      " '- IL\\n'\n",
      " '   ---- brought to you by your neighborhood Lerxst ----\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n'\n",
      " '\\n')\n",
      "(\"From  lerxst wam umd edu  where's my thing  Subject  WHAT car is this   Nntp \"\n",
      " 'Posting Host  rac  wam umd edu Organization  University of Maryland  College '\n",
      " 'Park Lines       I was wondering if anyone out there could enlighten me on '\n",
      " 'this car I saw the other day  It was a   door sports car  looked to be from '\n",
      " 'the late   s  early   s  It was called a Bricklin  The doors were really '\n",
      " 'small  In addition  the front bumper was separate from the rest of the body  '\n",
      " 'This is  all I know  If anyone can tellme a model name  engine specs  years '\n",
      " 'of production  where this car is made  history  or whatever info you have on '\n",
      " 'this funky looking car  please e mail   Thanks    IL         brought to you '\n",
      " 'by your neighborhood Lerxst          ')\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from pprint import pprint\n",
    "\n",
    "def clean_df(df: pd.DataFrame):\n",
    "    # The regex matches HTML-like tags (e.g., <tag />), \n",
    "    # non-word characters (excluding spaces and apostrophes), digits, and underscores\n",
    "    regex = re.compile('<\\\\w+ /?>|[^\\\\w \\']|\\\\d|_')\n",
    "    \n",
    "    # Replace the matched substrings with a space and re-assign the result\n",
    "    df['text'] = df['text'].replace(regex, ' ', regex=True)\n",
    "\n",
    "    def extract_label_name(text: str):\n",
    "        # The regex matches the path to the file and extracts the 3rd directory\n",
    "        match = re.match(r'\\./(.+)\\\\(.+)\\\\(.+)\\\\(.+)', text)\n",
    "        return match.group(3) if match else text\n",
    "\n",
    "    # extract label_name\n",
    "    df['label_name'] = df.label_name.apply(extract_label_name)\n",
    "\n",
    "    return df\n",
    "\n",
    "# before\n",
    "pprint(df.iloc[0]['text'])\n",
    "\n",
    "clean_df(df)\n",
    "\n",
    "# after\n",
    "pprint(df.iloc[0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "We're working with 18,000 newsgroup posts across 20 topics. What challenges do you think we'll face that are unique to text data compared to the image data we've worked with before?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee53216640d74b17934755f1d10d4ecc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', layout=Layout(width='500px'), placeholder='Type your answer here')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3add16c44354419495c0b4a06873ecfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='success', description='Submit', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "785ea7ac66e4497a9ed70160011f13d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from utils import create_answer_box\n",
    "create_answer_box(\"We're working with 18,000 newsgroup posts across 20 topics. What challenges do you think we'll face that are unique to text data compared to the image data we've worked with before?\", \"08-01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label_number</th>\n",
       "      <th>label_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>From  lerxst wam umd edu  where's my thing  Su...</td>\n",
       "      <td>7</td>\n",
       "      <td>./20news_home/20news-bydate-train/rec.autos/10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>From  guykuo carson u washington edu  Guy Kuo ...</td>\n",
       "      <td>4</td>\n",
       "      <td>./20news_home/20news-bydate-train/comp.sys.mac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>From  twillis ec ecn purdue edu  Thomas E Will...</td>\n",
       "      <td>4</td>\n",
       "      <td>./20news_home/20news-bydate-train/comp.sys.mac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>From  jgreen amber  Joe Green  Subject  Re  We...</td>\n",
       "      <td>1</td>\n",
       "      <td>./20news_home/20news-bydate-train/comp.graphic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From  jcm head cfa harvard edu  Jonathan McDow...</td>\n",
       "      <td>14</td>\n",
       "      <td>./20news_home/20news-bydate-train/sci.space/60880</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label_number  \\\n",
       "0  From  lerxst wam umd edu  where's my thing  Su...             7   \n",
       "1  From  guykuo carson u washington edu  Guy Kuo ...             4   \n",
       "2  From  twillis ec ecn purdue edu  Thomas E Will...             4   \n",
       "3  From  jgreen amber  Joe Green  Subject  Re  We...             1   \n",
       "4  From  jcm head cfa harvard edu  Jonathan McDow...            14   \n",
       "\n",
       "                                          label_name  \n",
       "0  ./20news_home/20news-bydate-train/rec.autos/10...  \n",
       "1  ./20news_home/20news-bydate-train/comp.sys.mac...  \n",
       "2  ./20news_home/20news-bydate-train/comp.sys.mac...  \n",
       "3  ./20news_home/20news-bydate-train/comp.graphic...  \n",
       "4  ./20news_home/20news-bydate-train/sci.space/60880  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# stop_words='english' removes common English words like \"a\" or \"the' from the text\n",
    "vectorizer = CountVectorizer(stop_words='english', lowercase=True, max_df=.5, min_df=10)\n",
    "bag_of_words = vectorizer.fit_transform(df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11314, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Compressed Sparse Row sparse matrix of dtype 'int64'\n",
       "\twith 981191 stored elements and shape (11314, 14060)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_of_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['aa', 'aaa', 'aardvark', ..., 'zx', 'zyeh', 'zz'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see some of the tokens it collected\n",
    "vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "\n",
    "Now let's use the cleaned `Dataframe` to make a pytorch `Dataset` so that we can manage and load data into our model later.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class NewsGroupsDataset(Dataset):\n",
    "\n",
    "    def __init__(self, df: pd.DataFrame):\n",
    "        self.df = df\n",
    "        self.vectorizer = CountVectorizer(stop_words='english', lowercase=True, max_df=.5, min_df=10)\n",
    "\n",
    "        # fit vectorizer\n",
    "        self.bag_of_words = self.vectorizer.fit_transform(self.df['text'])\n",
    "\n",
    "    def __getitem__(self, index: int):\n",
    "        # note: CrossEntropyLoss requires the datatype to be floats\n",
    "\n",
    "        # converting bag-of-words representation into numpy array\n",
    "        X = self.bag_of_words[index].toarray().squeeze().astype(np.float32)\n",
    "\n",
    "        # one-hot encoded vector representing the target data\n",
    "        # Y = [0.0] * len(self.classes)\n",
    "        # Y[self.df.iloc[index]['label_number']] = 1.0\n",
    "        # Y = torch.tensor(Y)\n",
    "        Y = self.df.iloc[index]['label_number']\n",
    "\n",
    "        return X, Y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    @property\n",
    "    def classes(self):\n",
    "        return fetch_20newsgroups(data_home='./').target_names\n",
    "\n",
    "    @property\n",
    "    def vocab_size(self):\n",
    "        return len(self.vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0., 0., 0., ..., 0., 0., 0.], dtype=float32), 7)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = NewsGroupsDataset(df)\n",
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "We're using bag-of-words, but you might have heard of word embeddings or transformers. What advantages might those approaches have over counting words?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "703d00805be741d5b86a134793ea0cea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', layout=Layout(width='500px'), placeholder='Type your answer here')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94307c79a1fa4ff583a0978eb7164a85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='success', description='Submit', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "508cdae6479342a4a1fb79940b7ff9f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "create_answer_box(\"We're using bag-of-words, but you might have heard of word embeddings or transformers. What advantages might those approaches have over counting words?\", \"08-02\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper parameters\n",
    "Set some hyper parameters for our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "epochs = 10\n",
    "batch_size = 128\n",
    "lr = 1e-3\n",
    "num_workers = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "Next, let's make the model. We'll make a super simple linear regression model using `pytorch_lightning`.\n",
    "For those that are unfamiliar with the library, PyTorch Lightning is a lightweight and flexible PyTorch wrapper\n",
    "that allows you to focus on the high-level structure of your deep learning models rather than the low-level details of PyTorch.\n",
    "\n",
    "Here are a list of basic things we will need in pytorch lightning model to get started.\n",
    "1) the forward function\n",
    "2) training_step and validation_step\n",
    "4) configure_optimizers\n",
    "5) train_dataloader and val_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch.utils.data import SubsetRandomSampler\n",
    "from torch.utils.data import DataLoader\n",
    "import pytorch_lightning as pl\n",
    "import torchmetrics\n",
    "\n",
    "class LitModel(pl.LightningModule):\n",
    "    def __init__(self, in_features: int, out_features: int, hidden_units=16, *, dataset=dataset):\n",
    "        super().__init__()\n",
    "        self.dataset = dataset\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "        self.metric = torchmetrics.Accuracy(task='multiclass', num_classes=len(self.dataset.classes))\n",
    "\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.hidden_units = hidden_units\n",
    "\n",
    "        # setting up samplers to split data for training and evaluation\n",
    "        dataset_indices = list(range(len(self.dataset)))\n",
    "        np.random.shuffle(dataset_indices)\n",
    "        split_index = int(np.floor(0.2 * len(self.dataset)))\n",
    "        train_indices, val_indices = dataset_indices[split_index:], dataset_indices[:split_index]\n",
    "        self.train_sampler = SubsetRandomSampler(train_indices)\n",
    "        self.val_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "        # layers\n",
    "        self.layer = nn.Sequential(\n",
    "            nn.Identity()\n",
    "            #nn.Linear(self.in_features, self.hidden_units),\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.LazyLinear(self.out_features),\n",
    "        )\n",
    "\n",
    "    def forward(self, X: torch.Tensor):\n",
    "        outputs = self.layer(X)\n",
    "        return self.fc(outputs)\n",
    "\n",
    "    def training_step(self, batch: torch.Tensor, index: int):\n",
    "        x, y = batch\n",
    "        # forward pass\n",
    "        output = self(x)\n",
    "        # calculate loss\n",
    "        loss = self.loss_fn(output, y)\n",
    "        # log data to a logger\n",
    "        self.log('train_loss', loss.item(), on_step=True, sync_dist=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch: torch.Tensor, index: int):\n",
    "        x, y = batch\n",
    "        # forward pass\n",
    "        output = self(x)\n",
    "        # calculate loss\n",
    "        loss = self.loss_fn(output, y)\n",
    "\n",
    "        accuracy = self.metric(torch.argmax(output, dim=-1), y).item()\n",
    "\n",
    "        # log data to a logger\n",
    "        self.log('val_loss', loss.item(), on_step=True, sync_dist=True)\n",
    "        self.log('accuracy', accuracy, on_epoch=True, sync_dist=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=lr)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        train_loader = DataLoader(\n",
    "            dataset=dataset,\n",
    "            batch_size=batch_size,\n",
    "            sampler=self.train_sampler,\n",
    "            num_workers=num_workers\n",
    "        )\n",
    "        return train_loader\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        val_loader = DataLoader(\n",
    "            dataset=dataset,\n",
    "            batch_size=batch_size,\n",
    "            sampler=self.val_sampler,\n",
    "            num_workers=num_workers\n",
    "        )\n",
    "        return val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "We're doing a random 80/20 split for training/validation. For text classification, what other splitting strategies might be important? What could go wrong with random splits?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa260e416af24bd396934b02ec56ed11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', layout=Layout(width='500px'), placeholder='Type your answer here')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8df8a4f6baa84ee88a326fac0d922fb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='success', description='Submit', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6eac9693f4548b586dcf265cc501a33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "create_answer_box(\"We're doing a random 80/20 split for training/validation. For text classification, what other splitting strategies might be important? What could go wrong with random splits?\", \"08-03\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "model = LitModel(\n",
    "    in_features=dataset.vocab_size,\n",
    "    out_features=len(dataset.classes),\n",
    "    hidden_units=32,\n",
    "    dataset=dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trainer\n",
    "To train our model, we'll need a `Trainer`.\n",
    "The `Trainer` is a high-level module that provides a simple and consistent interface for training, validation, and testing your PyTorch models.\n",
    "We'll also want to log our data with a logger. You will need a Wandb account to view you're logs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cehrett/.conda/envs/PytorchWorkshop/lib/python3.11/site-packages/lightning_fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /home/cehrett/.conda/envs/PytorchWorkshop/lib/python ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from pytorch_lightning import Trainer\n",
    "logger = WandbLogger(\n",
    "    project='lightning_logs',\n",
    "    name='experiment1')\n",
    "trainer = Trainer(max_epochs=epochs, logger=logger, log_every_n_steps=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA A100 80GB PCIe') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcehrett\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Unable to render HTML, can't import display from ipython.core\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Unable to render HTML, can't import display from ipython.core\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Unable to render HTML, can't import display from ipython.core\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Unable to render HTML, can't import display from ipython.core\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Unable to render HTML, can't import display from ipython.core\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/home/cehrett/.conda/envs/PytorchWorkshop/lib/python3.11/site-packages/pytorch_lightning/utilities/model_summary/model_summary.py:477: The total number of parameters detected may be inaccurate because the model contains an instance of `UninitializedParameter`. To get an accurate number, set `self.example_input_array` in your LightningModule.\n",
      "\n",
      "  | Name    | Type               | Params | Mode \n",
      "-------------------------------------------------------\n",
      "0 | loss_fn | CrossEntropyLoss   | 0      | train\n",
      "1 | metric  | MulticlassAccuracy | 0      | train\n",
      "2 | layer   | Sequential         | 0      | train\n",
      "3 | fc      | Sequential         | 0      | train\n",
      "-------------------------------------------------------\n",
      "0         Trainable params\n",
      "0         Non-trainable params\n",
      "0         Total params\n",
      "0.000     Total estimated model params size (MB)\n",
      "6         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b6c2fe7b63b4182952373dabd900212",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cehrett/.conda/envs/PytorchWorkshop/lib/python3.11/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b95143808274faf99633bbd7c6508a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f53c651adaa34586a4a6d3e4d19321ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0f11f4a6f9c4b8abbcf9c2e8485bb71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9ae4fd2667c43709eefc86b63593c0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "405d09acede04ff6ae014e85a7185869",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9eb3b98d2b54809a218711301fdc678",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc4487b4cb6149e78c353ca9ad5e895b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b77087e03da4ab3922a6774cc2c7d3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e7b4ec482b34c5599e198c6e73174c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdd11dc2bfcb4a3db9e5b74f212614ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e9fcbbb20414f6cbbe532a49e0b7ccc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Unable to render Widget, can't import display from ipython.core\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Unable to render HTML, can't import display from ipython.core\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Unable to render HTML, can't import display from ipython.core\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Unable to render HTML, can't import display from ipython.core\n"
     ]
    }
   ],
   "source": [
    "logger.experiment.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improvement\n",
    "There are ways to improve a model. One way is to try different model architectures.\n",
    "Let's start by introducing non-linearity with the `ReLU` activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "model = LitModel(\n",
    "    in_features=dataset.vocab_size,\n",
    "    out_features=len(dataset.classes),\n",
    "    hidden_units=32,\n",
    "    dataset=dataset\n",
    ")\n",
    "model.layer = nn.Sequential(\n",
    "    nn.Linear(model.in_features, model.hidden_units),\n",
    "    nn.ReLU(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "logger = WandbLogger(name='experiment2', project='lightning_logs')\n",
    "trainer = Trainer(max_epochs=epochs, logger=logger, log_every_n_steps=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "logger.experiment.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did it improve?\n",
    "Try adding regularization with `Dropout`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "model = LitModel(\n",
    "    in_features=dataset.vocab_size,\n",
    "    out_features=len(dataset.classes),\n",
    "    hidden_units=32,\n",
    "    dataset=dataset\n",
    ")\n",
    "model.layer = nn.Sequential(\n",
    "    nn.Linear(model.in_features, model.hidden_units),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(.2),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "logger = WandbLogger(name='experiment2', project='lightning_logs')\n",
    "trainer = Trainer(max_epochs=epochs, logger=logger, log_every_n_steps=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "logger.experiment.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "Machine learning requires lots of experimenting.\n",
    "It often requires trying out different models, hyperparameters, and preprocessing techniques to achieve optimal results.\n",
    "This is only the start of NLP. Throughout the workshop you may find other approaches to this problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Thank you for taking part in the Beginner Pytorch workshop! Please take a moment to describe what you think could improve this workshop's usefulness for you and students like you in the future."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3efb506e568c49d5a098d5963f6c44c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', layout=Layout(width='500px'), placeholder='Type your answer here')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bef51f82ce1041f3b151d2e91ab091a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='success', description='Submit', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bbeaf9f8bac47c98bf53069d1018367",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "create_answer_box(\"Thank you for taking part in the Beginner Pytorch workshop! Please take a moment to describe what you think could improve this workshop's usefulness for you and students like you in the future.\", \"08-04\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PytorchWorkshop",
   "language": "python",
   "name": "pytorchworkshop"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
