{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8n40xD862nhd"
   },
   "source": [
    "# Training Techniques\n",
    "The [Pytorch Ligtning](https://www.pytorchlightning.ai/index.html) `Trainer` class implements many advanced features to improve training speed, convergence, reproducibility, etc. In this notebook, we apply a number of these features to our EMNIST dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from utils import models\n",
    "from torchvision.models import resnet18, ResNet18_Weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_dir = f\"/scratch/{os.environ['USER']}/data\"\n",
    "model_path = f\"/scratch/{os.environ['USER']}/model.pt\"\n",
    "\n",
    "# Model and Training\n",
    "epochs=2 # number of training epochs\n",
    "batch_size=128 #input batch size for training (default: 64)\n",
    "test_batch_size=1000 #input batch size for testing (default: 1000)\n",
    "num_workers=10 # parallel data loading to speed things up\n",
    "lr=0.1 #learning rate (default: 0.1)\n",
    "gamma=0.7 #Learning rate step gamma (default: 0.7)\n",
    "seed=42 #random seed (default: 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7NGHwURr8or8"
   },
   "source": [
    "## EMNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils import data\n",
    "\n",
    "# transforms (we may wish to experiment with these so leave as inputs)\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "test_transforms = train_transforms\n",
    "\n",
    "train_loader = data.get_train_dataloader(data_dir, train_transforms, batch_size, num_workers)\n",
    "test_loader = data.get_test_dataloader(data_dir, test_transforms, test_batch_size, num_workers)\n",
    "\n",
    "# save a test batch for later testing\n",
    "image_gen = iter(test_loader)\n",
    "test_img, test_trg = next(image_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset: Dataset EMNIST\n",
      "    Number of datapoints: 112800\n",
      "    Root location: /scratch/dane2/data\n",
      "    Split: Train\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               ToTensor()\n",
      "               Normalize(mean=(0.1307,), std=(0.3081,))\n",
      "           )\n",
      "Testing dataset: Dataset EMNIST\n",
      "    Number of datapoints: 18800\n",
      "    Root location: /scratch/dane2/data\n",
      "    Split: Test\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               ToTensor()\n",
      "               Normalize(mean=(0.1307,), std=(0.3081,))\n",
      "           )\n"
     ]
    }
   ],
   "source": [
    "print(\"Training dataset:\", train_loader.dataset)\n",
    "print(\"Testing dataset:\", test_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test batch\n",
    "x, y = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init the classifier\n",
    "pt_model = models.Classifier() #models.make_resnet18_model(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
    "\n",
    "# init the lazy layers\n",
    "with torch.no_grad():\n",
    "    pt_model(x)\n",
    "    \n",
    "# create the ligtning model\n",
    "# Note: since the last notebook, we moved the LitModel logic into utils.models\n",
    "model = models.LitModel(pt_model, lr, gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type               | Params\n",
      "-------------------------------------------------\n",
      "0 | model     | Classifier         | 23.1 K\n",
      "1 | train_acc | MulticlassAccuracy | 0     \n",
      "2 | test_acc  | MulticlassAccuracy | 0     \n",
      "-------------------------------------------------\n",
      "23.1 K    Trainable params\n",
      "0         Non-trainable params\n",
      "23.1 K    Total params\n",
      "0.093     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73b4f7ad1d494bdfbd46f8434e2a4588",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=2` reached.\n"
     ]
    }
   ],
   "source": [
    "from lightning.pytorch import loggers as pl_loggers\n",
    "from lightning.pytorch import Trainer\n",
    "\n",
    "# a logger to save results\n",
    "csv_logger = pl_loggers.CSVLogger(save_dir=\"logs/\")\n",
    "\n",
    "# the trainer class has about a million arguments. For now, the defaults will suffice.\n",
    "trainer = Trainer(max_epochs=epochs, logger=csv_logger)\n",
    "trainer.fit(model, train_loader, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See `logs/lightning_logs` for results. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model profiling\n",
    "Profiling tools show you how much time each part of your training code is taking. This can help you identify areas where your program should be optimized in order to speed things up. \n",
    "\n",
    "[Pytorch has a built in profiler](https://pytorch.org/tutorials/recipes/recipes/profiler_recipe.html). We can easily turn this on in Lightning by setting the `profiler` argument in the trainer. Note that the Pytorch profiler forces synchronous cuda execution. That makes things take longer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init the classifier\n",
    "pt_model = models.Classifier() #models.make_resnet18_model(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
    "\n",
    "# init the lazy layers\n",
    "with torch.no_grad():\n",
    "    pt_model(x)\n",
    "    \n",
    "# create the ligtning model\n",
    "model = models.LitModel(pt_model, lr, gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type               | Params\n",
      "-------------------------------------------------\n",
      "0 | model     | Classifier         | 23.1 K\n",
      "1 | train_acc | MulticlassAccuracy | 0     \n",
      "2 | test_acc  | MulticlassAccuracy | 0     \n",
      "-------------------------------------------------\n",
      "23.1 K    Trainable params\n",
      "0         Non-trainable params\n",
      "23.1 K    Total params\n",
      "0.093     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cfb766397d54b98a46738b25ac0164b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=2` reached.\n",
      "FIT Profiler Report\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|  Action                                                                                                                                                         \t|  Mean duration (s)\t|  Num calls      \t|  Total time (s) \t|  Percentage %   \t|\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|  Total                                                                                                                                                          \t|  -              \t|  64189          \t|  14.797         \t|  100 %          \t|\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|  run_training_epoch                                                                                                                                             \t|  6.672          \t|  2              \t|  13.344         \t|  90.182         \t|\n",
      "|  run_training_batch                                                                                                                                             \t|  0.0041982      \t|  1764           \t|  7.4056         \t|  50.049         \t|\n",
      "|  [LightningModule]LitModel.optimizer_step                                                                                                                       \t|  0.0041312      \t|  1764           \t|  7.2875         \t|  49.251         \t|\n",
      "|  [Strategy]SingleDeviceStrategy.training_step                                                                                                                   \t|  0.0023097      \t|  1764           \t|  4.0742         \t|  27.535         \t|\n",
      "|  [Callback]TQDMProgressBar.on_train_batch_end                                                                                                                   \t|  0.0010392      \t|  1764           \t|  1.8332         \t|  12.389         \t|\n",
      "|  [Strategy]SingleDeviceStrategy.backward                                                                                                                        \t|  0.00097618     \t|  1764           \t|  1.722          \t|  11.638         \t|\n",
      "|  [_EvaluationLoop].val_next                                                                                                                                     \t|  0.016218       \t|  41             \t|  0.66495        \t|  4.4939         \t|\n",
      "|  [_TrainingEpochLoop].train_dataloader_next                                                                                                                     \t|  0.00020906     \t|  1764           \t|  0.36878        \t|  2.4923         \t|\n",
      "|  [Strategy]SingleDeviceStrategy.batch_to_device                                                                                                                 \t|  0.00016747     \t|  1804           \t|  0.30211        \t|  2.0417         \t|\n",
      "|  [LightningModule]LitModel.transfer_batch_to_device                                                                                                             \t|  0.0001305      \t|  1804           \t|  0.23541        \t|  1.591          \t|\n",
      "|  [Strategy]SingleDeviceStrategy.validation_step                                                                                                                 \t|  0.0034089      \t|  40             \t|  0.13635        \t|  0.92152        \t|\n",
      "|  [LightningModule]LitModel.optimizer_zero_grad                                                                                                                  \t|  7.4632e-05     \t|  1764           \t|  0.13165        \t|  0.88972        \t|\n",
      "|  [Callback]TQDMProgressBar.on_validation_start                                                                                                                  \t|  0.040434       \t|  3              \t|  0.1213         \t|  0.81979        \t|\n",
      "|  [LightningModule]LitModel.configure_gradient_clipping                                                                                                          \t|  1.8325e-05     \t|  1764           \t|  0.032326       \t|  0.21846        \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_train_batch_end       \t|  1.7976e-05     \t|  1764           \t|  0.031709       \t|  0.2143         \t|\n",
      "|  [Callback]TQDMProgressBar.on_validation_batch_end                                                                                                              \t|  0.00062314     \t|  40             \t|  0.024926       \t|  0.16845        \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_train_epoch_end       \t|  0.01069        \t|  2              \t|  0.02138        \t|  0.14449        \t|\n",
      "|  [Callback]TQDMProgressBar.on_train_start                                                                                                                       \t|  0.012711       \t|  1              \t|  0.012711       \t|  0.085902       \t|\n",
      "|  [Callback]TQDMProgressBar.on_sanity_check_start                                                                                                                \t|  0.011467       \t|  1              \t|  0.011467       \t|  0.077495       \t|\n",
      "|  [Callback]ModelSummary.on_train_batch_end                                                                                                                      \t|  3.5871e-06     \t|  1764           \t|  0.0063276      \t|  0.042764       \t|\n",
      "|  [Callback]TQDMProgressBar.on_before_zero_grad                                                                                                                  \t|  3.0775e-06     \t|  1764           \t|  0.0054287      \t|  0.036688       \t|\n",
      "|  [Callback]TQDMProgressBar.on_validation_batch_start                                                                                                            \t|  0.000128       \t|  40             \t|  0.0051199      \t|  0.034601       \t|\n",
      "|  [Callback]TQDMProgressBar.on_train_batch_start                                                                                                                 \t|  2.6424e-06     \t|  1764           \t|  0.0046612      \t|  0.031502       \t|\n",
      "|  [Callback]TQDMProgressBar.on_after_backward                                                                                                                    \t|  2.566e-06      \t|  1764           \t|  0.0045265      \t|  0.030591       \t|\n",
      "|  [Callback]TQDMProgressBar.on_before_backward                                                                                                                   \t|  2.4907e-06     \t|  1764           \t|  0.0043937      \t|  0.029694       \t|\n",
      "|  [Callback]TQDMProgressBar.on_before_optimizer_step                                                                                                             \t|  1.8815e-06     \t|  1764           \t|  0.0033191      \t|  0.022431       \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_after_backward        \t|  1.6706e-06     \t|  1764           \t|  0.0029469      \t|  0.019916       \t|\n",
      "|  [LightningModule]LitModel.on_before_batch_transfer                                                                                                             \t|  1.5896e-06     \t|  1804           \t|  0.0028677      \t|  0.01938        \t|\n",
      "|  [Callback]ModelSummary.on_before_zero_grad                                                                                                                     \t|  1.5617e-06     \t|  1764           \t|  0.0027549      \t|  0.018618       \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_before_zero_grad      \t|  1.5176e-06     \t|  1764           \t|  0.002677       \t|  0.018092       \t|\n",
      "|  [Callback]ModelSummary.on_train_batch_start                                                                                                                    \t|  1.4731e-06     \t|  1764           \t|  0.0025985      \t|  0.017561       \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_train_batch_start     \t|  1.4309e-06     \t|  1764           \t|  0.0025241      \t|  0.017058       \t|\n",
      "|  [Callback]TQDMProgressBar.on_validation_end                                                                                                                    \t|  0.00081106     \t|  3              \t|  0.0024332      \t|  0.016444       \t|\n",
      "|  [Callback]ModelSummary.on_before_backward                                                                                                                      \t|  1.3715e-06     \t|  1764           \t|  0.0024193      \t|  0.01635        \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_before_backward       \t|  1.3586e-06     \t|  1764           \t|  0.0023965      \t|  0.016196       \t|\n",
      "|  [Callback]ModelSummary.on_after_backward                                                                                                                       \t|  1.2958e-06     \t|  1764           \t|  0.0022858      \t|  0.015448       \t|\n",
      "|  [LightningModule]LitModel.on_after_batch_transfer                                                                                                              \t|  1.2316e-06     \t|  1804           \t|  0.0022217      \t|  0.015015       \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_before_optimizer_step \t|  1.2388e-06     \t|  1764           \t|  0.0021852      \t|  0.014768       \t|\n",
      "|  [Callback]ModelSummary.on_before_optimizer_step                                                                                                                \t|  1.2288e-06     \t|  1764           \t|  0.0021675      \t|  0.014649       \t|\n",
      "|  [LightningModule]LitModel.on_train_batch_end                                                                                                                   \t|  1.1941e-06     \t|  1764           \t|  0.0021064      \t|  0.014236       \t|\n",
      "|  [Callback]TQDMProgressBar.on_train_epoch_start                                                                                                                 \t|  0.00097899     \t|  2              \t|  0.001958       \t|  0.013233       \t|\n",
      "|  [LightningModule]LitModel.on_train_batch_start                                                                                                                 \t|  1.0119e-06     \t|  1764           \t|  0.0017849      \t|  0.012063       \t|\n",
      "|  [LightningModule]LitModel.on_before_zero_grad                                                                                                                  \t|  9.9306e-07     \t|  1764           \t|  0.0017518      \t|  0.011839       \t|\n",
      "|  [LightningModule]LitModel.on_after_backward                                                                                                                    \t|  9.5494e-07     \t|  1764           \t|  0.0016845      \t|  0.011384       \t|\n",
      "|  [LightningModule]LitModel.on_before_backward                                                                                                                   \t|  9.1773e-07     \t|  1764           \t|  0.0016189      \t|  0.010941       \t|\n",
      "|  [LightningModule]LitModel.on_before_optimizer_step                                                                                                             \t|  8.0452e-07     \t|  1764           \t|  0.0014192      \t|  0.0095912      \t|\n",
      "|  [Strategy]SingleDeviceStrategy.on_train_batch_start                                                                                                            \t|  8.0104e-07     \t|  1764           \t|  0.001413       \t|  0.0095497      \t|\n",
      "|  [Callback]ModelSummary.on_fit_start                                                                                                                            \t|  0.001351       \t|  1              \t|  0.001351       \t|  0.0091307      \t|\n",
      "|  [LightningModule]LitModel.on_validation_model_eval                                                                                                             \t|  0.00039541     \t|  3              \t|  0.0011862      \t|  0.0080169      \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.setup                    \t|  0.00079733     \t|  1              \t|  0.00079733     \t|  0.0053885      \t|\n",
      "|  [Callback]TQDMProgressBar.on_train_epoch_end                                                                                                                   \t|  0.00034932     \t|  2              \t|  0.00069864     \t|  0.0047216      \t|\n",
      "|  [Callback]TQDMProgressBar.on_train_end                                                                                                                         \t|  0.00055111     \t|  1              \t|  0.00055111     \t|  0.0037245      \t|\n",
      "|  [LightningModule]LitModel.on_validation_model_train                                                                                                            \t|  0.00011774     \t|  3              \t|  0.00035323     \t|  0.0023872      \t|\n",
      "|  [LightningModule]LitModel.configure_optimizers                                                                                                                 \t|  0.00014666     \t|  1              \t|  0.00014666     \t|  0.00099116     \t|\n",
      "|  [Callback]ModelSummary.on_validation_batch_end                                                                                                                 \t|  3.5676e-06     \t|  40             \t|  0.0001427      \t|  0.00096444     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_validation_end        \t|  4.3696e-05     \t|  3              \t|  0.00013109     \t|  0.00088594     \t|\n",
      "|  [LightningModule]LitModel.lr_scheduler_step                                                                                                                    \t|  5.1686e-05     \t|  2              \t|  0.00010337     \t|  0.00069861     \t|\n",
      "|  [Callback]ModelSummary.on_validation_batch_start                                                                                                               \t|  1.9563e-06     \t|  40             \t|  7.8253e-05     \t|  0.00052886     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_validation_batch_end  \t|  1.7672e-06     \t|  40             \t|  7.0687e-05     \t|  0.00047772     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_validation_batch_start\t|  1.6458e-06     \t|  40             \t|  6.5831e-05     \t|  0.00044491     \t|\n",
      "|  [LightningModule]LitModel.on_validation_batch_end                                                                                                              \t|  1.1852e-06     \t|  40             \t|  4.7408e-05     \t|  0.0003204      \t|\n",
      "|  [LightningModule]LitModel.on_validation_batch_start                                                                                                            \t|  9.9554e-07     \t|  40             \t|  3.9821e-05     \t|  0.00026912     \t|\n",
      "|  [Strategy]SingleDeviceStrategy.on_validation_start                                                                                                             \t|  7.5934e-06     \t|  3              \t|  2.278e-05      \t|  0.00015395     \t|\n",
      "|  [Callback]ModelSummary.on_validation_start                                                                                                                     \t|  7.4717e-06     \t|  3              \t|  2.2415e-05     \t|  0.00015149     \t|\n",
      "|  [Callback]ModelSummary.on_validation_end                                                                                                                       \t|  3.2149e-06     \t|  3              \t|  9.6448e-06     \t|  6.5182e-05     \t|\n",
      "|  [Callback]TQDMProgressBar.on_validation_epoch_end                                                                                                              \t|  2.7524e-06     \t|  3              \t|  8.2571e-06     \t|  5.5804e-05     \t|\n",
      "|  [LightningModule]LitModel.on_train_epoch_end                                                                                                                   \t|  3.9898e-06     \t|  2              \t|  7.9796e-06     \t|  5.3928e-05     \t|\n",
      "|  [Callback]ModelSummary.on_train_epoch_end                                                                                                                      \t|  3.2689e-06     \t|  2              \t|  6.5379e-06     \t|  4.4185e-05     \t|\n",
      "|  [Callback]ModelSummary.on_train_epoch_start                                                                                                                    \t|  3.2475e-06     \t|  2              \t|  6.495e-06      \t|  4.3895e-05     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_validation_start      \t|  2.0663e-06     \t|  3              \t|  6.1989e-06     \t|  4.1894e-05     \t|\n",
      "|  [Callback]ModelSummary.on_train_start                                                                                                                          \t|  5.8357e-06     \t|  1              \t|  5.8357e-06     \t|  3.9439e-05     \t|\n",
      "|  [Callback]TQDMProgressBar.on_save_checkpoint                                                                                                                   \t|  2.9039e-06     \t|  2              \t|  5.8077e-06     \t|  3.925e-05      \t|\n",
      "|  [Callback]TQDMProgressBar.on_validation_epoch_start                                                                                                            \t|  1.7403e-06     \t|  3              \t|  5.221e-06      \t|  3.5285e-05     \t|\n",
      "|  [Callback]TQDMProgressBar.setup                                                                                                                                \t|  4.6473e-06     \t|  1              \t|  4.6473e-06     \t|  3.1408e-05     \t|\n",
      "|  [Callback]ModelSummary.on_validation_epoch_end                                                                                                                 \t|  1.5199e-06     \t|  3              \t|  4.5598e-06     \t|  3.0816e-05     \t|\n",
      "|  [LightningModule]LitModel.on_validation_end                                                                                                                    \t|  1.4435e-06     \t|  3              \t|  4.3306e-06     \t|  2.9268e-05     \t|\n",
      "|  [Callback]TQDMProgressBar.on_fit_end                                                                                                                           \t|  4.1407e-06     \t|  1              \t|  4.1407e-06     \t|  2.7984e-05     \t|\n",
      "|  [Callback]TQDMProgressBar.on_sanity_check_end                                                                                                                  \t|  4.122e-06      \t|  1              \t|  4.122e-06      \t|  2.7858e-05     \t|\n",
      "|  [LightningModule]LitModel.on_train_epoch_start                                                                                                                 \t|  2.0051e-06     \t|  2              \t|  4.0103e-06     \t|  2.7102e-05     \t|\n",
      "|  [LightningModule]LitModel.on_validation_start                                                                                                                  \t|  1.3088e-06     \t|  3              \t|  3.9265e-06     \t|  2.6536e-05     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_validation_epoch_end  \t|  1.302e-06      \t|  3              \t|  3.906e-06      \t|  2.6398e-05     \t|\n",
      "|  [Callback]ModelSummary.on_validation_epoch_start                                                                                                               \t|  1.2126e-06     \t|  3              \t|  3.6377e-06     \t|  2.4585e-05     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_validation_epoch_start\t|  1.1958e-06     \t|  3              \t|  3.5875e-06     \t|  2.4245e-05     \t|\n",
      "|  [LightningModule]LitModel.on_validation_epoch_end                                                                                                              \t|  1.1759e-06     \t|  3              \t|  3.5278e-06     \t|  2.3842e-05     \t|\n",
      "|  [Callback]ModelSummary.on_save_checkpoint                                                                                                                      \t|  1.7025e-06     \t|  2              \t|  3.4049e-06     \t|  2.3011e-05     \t|\n",
      "|  [Callback]ModelSummary.on_sanity_check_start                                                                                                                   \t|  3.295e-06      \t|  1              \t|  3.295e-06      \t|  2.2269e-05     \t|\n",
      "|  [Callback]ModelSummary.on_train_end                                                                                                                            \t|  3.295e-06      \t|  1              \t|  3.295e-06      \t|  2.2269e-05     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_train_start           \t|  3.2205e-06     \t|  1              \t|  3.2205e-06     \t|  2.1765e-05     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_fit_start             \t|  3.1982e-06     \t|  1              \t|  3.1982e-06     \t|  2.1614e-05     \t|\n",
      "|  [Strategy]SingleDeviceStrategy.on_train_start                                                                                                                  \t|  3.0417e-06     \t|  1              \t|  3.0417e-06     \t|  2.0557e-05     \t|\n",
      "|  [Strategy]SingleDeviceStrategy.on_validation_end                                                                                                               \t|  9.7789e-07     \t|  3              \t|  2.9337e-06     \t|  1.9826e-05     \t|\n",
      "|  [LightningModule]LitModel.on_validation_epoch_start                                                                                                            \t|  9.6609e-07     \t|  3              \t|  2.8983e-06     \t|  1.9587e-05     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_train_epoch_start     \t|  1.4193e-06     \t|  2              \t|  2.8387e-06     \t|  1.9184e-05     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_save_checkpoint       \t|  1.3905e-06     \t|  2              \t|  2.7809e-06     \t|  1.8794e-05     \t|\n",
      "|  [LightningModule]LitModel.on_train_start                                                                                                                       \t|  2.5611e-06     \t|  1              \t|  2.5611e-06     \t|  1.7309e-05     \t|\n",
      "|  [LightningModule]LitModel.configure_callbacks                                                                                                                  \t|  2.5574e-06     \t|  1              \t|  2.5574e-06     \t|  1.7284e-05     \t|\n",
      "|  [Callback]TQDMProgressBar.on_fit_start                                                                                                                         \t|  2.5127e-06     \t|  1              \t|  2.5127e-06     \t|  1.6982e-05     \t|\n",
      "|  [Callback]TQDMProgressBar.teardown                                                                                                                             \t|  2.4326e-06     \t|  1              \t|  2.4326e-06     \t|  1.644e-05      \t|\n",
      "|  [LightningModule]LitModel.on_save_checkpoint                                                                                                                   \t|  1.0366e-06     \t|  2              \t|  2.0731e-06     \t|  1.4011e-05     \t|\n",
      "|  [LightningModule]LitModel.setup                                                                                                                                \t|  2.0284e-06     \t|  1              \t|  2.0284e-06     \t|  1.3709e-05     \t|\n",
      "|  [Callback]ModelSummary.on_sanity_check_end                                                                                                                     \t|  2.0135e-06     \t|  1              \t|  2.0135e-06     \t|  1.3608e-05     \t|\n",
      "|  [Callback]ModelSummary.setup                                                                                                                                   \t|  1.7472e-06     \t|  1              \t|  1.7472e-06     \t|  1.1808e-05     \t|\n",
      "|  [LightningModule]LitModel.prepare_data                                                                                                                         \t|  1.6913e-06     \t|  1              \t|  1.6913e-06     \t|  1.143e-05      \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.teardown                 \t|  1.628e-06      \t|  1              \t|  1.628e-06      \t|  1.1002e-05     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_sanity_check_start    \t|  1.6037e-06     \t|  1              \t|  1.6037e-06     \t|  1.0838e-05     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_fit_end               \t|  1.5199e-06     \t|  1              \t|  1.5199e-06     \t|  1.0272e-05     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_train_end             \t|  1.492e-06      \t|  1              \t|  1.492e-06      \t|  1.0083e-05     \t|\n",
      "|  [LightningModule]LitModel.on_fit_end                                                                                                                           \t|  1.4734e-06     \t|  1              \t|  1.4734e-06     \t|  9.9573e-06     \t|\n",
      "|  [Callback]ModelSummary.on_fit_end                                                                                                                              \t|  1.4585e-06     \t|  1              \t|  1.4585e-06     \t|  9.8566e-06     \t|\n",
      "|  [LightningModule]LitModel.configure_sharded_model                                                                                                              \t|  1.4193e-06     \t|  1              \t|  1.4193e-06     \t|  9.5922e-06     \t|\n",
      "|  [Strategy]SingleDeviceStrategy.on_train_end                                                                                                                    \t|  1.4193e-06     \t|  1              \t|  1.4193e-06     \t|  9.5922e-06     \t|\n",
      "|  [LightningModule]LitModel.on_train_end                                                                                                                         \t|  1.4156e-06     \t|  1              \t|  1.4156e-06     \t|  9.5671e-06     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_sanity_check_end      \t|  1.3392e-06     \t|  1              \t|  1.3392e-06     \t|  9.0509e-06     \t|\n",
      "|  [LightningModule]LitModel.teardown                                                                                                                             \t|  1.3392e-06     \t|  1              \t|  1.3392e-06     \t|  9.0509e-06     \t|\n",
      "|  [Callback]ModelSummary.teardown                                                                                                                                \t|  1.3318e-06     \t|  1              \t|  1.3318e-06     \t|  9.0006e-06     \t|\n",
      "|  [LightningModule]LitModel.on_fit_start                                                                                                                         \t|  1.302e-06      \t|  1              \t|  1.302e-06      \t|  8.7992e-06     \t|\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning.profilers import PyTorchProfiler\n",
    "profiler = PyTorchProfiler()\n",
    "\n",
    "# just need to set the profiler argument\n",
    "trainer = Trainer(max_epochs=epochs, logger=csv_logger, profiler='simple')\n",
    "trainer.fit(model, train_loader, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lightning supports [several other performance profilers](https://pytorch-lightning.readthedocs.io/en/1.6.2/advanced/profiler.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logging with Weights and Biases\n",
    "Logging is simply the act of recording data throughout model training and evaluation that can be used to make decisions about model development. Earlier, we used the CSV logger to record experimental results. [Weights and Biases (WandB)](https://wandb.ai/site) is an online platform for logging training experiments. It provides a range of data collection and visualization tools to help you understand how your training is going. WandB is free for academic use cases. It's also very easy to integrate with Pytorch Lightning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init the classifier\n",
    "pt_model = models.Classifier() #models.make_resnet18_model(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
    "\n",
    "# init the lazy layers\n",
    "with torch.no_grad():\n",
    "    pt_model(x)\n",
    "    \n",
    "# create the ligtning model\n",
    "model = models.LitModel(pt_model, lr, gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdhudsmith\u001b[0m (\u001b[33mwficai-fast\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>./wandb/run-20230621_221708-uugnumm8</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/wficai-fast/lightning_logs/runs/uugnumm8' target=\"_blank\">initial_run</a></strong> to <a href='https://wandb.ai/wficai-fast/lightning_logs' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/wficai-fast/lightning_logs' target=\"_blank\">https://wandb.ai/wficai-fast/lightning_logs</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/wficai-fast/lightning_logs/runs/uugnumm8' target=\"_blank\">https://wandb.ai/wficai-fast/lightning_logs/runs/uugnumm8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type               | Params\n",
      "-------------------------------------------------\n",
      "0 | model     | Classifier         | 23.1 K\n",
      "1 | train_acc | MulticlassAccuracy | 0     \n",
      "2 | test_acc  | MulticlassAccuracy | 0     \n",
      "-------------------------------------------------\n",
      "23.1 K    Trainable params\n",
      "0         Non-trainable params\n",
      "23.1 K    Total params\n",
      "0.093     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b394a541fa2344158a576c020dfc58f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=2` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30f7f964b84b482494e575febd77c136",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.004 MB of 0.004 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁███████████████████</td></tr><tr><td>train_acc</td><td>▁▄▄▅▆▅▇▆▇▆▆▆▇▆▇▆▆▇▇█▇▇▇▇▇██▇▇▇▇▇▇██</td></tr><tr><td>train_loss</td><td>█▆▅▄▃▃▃▃▂▂▂▃▂▂▂▂▂▂▂▁▁▂▂▂▂▁▁▂▂▂▂▂▁▂▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▂▂▃▃▃▄▄▁▁▁▁▁▁▁▁▁▁▄▅▅▅▆▆▇▇▇█▁▁▁▁▁▁▁▁▁▁█</td></tr><tr><td>val_acc_epoch</td><td>▁█</td></tr><tr><td>val_acc_step</td><td>▅▅▅▅▃▂▄▃▅▄▂▄▂▃▁▄▄▂▄█▇▇▇▆▅▆▆▇█▆▇▆▆▄▇▇▅█</td></tr><tr><td>val_loss_epoch</td><td>█▁</td></tr><tr><td>val_loss_step</td><td>▅▅▄▅▆▇▅▆▄▄▆▄▆▅█▆▄▅▄▂▂▂▂▃▄▃▃▂▂▃▁▃▂▆▃▂▃▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>1</td></tr><tr><td>train_acc</td><td>0.85938</td></tr><tr><td>train_loss</td><td>0.46852</td></tr><tr><td>trainer/global_step</td><td>1763</td></tr><tr><td>val_acc_epoch</td><td>0.79718</td></tr><tr><td>val_acc_step</td><td>0.8125</td></tr><tr><td>val_loss_epoch</td><td>0.67434</td></tr><tr><td>val_loss_step</td><td>0.60827</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">initial_run</strong> at: <a href='https://wandb.ai/wficai-fast/lightning_logs/runs/uugnumm8' target=\"_blank\">https://wandb.ai/wficai-fast/lightning_logs/runs/uugnumm8</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230621_221708-uugnumm8/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pytorch_lightning.loggers import WandbLogger\n",
    "wandb_logger = WandbLogger(name='initial_run')\n",
    "\n",
    "# just need to set the profiler argument\n",
    "trainer = Trainer(max_epochs=epochs, logger=wandb_logger)\n",
    "trainer.fit(model, train_loader, test_loader)\n",
    "\n",
    "# indicate that the run has finished\n",
    "wandb_logger.experiment.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Automatic mixed precision (AMP)\n",
    "By default, PyTorch uses 32-bit floating point numbers. These means that each element of a tensor, takes up 32 bits / 4 Bytes of memory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randn(3).dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "32-bit floats can store about 8 digits of precision. This level of precision may not be necessary for many of the computations performed by the neural network. Pytorch supports several other floating point formats, that we can make use of. For instance, we can allocate 16-bit tensors: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float16"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randn(3, dtype=torch.float16).dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "16-bit floats take up half the memory of 32 bit, so this may allow us to train larger models on the same GPU hardware. In addition, modern GPU architectures can perform some calculations more efficiently with 16-bit numbers. \n",
    "\n",
    "Unfortunately, it turns out that its usually not a good idea to convert all aspects of our computation into 16-bit floats. The research community has come up with good approaches to mixing 32-bit and 16-bit computation to get the benefits of using lower-precision without hurting model convergence. Manually setting all of this up is a headache, so Pytorch supports \"Automatic Mixed Precision\" to perform the conversion automatically under the hood. \n",
    "\n",
    "To use this functionality, you use the `autocast` context manager: \n",
    "```python\n",
    "# Creates model and optimizer in default precision\n",
    "model = Net().cuda()\n",
    "optimizer = optim.SGD(model.parameters(), ...)\n",
    "\n",
    "# Creates a GradScaler once at the beginning of training.\n",
    "# this improves convergence by preventing underflow\n",
    "scaler = GradScaler()\n",
    "\n",
    "for epoch in epochs:\n",
    "    for input, target in data:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Runs the forward pass with autocasting.\n",
    "        with autocast(device_type='cuda', dtype=torch.float16):\n",
    "            output = model(input)\n",
    "            loss = loss_fn(output, target)\n",
    "\n",
    "        # Scales loss.  Calls backward() on scaled loss to create scaled gradients.\n",
    "        # Backward passes under autocast are not recommended.\n",
    "        # Backward ops run in the same dtype autocast chose for corresponding forward ops.\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        # scaler.step() first unscales the gradients of the optimizer's assigned params.\n",
    "        # If these gradients do not contain infs or NaNs, optimizer.step() is then called,\n",
    "        # otherwise, optimizer.step() is skipped.\n",
    "        scaler.step(optimizer)\n",
    "\n",
    "        # Updates the scale for next iteration.\n",
    "        scaler.update()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AMP in Pytorch Ligtning\n",
    "Fortunately for us, it is extremely easy to implement AMP now that we have our model set up in Pytorch Lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# init the classifier\n",
    "pt_model = models.Classifier() #models.make_resnet18_model(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
    "\n",
    "# init the lazy layers\n",
    "with torch.no_grad():\n",
    "    pt_model(x)\n",
    "    \n",
    "# create the ligtning model\n",
    "model = models.LitModel(pt_model, lr, gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e7b2500a93446519091648765f7418a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01666884127383431, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>./wandb/run-20230621_221732-4r3rplac</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/wficai-fast/lightning_logs/runs/4r3rplac' target=\"_blank\">AMP run</a></strong> to <a href='https://wandb.ai/wficai-fast/lightning_logs' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/wficai-fast/lightning_logs' target=\"_blank\">https://wandb.ai/wficai-fast/lightning_logs</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/wficai-fast/lightning_logs/runs/4r3rplac' target=\"_blank\">https://wandb.ai/wficai-fast/lightning_logs/runs/4r3rplac</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type               | Params\n",
      "-------------------------------------------------\n",
      "0 | model     | Classifier         | 23.1 K\n",
      "1 | train_acc | MulticlassAccuracy | 0     \n",
      "2 | test_acc  | MulticlassAccuracy | 0     \n",
      "-------------------------------------------------\n",
      "23.1 K    Trainable params\n",
      "0         Non-trainable params\n",
      "23.1 K    Total params\n",
      "0.093     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee0e4599ab1e468c839db7f4e4d9fa3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=2` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59547b0878dd4e72829c77bb6aa91915",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.004 MB of 0.004 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁███████████████████</td></tr><tr><td>train_acc</td><td>▁▃▄▅▅▆▆▆▆▇▆▆▆▆▆▇▆▆▇▇██▇▇▆▇▆▇▇▇▇▇▇▇▇</td></tr><tr><td>train_loss</td><td>█▆▅▄▄▃▃▃▃▂▃▃▂▃▂▂▂▂▂▂▁▁▂▂▂▁▂▁▁▂▁▁▂▂▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▂▂▃▃▃▄▄▁▁▁▁▁▁▁▁▁▁▄▅▅▅▆▆▇▇▇█▁▁▁▁▁▁▁▁▁▁█</td></tr><tr><td>val_acc_epoch</td><td>▁█</td></tr><tr><td>val_acc_step</td><td>▄▃▃▄▃▂▂▂▃▃▃▄▂▁▂▅▃▄▂▇▇▆█▆▅▆▇▇▇▆▇▅▅▄█▇▇▆</td></tr><tr><td>val_loss_epoch</td><td>█▁</td></tr><tr><td>val_loss_step</td><td>▅▆▅▅▇▇▆▆▅▅▆▄▇▆█▆▅▅▅▂▂▂▂▃▄▂▃▂▁▃▁▄▃▅▂▁▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>1</td></tr><tr><td>train_acc</td><td>0.79688</td></tr><tr><td>train_loss</td><td>0.62448</td></tr><tr><td>trainer/global_step</td><td>1763</td></tr><tr><td>val_acc_epoch</td><td>0.77883</td></tr><tr><td>val_acc_step</td><td>0.7775</td></tr><tr><td>val_loss_epoch</td><td>0.75217</td></tr><tr><td>val_loss_step</td><td>0.71923</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">AMP run</strong> at: <a href='https://wandb.ai/wficai-fast/lightning_logs/runs/4r3rplac' target=\"_blank\">https://wandb.ai/wficai-fast/lightning_logs/runs/4r3rplac</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230621_221732-4r3rplac/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb_logger = WandbLogger(name='AMP run')\n",
    "\n",
    "trainer = Trainer(max_epochs=epochs, logger=wandb_logger, \n",
    "                  precision=16) #<-- this\n",
    "trainer.fit(model, train_loader, test_loader)\n",
    "\n",
    "wandb_logger.experiment.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model checkpointing\n",
    "Simply put, checkpointing is the process of saving a model periodically based on a metric that you monitor. If the metric has improved, save the model. In addition to saving the model weights, we need to save the hyperparameters. We do this by calling `self.save_hyperparameters()` in the initializer for the lightning model:\n",
    "```python\n",
    "class LitModel(pl.LightningModule):\n",
    "    def __init__(self, pytorch_model, lr, gamma):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        ...\n",
    "```\n",
    "Unlike the previous options, we need to use a Callback method to set up checkpointing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init the classifier\n",
    "pt_model = models.Classifier() #models.make_resnet18_model(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
    "\n",
    "# init the lazy layers\n",
    "with torch.no_grad():\n",
    "    pt_model(x)\n",
    "     \n",
    "# create the ligtning model\n",
    "model = models.LitModel(pt_model, lr, gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e99b440b2954780b30853d94b04fe24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016668776174386342, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>./wandb/run-20230621_221757-tgzrctm2</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/wficai-fast/lightning_logs/runs/tgzrctm2' target=\"_blank\">Run with Checkpointing</a></strong> to <a href='https://wandb.ai/wficai-fast/lightning_logs' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/wficai-fast/lightning_logs' target=\"_blank\">https://wandb.ai/wficai-fast/lightning_logs</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/wficai-fast/lightning_logs/runs/tgzrctm2' target=\"_blank\">https://wandb.ai/wficai-fast/lightning_logs/runs/tgzrctm2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type               | Params\n",
      "-------------------------------------------------\n",
      "0 | model     | Classifier         | 23.1 K\n",
      "1 | train_acc | MulticlassAccuracy | 0     \n",
      "2 | test_acc  | MulticlassAccuracy | 0     \n",
      "-------------------------------------------------\n",
      "23.1 K    Trainable params\n",
      "0         Non-trainable params\n",
      "23.1 K    Total params\n",
      "0.093     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e527d8f6408470188594fc06ea5dfac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=2` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec73dd6aa67a44c39dd9c4cae7921855",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.579 MB of 0.579 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁███████████████████</td></tr><tr><td>train_acc</td><td>▁▂▄▄▅▅▆▅▆▆▆▇▆▆▇▇▇▆▆▇█▇▇▇▇█▇▇█▇▇▇██▇</td></tr><tr><td>train_loss</td><td>█▆▅▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▂▁▁▁▂▂▁▁▂▁▁▁▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▂▂▃▃▃▄▄▁▁▁▁▁▁▁▁▁▁▄▅▅▅▆▆▇▇▇█▁▁▁▁▁▁▁▁▁▁█</td></tr><tr><td>val_acc_epoch</td><td>▁█</td></tr><tr><td>val_acc_step</td><td>▅▅▄▃▁▁▃▃▄▅▂▄▄▁▂▅▃▄▃██▇▆▆▅▆▆▇▇▇█▇▇▆█▇▆▇</td></tr><tr><td>val_loss_epoch</td><td>█▁</td></tr><tr><td>val_loss_step</td><td>▅▅▄▄▆▇▆▆▄▄▆▄▆▆█▅▄▅▄▂▂▁▁▃▄▃▂▁▁▃▁▃▂▅▂▁▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>1</td></tr><tr><td>train_acc</td><td>0.77344</td></tr><tr><td>train_loss</td><td>0.85265</td></tr><tr><td>trainer/global_step</td><td>1763</td></tr><tr><td>val_acc_epoch</td><td>0.78878</td></tr><tr><td>val_acc_step</td><td>0.79125</td></tr><tr><td>val_loss_epoch</td><td>0.70496</td></tr><tr><td>val_loss_step</td><td>0.64834</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Run with Checkpointing</strong> at: <a href='https://wandb.ai/wficai-fast/lightning_logs/runs/tgzrctm2' target=\"_blank\">https://wandb.ai/wficai-fast/lightning_logs/runs/tgzrctm2</a><br/>Synced 6 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230621_221757-tgzrctm2/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# need to import the checkpoint callback object\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "checkpoint_callback = ModelCheckpoint(\"checkpoints/\", save_top_k=3, monitor='val_loss')\n",
    "\n",
    "# we add log_model='all' to save models on wandb\n",
    "wandb_logger = WandbLogger(name='Run with Checkpointing', log_model='all')\n",
    "\n",
    "# need to pass the checkpoint callback\n",
    "trainer = Trainer(max_epochs=epochs, logger=wandb_logger, precision=16, callbacks = [checkpoint_callback])\n",
    "trainer.fit(model, train_loader, test_loader)\n",
    "\n",
    "wandb_logger.experiment.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the model from a local checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To load a model from a checkpoint, we use the `load_from_checkpoint`, passing in the path. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.LitModel.load_from_checkpoint('checkpoints/epoch=1-step=1764.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1da46ffec63548f3b2300af2d56d9d39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       val_acc_epoch       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7675532102584839     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      val_loss_epoch       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7949550747871399     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m      val_acc_epoch      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7675532102584839    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     val_loss_epoch      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7949550747871399    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'val_loss_epoch': 0.7949550747871399, 'val_acc_epoch': 0.7675532102584839}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# when creating a trainer just for validation, we don't need to fuss over the arguments.\n",
    "trainer = Trainer()\n",
    "trainer.validate(model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Early Stopping\n",
    "Early stopping, as the name implies, is a technique for stopping training early if a monitored metric is not improving. This can save lots of time and compute resources. We set this up in Lightning using a callback. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init the classifier\n",
    "pt_model = models.Classifier() #models.make_resnet18_model(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
    "\n",
    "# init the lazy layers\n",
    "with torch.no_grad():\n",
    "    pt_model(x)\n",
    "    \n",
    "# create the ligtning model\n",
    "model = models.LitModel(pt_model, lr, gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>./wandb/run-20230621_221825-s41wgsxm</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/wficai-fast/lightning_logs/runs/s41wgsxm' target=\"_blank\">Early stopping run</a></strong> to <a href='https://wandb.ai/wficai-fast/lightning_logs' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/wficai-fast/lightning_logs' target=\"_blank\">https://wandb.ai/wficai-fast/lightning_logs</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/wficai-fast/lightning_logs/runs/s41wgsxm' target=\"_blank\">https://wandb.ai/wficai-fast/lightning_logs/runs/s41wgsxm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type               | Params\n",
      "-------------------------------------------------\n",
      "0 | model     | Classifier         | 23.1 K\n",
      "1 | train_acc | MulticlassAccuracy | 0     \n",
      "2 | test_acc  | MulticlassAccuracy | 0     \n",
      "-------------------------------------------------\n",
      "23.1 K    Trainable params\n",
      "0         Non-trainable params\n",
      "23.1 K    Total params\n",
      "0.093     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3de30ef27fa54a8c8cc0ac5f874ae20a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9341bea7a76f4fc3af1281023dc89fba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.004 MB of 0.004 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▂▂▃▃▃▃▄▄▄▅▅▅▅▅▅▅▅▆▆▆▇▇▇▇▇▇▇████</td></tr><tr><td>train_acc</td><td>▁▆▆▅▇▇▇▇▆▇▇▇▇▇▇▇▇▇▇█▇▆▇█▇▆▇▇▇▇▇▇▇██▇██▇▇</td></tr><tr><td>train_loss</td><td>█▃▃▃▂▂▂▁▂▂▁▁▂▂▁▁▁▁▁▁▁▂▁▁▁▂▂▁▂▂▁▂▂▁▁▁▁▁▁▂</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▁▁▂▃▁▁▃▄▁▁▄▄▁▄▅▁▁▅▁▁▆▆▁▁▆▇▁▁▇█▁██▁▁</td></tr><tr><td>val_acc_epoch</td><td>▁▄▆▇▇▇▇████</td></tr><tr><td>val_acc_step</td><td>▁▁▃▂▄▄▃▃▅▇▇▅▆▅▆▆▇▆▇▇▆█▆▇▇█▇▇▄▆▇▇▇▆▇▃▆▇▇▇</td></tr><tr><td>val_loss_epoch</td><td>█▄▃▂▂▁▁▁▁▁▁</td></tr><tr><td>val_loss_step</td><td>▇█▅▇▄▃▅▄▆▂▃▃▄▄▂▃▂▃▃▃▄▂▂▃▂▃▄▄▆▃▃▁▂▄▁▆▃▅▁▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>10</td></tr><tr><td>train_acc</td><td>0.82031</td></tr><tr><td>train_loss</td><td>0.72232</td></tr><tr><td>trainer/global_step</td><td>9701</td></tr><tr><td>val_acc_epoch</td><td>0.82207</td></tr><tr><td>val_acc_step</td><td>0.825</td></tr><tr><td>val_loss_epoch</td><td>0.58447</td></tr><tr><td>val_loss_step</td><td>0.54862</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Early stopping run</strong> at: <a href='https://wandb.ai/wficai-fast/lightning_logs/runs/s41wgsxm' target=\"_blank\">https://wandb.ai/wficai-fast/lightning_logs/runs/s41wgsxm</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230621_221825-s41wgsxm/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# need to import the early stop callback object\n",
    "from lightning.pytorch.callbacks import EarlyStopping\n",
    "earlystop_callback = EarlyStopping(monitor=\"val_loss\", min_delta=0.005, patience=3, verbose=False)\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\"checkpoints/\", save_top_k=3, monitor='val_loss')\n",
    "wandb_logger = WandbLogger(name='Early stopping run')\n",
    "\n",
    "\n",
    "# need to pass the checkpoint callback\n",
    "trainer = Trainer(max_epochs=20, logger=wandb_logger, precision=16, \n",
    "                  callbacks = [earlystop_callback, checkpoint_callback])\n",
    "trainer.fit(model, train_loader, test_loader)\n",
    "\n",
    "wandb_logger.experiment.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-gpu\n",
    "\n",
    "### Single-node, multi-gpu\n",
    "Pytorch Lightning makes this very easy. In fact, Lightning will automatically use all available gpus by default. However, it is tricky to get this working in Jupyter notebooks. To demonstrate, we have create a script that you can download [here](https://raw.githubusercontent.com/clemsonciti/rcde_workshops/master/pytorch_advanced/multi_gpu.py). \n",
    "\n",
    "### Multi-node, multi-gpu\n",
    "This is a bit trickier because it involves setting up communication across nodes. We have an example of how to set this up in our Palmetto Examples repository [here](https://github.com/clemsonciti/palmetto-examples/tree/master/PyTorch/PBS/distributed_data_parallel)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "21179021fdd249dca874a2cb3215d3e9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3f00f27414ed4d80ace97ee0bcea32d6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "430518b6f83343e0b5e22d32b348d605": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b765f713ef5440ea85c5f12540ebba75",
      "max": 561753746,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_674919a7e1d14f738a6d70ad66a89f4b",
      "value": 561753746
     }
    },
    "4b3178c079fb4eb3800e3b8311caf412": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_60c4d3e66e2146cdb1ed443d133ae9ec",
      "placeholder": "​",
      "style": "IPY_MODEL_c7cb437d14a24ecd9551c8f9516577c8",
      "value": " 561753746/561753746 [00:37&lt;00:00, 15679465.54it/s]"
     }
    },
    "60c4d3e66e2146cdb1ed443d133ae9ec": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "674919a7e1d14f738a6d70ad66a89f4b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "7907db13bf594b6188ee1321502e01f3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3f00f27414ed4d80ace97ee0bcea32d6",
      "placeholder": "​",
      "style": "IPY_MODEL_87f7464c25c44cde8088e97126f4190e",
      "value": "100%"
     }
    },
    "87f7464c25c44cde8088e97126f4190e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a594b0a61f9c471f927d1e84bb6b660e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7907db13bf594b6188ee1321502e01f3",
       "IPY_MODEL_430518b6f83343e0b5e22d32b348d605",
       "IPY_MODEL_4b3178c079fb4eb3800e3b8311caf412"
      ],
      "layout": "IPY_MODEL_21179021fdd249dca874a2cb3215d3e9"
     }
    },
    "b765f713ef5440ea85c5f12540ebba75": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c7cb437d14a24ecd9551c8f9516577c8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
