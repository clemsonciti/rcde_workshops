{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8n40xD862nhd"
   },
   "source": [
    "# EMNIST Baseline\n",
    "\n",
    "Copying from the [beginner workshop](https://clemsonciti.github.io/rcde_workshops/pytorch/07-cnn_emnist.html), we introduce basic model training for the EMNIST dataset. We will build upon the approach outlined here throughout the series. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.io import read_image\n",
    "from torchvision.io import ImageReadMode\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "data_dir = f\"/scratch/{os.environ['USER']}/data\"\n",
    "model_path = f\"/scratch/{os.environ['USER']}/model.pt\"\n",
    "\n",
    "# Model and Training\n",
    "batch_size=128 #input batch size for training (default: 64)\n",
    "test_batch_size=1000 #input batch size for testing (default: 1000)\n",
    "num_workers=10 # parallel data loading to speed things up\n",
    "lr=1.0 #learning rate (default: 1.0)\n",
    "gamma=0.7 #Learning rate step gamma (default: 0.7)\n",
    "no_cuda=False #disables CUDA training (default: False)\n",
    "seed=42 #random seed (default: 42)\n",
    "log_interval=10 #how many batches to wait before logging training status (default: 10)\n",
    "save_model=False #save the trained model (default: False)\n",
    "\n",
    "# additional derived settings\n",
    "use_cuda = not no_cuda and torch.cuda.is_available()\n",
    "torch.manual_seed(seed)\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "print(\"Device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7NGHwURr8or8"
   },
   "source": [
    "## Dataset\n",
    "In the beginner series, we saw how to set up a Pytorch Dataset class for the ImageNet dataset. We will copy the result here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Loading the data\n",
    "\n",
    "# Pytorch provides a number of pre-defined dataset classes\n",
    "# EMNIST is one of them! Pytorch will automatically download the data.\n",
    "# It will only download if the data is not already present.\n",
    "data_train = datasets.EMNIST(data_dir, split='balanced', train=True, download=True,\n",
    "                    transform=transforms.Compose([\n",
    "                        transforms.ToTensor(),\n",
    "                        transforms.Normalize((0.1307,), (0.3081,))\n",
    "                    ]))\n",
    "\n",
    "data_test = datasets.EMNIST(data_dir, split='balanced', train=False, transform=transforms.Compose([\n",
    "                        transforms.ToTensor(),\n",
    "                        transforms.Normalize((0.1307,), (0.3081,))\n",
    "                    ]))\n",
    "\n",
    "# define pytorch dataloaders for training and testing\n",
    "train_loader = DataLoader(data_train, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=True)\n",
    "test_loader = DataLoader(data_test, batch_size=test_batch_size, shuffle=False, num_workers=num_workers, pin_memory=True)\n",
    "\n",
    "# save a test batch for later testing\n",
    "image_gen = iter(test_loader)\n",
    "test_img, test_trg = next(image_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset: Dataset EMNIST\n",
      "    Number of datapoints: 112800\n",
      "    Root location: /scratch/dane2/data\n",
      "    Split: Train\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               ToTensor()\n",
      "               Normalize(mean=(0.1307,), std=(0.3081,))\n",
      "           )\n",
      "Testing dataset: Dataset EMNIST\n",
      "    Number of datapoints: 18800\n",
      "    Root location: /scratch/dane2/data\n",
      "    Split: Test\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               ToTensor()\n",
      "               Normalize(mean=(0.1307,), std=(0.3081,))\n",
      "           )\n"
     ]
    }
   ],
   "source": [
    "print(\"Training dataset:\", train_loader.dataset)\n",
    "print(\"Testing dataset:\", test_loader.dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Model definition\n",
    "In the [EMNIST notebook](https://clemsonciti.github.io/rcde_workshops/pytorch/07-cnn_emnist.html), we developed CNN architectures for hand-written characters. We will copy our best architecture here and adapt it to the situation of color-image inputs and 1000-class output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Classifier, self).__init__()\n",
    "\n",
    "        # feature encoder\n",
    "        self.feature_extractor = feature_extractor = nn.Sequential(\n",
    "            # block 1\n",
    "            nn.Conv2d(in_channels=1, out_channels=4, kernel_size=3, stride=1, bias=False),\n",
    "            nn.LazyBatchNorm2d(),\n",
    "            nn.ReLU(),\n",
    "            # 2\n",
    "            nn.Conv2d(in_channels=4, out_channels=4, kernel_size=3, stride=1, bias=False),\n",
    "            nn.LazyBatchNorm2d(),\n",
    "            nn.ReLU(),\n",
    "            # 3\n",
    "            nn.Conv2d(in_channels=4, out_channels=4, kernel_size=3, stride=1, bias=False),\n",
    "            nn.LazyBatchNorm2d(),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            # flatten just as with the linear classifier\n",
    "            nn.Flatten()\n",
    "        )\n",
    "        \n",
    "        # linear classification head -- ImageNet has 1000 classes\n",
    "        self.classifier = nn.LazyLinear(47)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.feature_extractor(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "    \n",
    "    def num_params(self):\n",
    "        return sum(p.numel() for p in model.parameters())\n",
    "\n",
    "# Create the model\n",
    "model = Classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([128, 47]),\n",
       " tensor([[-0.2897, -0.5617,  0.0628,  ..., -1.2602,  0.8728,  0.3598],\n",
       "         [ 0.8654, -0.0719,  0.6095,  ..., -0.0504, -0.4102, -0.1677],\n",
       "         [ 0.2731, -0.2552,  0.0274,  ...,  0.0960,  0.7097,  0.4219],\n",
       "         ...,\n",
       "         [-0.2629,  0.0098,  0.0789,  ..., -0.7038,  0.5512, -1.0838],\n",
       "         [ 0.2294,  0.5040, -0.4386,  ..., -0.5136,  0.5362,  0.4131],\n",
       "         [-0.1829, -0.6301,  1.2044,  ..., -1.4666, -0.5272, -0.3675]]),\n",
       " tensor([-1.1857,  7.7833,  3.6772, -1.0103,  7.2764,  3.0098,  6.7484, -2.4809,\n",
       "         16.5917,  7.4026,  1.1977,  7.7264,  1.4142,  8.6851,  5.8889,  0.8193,\n",
       "         11.8244,  9.6126,  3.6529,  3.7360,  6.5334,  5.4083,  2.3121,  4.2810,\n",
       "          3.9888,  0.9701,  6.4130,  3.1773,  7.5547,  9.3368,  4.6726,  8.8772,\n",
       "         10.0957,  4.4073,  5.9341, -1.3580,  1.0337,  4.1729,  7.2586,  5.7577,\n",
       "          0.5533,  7.2799,  0.6950,  6.7011, -4.1594,  4.3148,  7.4138,  1.8631,\n",
       "         -1.8655,  6.9863, -0.7021,  8.2847,  4.9730, -1.9363,  6.9793,  1.7842,\n",
       "         13.1547,  7.6535,  6.8881,  9.3821,  8.7600,  5.9675,  3.2702, -0.2760,\n",
       "          2.1410,  5.2800,  4.0835,  0.3117,  8.4077,  4.7187,  1.8049,  0.7824,\n",
       "          7.1940, 10.2863,  7.8565,  6.0385, -1.9799,  6.3945,  0.3884,  0.3304,\n",
       "          5.6073,  9.4075, 10.4626, -0.7341,  3.5893,  2.9042,  6.0140,  4.1800,\n",
       "          7.2520, -0.9992,  8.0851,  7.3866, 10.2711,  5.5463,  2.7001,  7.8807,\n",
       "          7.6535,  7.2546,  7.2469,  4.9917,  0.8115, 12.6958,  3.4918,  4.0801,\n",
       "          8.3012,  2.5887,  1.9310,  4.5293,  4.0950,  4.1541,  6.9728,  7.7243,\n",
       "          3.2597,  8.9427,  3.4462, -2.8556,  7.1138,  4.0573,  1.0241,  6.8103,\n",
       "          2.1410, 11.8644,  2.2207,  1.7766,  4.6555,  4.4057,  7.7114,  6.6785]))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's make sure we can run a batch of data through the model\n",
    "with torch.no_grad():\n",
    "    x, y = next(iter(train_loader))\n",
    "    y_hat = model(x)\n",
    "    \n",
    "y_hat.shape, y_hat, y_hat.sum(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Classifier(\n",
       "  (feature_extractor): Sequential(\n",
       "    (0): Conv2d(1, 4, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "    (4): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU()\n",
       "    (6): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "    (7): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (8): ReLU()\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Flatten(start_dim=1, end_dim=-1)\n",
       "  )\n",
       "  (classifier): Linear(in_features=484, out_features=47, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 23143\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of parameters:\", model.num_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and testing loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "cellView": "form",
    "id": "7g4s_TT-3ZeF",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    losses = []\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.cross_entropy(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('\\r\\tTrain epoch {}: [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()), end='')\n",
    "            \n",
    "def test(model, device, test_loader, epoch):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.cross_entropy(output, target, reduction='sum').item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\rTest epoch {}: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)'.format(\n",
    "        epoch,\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "    \n",
    "def train_and_test(model, dl_train, dl_test, save_name=model_path, epochs=5):\n",
    "    # @title Train the linear model\n",
    "    optimizer = optim.Adadelta(model.parameters(), lr=lr)\n",
    "    scheduler = StepLR(optimizer, step_size=1, gamma=gamma)\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        train(model, device, dl_train, optimizer, epoch)\n",
    "        test(model, device, dl_test, epoch)\n",
    "        scheduler.step()\n",
    "\n",
    "    if save_model:\n",
    "        torch.save(model.state_dict(), save_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Classifier(\n",
       "  (feature_extractor): Sequential(\n",
       "    (0): Conv2d(1, 4, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "    (1): LazyBatchNorm2d(0, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "    (4): LazyBatchNorm2d(0, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU()\n",
       "    (6): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "    (7): LazyBatchNorm2d(0, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (8): ReLU()\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Flatten(start_dim=1, end_dim=-1)\n",
       "  )\n",
       "  (classifier): LazyLinear(in_features=0, out_features=47, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Classifier().to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test epoch 1: Average loss: 0.6545, Accuracy: 15048/18800 (80.04%)\n",
      "Test epoch 2: Average loss: 0.5639, Accuracy: 15416/18800 (82.00%)\n",
      "Test epoch 3: Average loss: 0.5422, Accuracy: 15651/18800 (83.25%)\n",
      "Test epoch 4: Average loss: 0.5266, Accuracy: 15735/18800 (83.70%)\n",
      "Test epoch 5: Average loss: 0.5081, Accuracy: 15831/18800 (84.21%)\n"
     ]
    }
   ],
   "source": [
    "train_and_test(model, train_loader, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "21179021fdd249dca874a2cb3215d3e9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3f00f27414ed4d80ace97ee0bcea32d6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "430518b6f83343e0b5e22d32b348d605": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b765f713ef5440ea85c5f12540ebba75",
      "max": 561753746,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_674919a7e1d14f738a6d70ad66a89f4b",
      "value": 561753746
     }
    },
    "4b3178c079fb4eb3800e3b8311caf412": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_60c4d3e66e2146cdb1ed443d133ae9ec",
      "placeholder": "​",
      "style": "IPY_MODEL_c7cb437d14a24ecd9551c8f9516577c8",
      "value": " 561753746/561753746 [00:37&lt;00:00, 15679465.54it/s]"
     }
    },
    "60c4d3e66e2146cdb1ed443d133ae9ec": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "674919a7e1d14f738a6d70ad66a89f4b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "7907db13bf594b6188ee1321502e01f3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3f00f27414ed4d80ace97ee0bcea32d6",
      "placeholder": "​",
      "style": "IPY_MODEL_87f7464c25c44cde8088e97126f4190e",
      "value": "100%"
     }
    },
    "87f7464c25c44cde8088e97126f4190e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a594b0a61f9c471f927d1e84bb6b660e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7907db13bf594b6188ee1321502e01f3",
       "IPY_MODEL_430518b6f83343e0b5e22d32b348d605",
       "IPY_MODEL_4b3178c079fb4eb3800e3b8311caf412"
      ],
      "layout": "IPY_MODEL_21179021fdd249dca874a2cb3215d3e9"
     }
    },
    "b765f713ef5440ea85c5f12540ebba75": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c7cb437d14a24ecd9551c8f9516577c8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
