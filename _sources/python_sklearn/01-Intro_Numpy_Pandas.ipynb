{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38d7efc4-f10a-4e85-9d2c-03fc9c3d97f8",
   "metadata": {},
   "source": [
    "# Introduction to Python for Machine Learning\n",
    "\n",
    "Python has become the de facto language for machine learning due to its simplicity, readability, and extensive ecosystem of libraries. Its flexibility allows for rapid prototyping and development, while its powerful libraries like NumPy, Pandas, and Scikit-learn provide efficient tools for data manipulation and model building.\n",
    "\n",
    "## 1. Essential Python Concepts Review\n",
    " \n",
    "For a broad introduction to Python, check out the [Python Programming Guide](https://www.python.org/about/gettingstarted/). Here are some key features of Python that are particularly useful for machine learning:\n",
    "\n",
    "* **List Comprehensions**: A concise way to create lists in Python.\n",
    "* **Lambda Functions**: Anonymous functions that can be defined in a single line.\n",
    "* **Error Handling**: Using `try`, `except`, and `finally` blocks to handle exceptions.\n",
    "* **Generators**: Functions that return an iterator, allowing for lazy evaluation (meaning they don't store all values in memory at once).\n",
    "* **Dynamic Typing**: Variables in Python are dynamically typed, meaning you don't need to specify the type of a variable when you declare it.\n",
    "* **Runtime Compilation**: Python code is compiled to bytecode, which is then interpreted by the Python interpreter. This allows for dynamic execution of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c41809-f07f-46cd-b059-5f3e5223e8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code snippets demonstrating key Python concepts\n",
    "# List comprehension example\n",
    "squares = [x**2 for x in range(10)]\n",
    "squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6db11b-d40a-4984-8559-a1460e428800",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lambda function example\n",
    "multiply = lambda x, y: x * y\n",
    "multiply(5, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba8d77f-a252-4ec5-9dfd-d19d6afb2d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error handling example\n",
    "try:\n",
    "    result = 10 / 0\n",
    "except ZeroDivisionError:\n",
    "    print(\"Cannot divide by zero\")\n",
    "    \n",
    "print(\"This line still runs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7078433-b913-4224-8bc2-59f6f7b689d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generators example\n",
    "def fibonacci(n):\n",
    "    a, b = 0, 1\n",
    "    for _ in range(n):\n",
    "        yield a\n",
    "        a, b = b, a + b\n",
    "\n",
    "fib = fibonacci(int(1e18)) # Large number to demonstrate generator memory efficiency, the first 1e18 (i.e. 1 quintillion) Fibonacci numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2d5670-2474-48f4-bd00-24fafb0559eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the next Fibonacci number\n",
    "next(fib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8819dc17-0304-47b8-97ae-9f6ac1f394d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How much memory does the fib object consume?\n",
    "import sys\n",
    "sys.getsizeof(fib)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e490e59-07f1-4710-b8c1-b2847593910d",
   "metadata": {},
   "source": [
    "If we were to run `list(fib)`, we would get a list of the first quintillion Fibonacci numbers. But we don't want to do that, because it would take up all the memory on our machine!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc09c3f-de76-4f5f-91b9-cdd3de544abd",
   "metadata": {},
   "source": [
    "## 2. Introduction to NumPy\n",
    "\n",
    "NumPy is a powerful library for numerical computing in Python. It provides support for large, multi-dimensional arrays and matrices, along with a collection of mathematical functions to operate on these arrays. NumPy is the foundation for many other libraries in the Python data science ecosystem, such as Pandas, Scikit-learn, PyTorch, and TensorFlow. The reason NumPy is so fast is that it is implemented in C, which is a much faster language than Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a080ed9-0e30-4f17-816a-6c1adbd9a28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic NumPy operations and array manipulations\n",
    "import numpy as np\n",
    "\n",
    "# Create an array\n",
    "arr = np.array([1, 2, 3, 4, 5])\n",
    "\n",
    "# Array operations\n",
    "print(\"Array operations:\")\n",
    "print(\"Array:\")\n",
    "print(arr)\n",
    "print(\"Array x 2:\")\n",
    "print(arr * 2)\n",
    "print(\"Array summed:\")\n",
    "print(np.sum(arr))\n",
    "\n",
    "# Broadcasting example\n",
    "matrix = np.array([[1, 2, 3, 4 , 5], [6, 7, 8, 9, 10]])\n",
    "print(\"\\nBroadcasting example:\")\n",
    "print(\"Matrix:\")\n",
    "print(matrix)\n",
    "print(\"Array:\")\n",
    "print(arr)\n",
    "print(\"Matrix + Array:\")\n",
    "print(matrix + arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef961e1-f8a1-4787-ac86-883db00714f3",
   "metadata": {},
   "source": [
    "## 3. Intro to Pandas\n",
    "\n",
    "Pandas is a powerful data manipulation library for Python. It is built on top of NumPy and provides data structures and functions for efficiently manipulating large datasets. Pandas is widely used in data science and machine learning for data cleaning, exploration, and preparation.\n",
    "\n",
    "Pandas isn't the best choice for truly massive datasets, since it loads the entire dataset into memory. But even libraries that are better suited for massive datasets, like Dask, tend to conform to the Pandas API, so learning Pandas is a good foundation for working with other libraries.\n",
    "\n",
    "Pandas is great for organizing and exploring data. We'll spend more time on data exploration in Day 2, but let's take a quick look at how to use Pandas dataframes to organize data. We'll use the California Housing dataset, which is a dataset containing information about housing prices. The dataset contains 20,640 samples and 9 features. The goal is to predict the house value, given a set of features about the property and its district."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeaf332a-e918-4eb4-8615-419090842586",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "# Load the California housing dataset\n",
    "california = fetch_california_housing()\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(california.data, columns=california.feature_names)\n",
    "# The above created a dataframe with the features, but it doesn't have the target variable. It's easy to add new columns to a Pandas DataFrame:\n",
    "df['Price'] = california.target\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "print(\"First few rows of the California Housing Dataset:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0ca836-1cd1-4cc4-858d-aaed0840e9a9",
   "metadata": {},
   "source": [
    "Pandas includes some methods for quickly summarizing the data in a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439dad39-32e1-4ad4-a69f-95a24fe677d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic data exploration\n",
    "print(\"DataFrame Info:\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b72aa4-2788-4729-a98e-56fce62cbd43",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Basic Statistics:\")\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1e6631-fa51-4087-94fd-ada51451bc6a",
   "metadata": {},
   "source": [
    "Pandas also makes it easy to filter data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd08757-0759-43b1-a10d-40f1e66096de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering data\n",
    "print(\"Houses with more than 4 rooms on average:\")\n",
    "print(df[df['AveRooms'] > 4].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb83ba87-defd-4d8d-b730-cb98c6daac7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nHouses with more than 4 rooms on average and a price above the median:\")\n",
    "print(df[(df['AveRooms'] > 4) & (df['Price'] > df['Price'].median())].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7ad84d-fc4e-4bf3-aaa8-1ccc0736356b",
   "metadata": {},
   "source": [
    "We can also sort the data easily, and add new columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba98c5b-c3ef-4e69-bb2d-b8fc3795803f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting data\n",
    "print(\"\\nTop 5 most expensive areas:\")\n",
    "print(df.sort_values('Price', ascending=False).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc44e5a-58cd-42d3-94a8-aea57c5aaaa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a new column\n",
    "df['PriceCategory'] = pd.cut(df['Price'], bins=[0, 1.25, 2.5, 3.75, np.inf], labels=['Low', 'Medium', 'High', 'Very High'])\n",
    "print(\"\\nDataFrame with new PriceCategory column:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4afbf912-3569-4cbe-9b5a-bdda5b7d434d",
   "metadata": {},
   "source": [
    "A particularly useful feature of Pandas is the ability to group data by a particular column and then apply a function to each group. This is similar to the SQL `GROUP BY` clause, or to Excel's pivot tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2c91bf-936f-4242-80f7-8c52e9adbf6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by operations\n",
    "print(\"\\nAverage house age by price category:\")\n",
    "print(df.groupby('PriceCategory', observed=False)['HouseAge'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c1c88f-ddfb-47a5-b972-2fe9e525fd55",
   "metadata": {},
   "source": [
    "Pandas also includes some plotting functionality, which is built on top of the Matplotlib library. Very useful for quickly visualizing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f031bc05-2703-48a4-a20e-906c4fc5a405",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic data visualization\n",
    "plt.figure(figsize=(4, 3))\n",
    "df.plot(x='MedInc', y='Price', kind='scatter', alpha=0.5)\n",
    "plt.title('Median Income vs House Price')\n",
    "plt.xlabel('Median Income')\n",
    "plt.ylabel('House Price')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698bad3c-5102-4822-b099-e6cb240aa2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation heatmap (excluding categorical column)\n",
    "plt.figure(figsize=(4, 3))\n",
    "correlation_matrix = df.drop('PriceCategory', axis=1).corr()\n",
    "plt.imshow(correlation_matrix, cmap='coolwarm', aspect='auto')\n",
    "plt.colorbar()\n",
    "plt.xticks(range(len(correlation_matrix.columns)), correlation_matrix.columns, rotation=90)\n",
    "plt.yticks(range(len(correlation_matrix.columns)), correlation_matrix.columns)\n",
    "plt.title('Correlation Heatmap of California Housing Features')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e637f5-275b-4909-8496-4a9b5c72b21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling categorical data\n",
    "print(\"\\nCount of houses in each price category:\")\n",
    "print(df['PriceCategory'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8546fe49-39c4-46a4-bfd1-4b6c2003f0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing categorical data\n",
    "plt.figure(figsize=(6, 4))\n",
    "df['PriceCategory'].value_counts().plot(kind='bar')\n",
    "plt.title('Distribution of House Prices by Category')\n",
    "plt.xlabel('Price Category')\n",
    "plt.ylabel('Number of Houses')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cfaca93-6303-4461-abb7-53d1566a7c6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HPC_ML",
   "language": "python",
   "name": "hpc_ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
