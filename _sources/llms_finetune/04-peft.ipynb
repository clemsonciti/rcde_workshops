{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Parameter-efficient Fine-tuning (PEFT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from workshop_utils import display_pdf\n",
    "\n",
    "display_pdf(\"Slides_part8.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LoRA\n",
    "\n",
    "Now let's use LoRA to train the model. Notice how many fewer trainable parameters there are compared to the full fine-tune, and how much faster the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    ")\n",
    "import torch\n",
    "\n",
    "# Load the dataset\n",
    "ds = load_dataset(\"HuggingFaceH4/MATH-500\")\n",
    "# Split the dataset into training and validation sets\n",
    "train_val_dataset = ds[\"test\"].train_test_split(test_size=0.1)\n",
    "train_dataset = train_val_dataset[\"train\"]\n",
    "eval_dataset = train_val_dataset[\"test\"]\n",
    "\n",
    " # This example only has a test split, so we use that, for demonstration purposes.\n",
    "\n",
    " # Load the model and tokenizer\n",
    "model_name = \"Qwen/Qwen2.5-0.5B-Instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "# The model may not have a pad token set by default, so set it (using the EOS token)\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "from workshop_utils import tokenize_and_mask, tokenize_for_generation, generate_and_print, data_collator\n",
    "\n",
    "data_collator_fn = lambda features: data_collator(features, tokenizer=tokenizer) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Map the formatting function over the dataset.\n",
    "# This applies the formatting function to each example in the dataset.\n",
    "# The result is that we have a dataset where each math problem is formatted as a prompt for the model,\n",
    "# and the solution is formatted as a response that the model should generate.\n",
    "# Each example is also tokenized\n",
    "# (If your dataset is large you might use batched=True; here we keep it simple.)\n",
    "train_dataset_tokenized = train_dataset.map(tokenize_and_mask, batched=False, fn_kwargs={\"tokenizer\": tokenizer})\n",
    "eval_dataset_tokenized = eval_dataset.map(tokenize_and_mask, batched=False, fn_kwargs={\"tokenizer\": tokenizer})\n",
    "\n",
    "# Get a sample dataset so we can examine model generations before and after training\n",
    "sample_dataset = eval_dataset.select(range(3))\n",
    "sample_dataset_tokenized = sample_dataset.map(tokenize_for_generation, batched=False, fn_kwargs={\"tokenizer\": tokenizer})\n",
    "\n",
    "train_dataset_tokenized.set_format(type=\"torch\", columns=[\"input_ids\", \"labels\", \"attention_mask\"])\n",
    "eval_dataset_tokenized.set_format(type=\"torch\", columns=[\"input_ids\", \"labels\", \"attention_mask\"])\n",
    "sample_dataset_tokenized.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def print_trainable_parameters(model):\n",
    "    \"\"\"\n",
    "    Prints the number of trainable parameters in the model.\n",
    "    \"\"\"\n",
    "    trainable_params = 0\n",
    "    all_params = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        num_params = param.numel()\n",
    "        all_params += num_params\n",
    "        if param.requires_grad:\n",
    "            trainable_params += num_params\n",
    "    print(f\"trainable params: {trainable_params:,d} || all params: {all_params:,d} || trainable%: {100 * trainable_params / all_params:.2f}%\")\n",
    "\n",
    "print_trainable_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "\n",
    "# Define LoRA Config\n",
    "lora_config = LoraConfig(\n",
    "    task_type=TaskType.CAUSAL_LM, \n",
    "    inference_mode=False, \n",
    "    r=8, \n",
    "    lora_alpha=32, \n",
    "    lora_dropout=0.05,\n",
    "    target_modules=[\"q_proj\", \"v_proj\"] # Replace with the target modules of your model\n",
    ")\n",
    "\n",
    "# Add LoRA adapter to the model\n",
    "model = get_peft_model(model, lora_config)\n",
    "model.print_trainable_parameters()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./qwen-lora-math\",          # Output directory\n",
    "    num_train_epochs=3,              # Number of training epochs\n",
    "    per_device_train_batch_size=8,   # Batch size per device during training\n",
    "    gradient_accumulation_steps=1,   # Number of updates steps to accumulate before performing a backward/update pass\n",
    "    optim=\"paged_adamw_32bit\",        # Optimizer, you might need to install accelerate: pip install accelerate -U\n",
    "    save_steps=20,                   # Save checkpoint every X updates steps\n",
    "    eval_steps=20,                   # Evaluate every X updates steps\n",
    "    eval_strategy=\"steps\",           # Evaluation strategy\n",
    "    save_total_limit=1,              # Limit the total amount of checkpoints\n",
    "    load_best_model_at_end=True,     # Load the best model when finished training (default is True)\n",
    "    logging_steps=10,                # Log every X updates steps\n",
    "    learning_rate=1e-4,              # Learning rate\n",
    "    weight_decay=0.001,              # Weight decay\n",
    "    fp16=True,                       # Use mixed precision training\n",
    "    bf16=False,                      # Use bfloat16 training\n",
    "    max_grad_norm=0.3,               # Gradient clipping max norm\n",
    "    max_steps=-1,                    # If > 0: set total number of training steps to perform. Override num_train_epochs.\n",
    "    warmup_ratio=0.03,               # Linear warmup over warmup_ratio fraction of the total number of training steps.\n",
    "    group_by_length=True,            # Group sequences of roughly the same length together for more efficient training\n",
    "    lr_scheduler_type=\"cosine\",       # Learning rate scheduler type\n",
    "    report_to=\"none\",                # Disable logging\n",
    ")\n",
    "\n",
    "# Create Trainer instance\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset_tokenized,\n",
    "    eval_dataset=eval_dataset_tokenized,\n",
    "    data_collator=data_collator_fn,     # Data collator if needed\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save the LORA model\n",
    "output_dir = \"./qwen-lora-math-final\"\n",
    "model.save_pretrained(output_dir)\n",
    "tokenizer.save_pretrained(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the LORA model\n",
    "from peft import PeftModel\n",
    "from transformers import AutoModelForCausalLM\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"Qwen/Qwen2.5-0.5B-Instruct\", device_map=\"auto\")\n",
    "model = PeftModel.from_pretrained(model, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Generate and print model outputs after training\n",
    "generate_and_print(sample_dataset, sample_dataset_tokenized, model, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QLoRA\n",
    "\n",
    "Now let's try QLoRA. The primary benefit is reduced model size through quantization, so you can train a larger model on the same resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    ")\n",
    "import torch\n",
    "from transformers import BitsAndBytesConfig\n",
    "\n",
    "# Load the dataset\n",
    "ds = load_dataset(\"HuggingFaceH4/MATH-500\")\n",
    "# Split the dataset into training and validation sets\n",
    "train_val_dataset = ds[\"test\"].train_test_split(test_size=0.1)\n",
    "train_dataset = train_val_dataset[\"train\"]\n",
    "eval_dataset = train_val_dataset[\"test\"]\n",
    "\n",
    " # This example only has a test split, so we use that, for demonstration purposes.\n",
    "\n",
    "# Configuration for bitsandbytes (QLoRA)\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float16, # Or torch.bfloat16 if supported\n",
    ")\n",
    "\n",
    " # Load the model and tokenizer\n",
    "model_name = \"Qwen/Qwen2.5-0.5B-Instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "# The model may not have a pad token set by default, so set it (using the EOS token)\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from peft import prepare_model_for_kbit_training\n",
    "\n",
    "\n",
    "# Prepare Model for QLoRA\n",
    "model = prepare_model_for_kbit_training(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Configure LoRA\n",
    "lora_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.CAUSAL_LM,\n",
    "    inference_mode=False,\n",
    "    target_modules=[\"q_proj\", \"v_proj\"] # Adjust for your model\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, lora_config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./qwen-qlora-math\",          # Output directory\n",
    "    num_train_epochs=3,              # Number of training epochs\n",
    "    per_device_train_batch_size=8,   # Batch size per device during training\n",
    "    gradient_accumulation_steps=1,   # Number of updates steps to accumulate before performing a backward/update pass\n",
    "    optim=\"paged_adamw_32bit\",       # Optimizer, you might need to install accelerate: pip install accelerate -U\n",
    "    save_steps=20,                   # Save checkpoint every X updates steps\n",
    "    eval_steps=20,                   # Evaluate every X updates steps\n",
    "    eval_strategy=\"steps\",           # Evaluation strategy\n",
    "    save_total_limit=1,              # Limit the total amount of checkpoints\n",
    "    load_best_model_at_end=True,     # Load the best model when finished training (default is True)\n",
    "    logging_steps=10,                # Log every X updates steps\n",
    "    learning_rate=1e-4,              # Learning rate\n",
    "    weight_decay=0.001,              # Weight decay\n",
    "    fp16=True,                       # Use mixed precision training\n",
    "    bf16=False,                      # Use bfloat16 training\n",
    "    max_grad_norm=0.3,               # Gradient clipping max norm\n",
    "    max_steps=-1,                    # If > 0: set total number of training steps to perform. Override num_train_epochs.\n",
    "    warmup_ratio=0.03,               # Linear warmup over warmup_ratio fraction of the total number of training steps.\n",
    "    group_by_length=True,            # Group sequences of roughly the same length together for more efficient training\n",
    "    lr_scheduler_type=\"cosine\",      # Learning rate scheduler type\n",
    "    report_to=\"none\",                # Disable logging\n",
    ")\n",
    "\n",
    "# Create Trainer instance\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset_tokenized,\n",
    "    eval_dataset=eval_dataset_tokenized,\n",
    "    data_collator=data_collator_fn,     # Data collator if needed\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the QLoRA model\n",
    "output_dir = \"./qwen-qlora-math-final\"\n",
    "model.save_pretrained(output_dir)\n",
    "tokenizer.save_pretrained(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the QLoRA model\n",
    "from peft import PeftModel\n",
    "from transformers import AutoModelForCausalLM\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"Qwen/Qwen2.5-0.5B-Instruct\", device_map=\"auto\", quantization_config=bnb_config)\n",
    "model = PeftModel.from_pretrained(model, output_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate and print model outputs after training\n",
    "generate_and_print(sample_dataset, sample_dataset_tokenized, model, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt tuning\n",
    "\n",
    "The last PEFT method we'll use is prompt tuning, in which the only thing trained is a continuous-valued addition to the prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from peft import PromptTuningConfig, get_peft_model\n",
    "\n",
    "# Define Prompt Tuning Config\n",
    "prompt_tuning_config = PromptTuningConfig(\n",
    "    task_type=TaskType.CAUSAL_LM, \n",
    "    num_virtual_tokens=20, # Length of the prompt\n",
    "    prompt_tuning_init=\"TEXT\",\n",
    "    prompt_tuning_init_text=\"Solve the following math problem:\",\n",
    "    tokenizer_name_or_path=model_name,\n",
    ")\n",
    "\n",
    "# Add prompt tuning adapter to the model\n",
    "model = AutoModelForCausalLM.from_pretrained(\"Qwen/Qwen2.5-0.5B-Instruct\", device_map=\"auto\")\n",
    "model = get_peft_model(model, prompt_tuning_config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Training Arguments (example - adjust as needed)\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./qwen-prompt-tuning-math\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=8,\n",
    "    gradient_accumulation_steps=1,\n",
    "    optim=\"paged_adamw_32bit\",\n",
    "    save_steps=20,\n",
    "    eval_steps=20,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    save_total_limit=1,\n",
    "    load_best_model_at_end=True,\n",
    "    logging_steps=10,\n",
    "    learning_rate=5e-3,  # Smaller learning rate often helps\n",
    "    weight_decay=0.001,\n",
    "    fp16=True,\n",
    "    bf16=False,\n",
    "    max_grad_norm=0.3,\n",
    "    max_steps=-1,\n",
    "    warmup_ratio=0.03,\n",
    "    group_by_length=True,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    report_to=\"none\",\n",
    ")\n",
    "\n",
    "# Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset_tokenized,\n",
    "    eval_dataset=eval_dataset_tokenized,\n",
    "    data_collator=data_collator_fn,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "output_dir = \"./qwen-prompt-tuning-math-final\"\n",
    "model.save_pretrained(output_dir)\n",
    "tokenizer.save_pretrained(output_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the model\n",
    "from peft import PeftModel\n",
    "from transformers import AutoModelForCausalLM\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"Qwen/Qwen2.5-0.5B-Instruct\", device_map=\"auto\")\n",
    "model = PeftModel.from_pretrained(model, output_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Generate and print model outputs after training\n",
    "generate_and_print(sample_dataset, sample_dataset_tokenized, model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (LLMsFT2)",
   "language": "python",
   "name": "llmsft2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
